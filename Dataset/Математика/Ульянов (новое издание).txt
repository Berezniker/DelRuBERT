Оглавление
Лекция 1
1.1 Предисловие . . . . . . . . . . . . . . .
1.2 Конечные вероятностные пространства
ные исходы. Классическая вероятность
1.2.1 Задача о разделе ставки . . . .
1.2.2 Примеры устойчивости частот .
1.2.3 Петербургский парадокс . . . .

. . . . . . . . . . .
и равновероятные
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .

. . . . . . .
элементар. . . . . . .
. . . . . . .
. . . . . . .
. . . . . . .

4
4
5
5
6
7

Лекция 2
2.1 Аксиоматика А. Н. Колмогорова . . . . . . . . . . . . . . . . . . . . . .
2.1.1 Вероятностное пространство, σ-алгебра событий, вероятность .
2.1.2 Примеры вероятностных пространств . . . . . . . . . . . . . . .
2.1.3 Свойства вероятности . . . . . . . . . . . . . . . . . . . . . . . .

8
8
8
11
13

Лекция 3
3.1 Урновые схемы . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 Выборка с возвращением, биномиальное распределение . . . .
3.1.2 Выборка без возвращения, гипергеометрическое распределение
3.2 Условная вероятность . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Независимость множества событий . . . . . . . . . . . . . . . . . . . .
3.3.1 Пример Бернштейна . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Формула полной вероятности . . . . . . . . . . . . . . . . . . . . . . . .
3.5 Формула Байеса . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.6 Дискретные случайные величины, индикаторы событий . . . . . . . .
3.7 Схема Бернулли . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

21
21
21
22
23
26
26
27
28
29
31

Лекция 4
4.1 Независимость дискретных случайных величин, теорема о независимости двух функций от непересекающихся совокупностей независимых
дискретных случайных величин . . . . . . . . . . . . . . . . . . . . . .
4.2 Математическое ожидание дискретной случайной величины . . . . . .
4.2.1 Свойства математического ожидания . . . . . . . . . . . . . . .
4.2.2 Пример случайной величины, не имеющей мат. ожидания . . .
4.2.3 Мат. ожидание биномиально распределённой случайной величины . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Моменты и центральные моменты k-го порядка . . . . . . . . . . . . .
4.4 Дисперсия и её свойства . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.1 Дисперсия биномиально распределённой случайной величины
4.4.2 Среднеквадратичное отклонение . . . . . . . . . . . . . . . . . .

33

1

33
35
35
38
39
39
40
41
42

4.5

.
.
.
.
.

42
43
44
45
46

Лекция 5
5.1 Закон больших чисел Чебышева . . . . . . . . . . . . . . . . . . . . . .
5.2 Теорема Бернулли . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 Пуассоновское распределение . . . . . . . . . . . . . . . . . . . . . . .
5.4 Теорема Пуассона . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4.1 Оценка близости биномиальных вероятностей к пуассоновским
5.5 Задача о конкуренции (завязка) . . . . . . . . . . . . . . . . . . . . . .
5.6 Локальная предельная и интегральная теоремы Муавра-Лапласа . . .
5.7 Задача о конкуренции (развязка) . . . . . . . . . . . . . . . . . . . . .

47
47
47
48
48
50
50
51
52

Лекция 6
6.1 Задача о различении двух гипотез о доле шаров в урне . . . . . . . .
6.1.1 Ошибки первого и второго рода . . . . . . . . . . . . . . . . . .
6.1.2 Оценка для числа наблюдений, необходимых для различения
гипотез с заданной точностью . . . . . . . . . . . . . . . . . . .
6.2 Определение вероятностного пространства в общем случае . . . . . .
6.3 Сигма-алгебра, порождённая классом множеств . . . . . . . . . . . . .
6.4 Борелевская сигма-алгебра . . . . . . . . . . . . . . . . . . . . . . . . .
6.5 Случайные величины как измеримые отображения . . . . . . . . . . .

53
53
54

Лекция 7
7.1 Функция распределения случайной величины . . . . . . . . . . . . . .
7.1.1 Свойства функции распределения . . . . . . . . . . . . . . . . .
7.2 Распределение случайной величины . . . . . . . . . . . . . . . . . . . .
7.3 Теорема о единственности продолжения вероятности с алгебры на порождённую ею σ-алгебру . . . . . . . . . . . . . . . . . . . . . . . . . .
7.4 Взаимно однозначное соответствие между функциями распределения
и вероятностными распределениями . . . . . . . . . . . . . . . . . . . .

62
62
62
64

Лекция 8
8.1 Неравенство и УЗБЧ Колмогорова . . . . . . . . . . .
8.1.1 Неравенство Колмогорова . . . . . . . . . . . .
8.1.2 Усиленный закон больших чисел Колмогорова
8.1.3 Применение УЗБЧ: метод Монте-Карло . . . .
8.2 Сходимость в среднем . . . . . . . . . . . . . . . . . . .
8.3 Производящие функции . . . . . . . . . . . . . . . . . .
8.3.1 Свойства производящих функций . . . . . . . .

.
.
.
.
.
.
.

69
69
69
70
71
72
73
73

Лекция 9
9.1 Характеристические функции . . . . . . . . . . . . . . . . . . . . . . .
9.1.1 Свойства характеристических функций . . . . . . . . . . . . . .
9.2 Формула обращения . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

76
76
78
80

4.6
4.7

Ковариация и коэффициент корреляции . .
4.5.1 Свойства коэффициента корреляции
Неравенство А. А. Маркова . . . . . . . . .
Неравенство Чебышева . . . . . . . . . . . .
4.7.1 Правило трёх сигм . . . . . . . . . . .

2

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.

55
56
58
58
60

65
65

Лекция 10
10.1 Слабая cходимость . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10.2 Предельные теоремы
для характеристических функций . . . . . . . . . . . . . . . . . . . . .

84
84

Лекция 11
11.1 Метод характеристических функций в доказательстве предельных теорем . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11.1.1 Центральная предельная теорема . . . . . . . . . . . . . . . . .

91

Лекция 12
12.1 Условное математическое ожидание, условное
распределение случайной величины . . . . . . . . . . . . . . . . . . . .
12.1.1 Условное математическое ожидание, условное распределение в
случае дискретных случайных величин . . . . . . . . . . . . . .
12.1.2 Условное математическое ожидание, условное распределение в
случае абсолютно непрерывных случайных величин . . . . . .
12.2 Свойства условного математического ожидания . . . . . . . . . . . . .

96

Лекция 13
13.1 Введение в математическую статистику . . . .
13.2 Эмпирическая функция распределения . . . . .
13.3 Эмпирические или выборочные моменты . . . .
13.4 Порядковые статистики и вариационные ряды .
13.5 Статистические оценки . . . . . . . . . . . . . .
13.5.1 Свойства несмещенных оценок . . . . . .
13.5.2 Свойства cостоятельных оценок . . . . .
Лекция 14
14.1 Оптимальные оценки . . . . . .
14.2 Неравенство Рао - Крамера . . .
14.2.1 Функция правдоподобия
14.3 Метод моментов . . . . . . . . .
14.4 Достаточные статистики . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.

87

91
93

96
96
97
99

.
.
.
.
.
.
.

100
100
101
102
104
105
106
106

.
.
.
.
.

107
107
108
108
111
112

Лекция 15
115
15.1 Достаточные и полные статистики . . . . . . . . . . . . . . . . . . . . 115
15.2 Оценки максимального правдоподобия . . . . . . . . . . . . . . . . . . 116
Лекция 16
119
16.1 Доверительные интервалы и трактовка коэффициента доверия . . . . 119
Лекция 17
17.1 Методы построения интервальных оценок . . . . . . . . . . . .
17.1.1 Метод, основанный на точечных оценках . . . . . . . . .
17.1.2 Метод, основанный на центральной статистике . . . . .
17.1.3 Метод, основанный на центральной предельной теореме
17.2 Проверка статистических гипотез . . . . . . . . . . . . . . . . .
17.2.1 Общая постановка проверки статистических гипотез . .
17.2.2 Типы гипотез . . . . . . . . . . . . . . . . . . . . . . . . .

3

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

121
121
121
122
124
126
126
126

Лекция 18
130
18.1 Лемма Неймана-Пирсона . . . . . . . . . . . . . . . . . . . . . . . . . . 130
18.2 Равномерно наиболее мощные критерии . . . . . . . . . . . . . . . . . 132
Лекция 19
19.1 Состоятельные критерии . . . . . . . . . . .
19.2 Критерий χ2 Пирсона . . . . . . . . . . . . .
19.2.1 Критерий χ2 Пирсона . . . . . . . . .
19.2.2 Асимптотика для критерия Пирсона
19.3 Состоятельность критерия Пирсона . . . . .
19.4 Обобщение классического критерия χ2 . . .

.
.
.
.
.
.

.
.
.
.
.
.

Лекция 20
20.1 Критерий согласия Пирсона χ 2 для абсолютно
делений . . . . . . . . . . . . . . . . . . . . . . .
20.2 Критерий независимости χ 2 . . . . . . . . . . .
20.3 Критерий независимости χ 2 . . . . . . . . . . .
20.4 Проверка гипотез и доверительный интервал .
20.5 Несмещенные критерии . . . . . . . . . . . . . .

4

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

134
134
134
134
135
136
137
138

непрерывных
. . . . . . . .
. . . . . . . .
. . . . . . . .
. . . . . . . .
. . . . . . . .

распре. . . . .
. . . . .
. . . . .
. . . . .
. . . . .

138
139
140
140
141

Лекция 1

1.1

Предисловие

Представим себе жидкость, которая с постоянным расходом w перетекает из первого
сосуда во второй. Нам точно известно, что через время t из первого сосуда во второй
перетечет wt жидкости. Мы точно знаем, что произойдет, наш ответ мы даем с
вероятностью один.
Теперь, получив образование и достав где-то N единиц некоторой валюты, положим их в ПИФ "Зияющие высоты". Теперь едва-ли кто-нибудь знает, что там с
ними будет через год. Есть несколько вариантов:
• Наши сбережения выросли в полтора раза! Вероятность такого события, положим, 80%.
• Наши сбережения едва-едва не обесценились в результате потрясений в финансовом мире, но остались в сохранности. Вероятность этого события, скажем,
12%.
• И, наконец, наши сбережения исчезли. Вероятность — 8%.
Теперь на вопрос, что же там будет дальше, мы отвечаем, используя слово «вероятность».
Это — одно из обстоятельств, с которым придется иметь дело в этом курсе. Дать
точно определенный ответ на вопрос, что же произойдет, нельзя, хотя бы из-за установленных Гейзенбергом фактов квантовой механики. Зато, если повезет, можно
точно указать вероятность некоторого события. Чему равна вероятность выпадения в казино на рулетке именно той позиции, на которой некто вечером в пятницу
составил башенку из всех фишек, которые смог добыть?
Один из источников теории вероятности — азартные игры, и это не всем нравится.
И рулетка, между прочим, возникла как средство борьбы с карточными шулерами!
А владельцы казино тем временем, располагая данными о вероятностях выпадения позиций на рулетке, распределении ставок и выигрышей, посчитали, сколько в
среднем выносят из казино и сколько в нем оставляют. Разумеется, выносят немного
меньше. Эта игра — несправедливая.
Определение 1.1. Игра называется справедливой тогда и только тогда, когда
средние выигрыш и проигрыш равны между собой.
Еще один источник теории вероятности — страхование морских грузов. В случае
страхования определить требуемые вероятности уже гораздо сложнее. При страховании жизни, например, ставка должна зависеть от очень и очень многих вещей.
Взять и посчитать нужные величины, используя только точно известные физические константы и фундаментальные законы не представляется возможным. И здесь
появляется математическая статистика, призванная на основе полученных опытным
путем данных строить вероятностную модель.
5

1.2

Конечные вероятностные пространства и равновероятные элементарные исходы. Классическая
вероятность

Считается, что теория вероятности родилась летом 1654 года, когда была решена
задача о разделе ставки.

1.2.1

Задача о разделе ставки

Задача. Два игрока, точно равных в силах, играют в разные игры и за одну победу получают одно очко. Всего запланировано 11 раундов. Внезапно игры остановились. На момент остановки счет оказался равным 5 : 3. Вопрос, как справедливо
делить приз, решается следующим образом: приз делится пропорционально вероятности выигрыша каждого из игроков. Вот только вопрос определения вероятностей
выигрышей решить еще осталось! Итак, как делить приз?
Решение. Разберемся с тем, что может произойти за последние три игры. Имеется
восемь раскладов для побед в этих играх, все они равновозможны в силу одинаковости игроков в силе. Первый игрок одержал 5 побед, второй — 3. Победу первого
игрока будем обозначать «A», победу второго — «B». Итак, варианты исходов последних трёх игр:

AAA



AAB 



ABA


ABB при этих раскладах победит первый,


BAA




BAB 



BBA
BBB — и только в этом случае победит второй.
В семи из восьми случаев в итоге победит первый игрок. И только в одном из них —
второй. Все эти случаи равновероятны, равносильны при учете в разделе приза. Поэтому 7/8 получит первый игрок, а 1/8 получит второй. И на самом деле — первому
достаточно одержать только одну победу, в то время как второму — целых три. И
отношение долей — 7 : 1, а вовсе не 5 : 3.
Теперь следует попытаться формализовать процесс решения задачи. Были рассмотрены все возможные исходы. К счастью, в этой задаче их конечное количество
(что не всегда так — вот, например, бросить точку в отрезок от нуля до одного, исходов будет континуум). Все исходы равновероятны (что тоже не всегда так — просто
дадим одному из игроков доппинг, увеличивающий силу в e раз). Событий было два:
побеждает первый игрок или второй. Каждому из событий соответствует свой набор
элементарных исходов, и необязательно эти наборы имеют пустое пересечение.
Все дальнейшие определения вводятся в том контексте, что имеется некоторый
случайный эксперимент.
Определение 1.2. Пусть Ω = {ω1 , . . . , ωn } — множество всех исходов случайного эксперимента. В этом случае множество Ω называется пространством
элементарных исходов.
6

Замечание. Вообще-то, один и тот же эксперимент может быть представлен разными пространствами элементарных исходов. Далее будет нужна равновозможность
элементарных исходов и конечность Ω. Остальное пока неважно.
Замечание. С тех пор, как все результаты содержатся в конечном множестве Ω,
любое событие A можно считать подмножеством Ω. Строгое определение события
появится несколько позже. В задаче о разделе ставки победу первого игрока означало множество из семи элементарных исходов, победу второго игрока — множество
из одного элементарного исхода.
Определение 1.3. Пусть есть конечное пространство элементарных исходов Ω,
все элементарные исходы равновозможны. Пусть имеется событие A, A ⊆ Ω.
Тогда классическая вероятность события A определяется как
P(A) =

kAk
.
kΩk

Пусть теперь нам удалось построить множество всех событий. Обозначим его F .
В задаче о разделе ставки событий было, грубо говоря, два: победа первого игрока
и победа второго игрока. Можно говорить о событии «победил один из них» или «не
победил никто», можно придумывать события и далее. То есть, речь идет максимум
о множестве всех подмножеств Ω. В конечном случае никаких проблем тут не возникает, а вот множество всех подмножеств сегмента от нуля до одного, как выяснится
позже, обладает весьма неподходящими для вероятности свойствами.
Определение 1.4. Тройку (Ω, F, P), где Ω — конечное множество всех элементарных исходов, F — множество всех событий и P — вероятность, определенная для
всех элементов из F , будем называть конечным вероятностным пространством.

1.2.2

Примеры устойчивости частот

Как на деле установить, равновозможны элементарные исходы или нет — это серьезный вопрос. Можно, например, обратиться к статистике, о которой мы ничего
пока не знаем. Так вот выдвинем гипотезу о равновозможности элементарных исходов и оценим, насколько она правдоподобна. Пока ничего не знаем о статистике, эти
действия проведем интуитивно и нестрого.
Определение 1.5. Пусть A — некоторое событие. Пусть проведено N экспериментов, причем событие A наступило в NA экспериментах. Отношение
νA =

NA
N

будем называть частотой события A.
Мысль подсказывает, что если некоторый эксперимент провести много раз, причем так, чтобы эксперименты никак друг на друга не влияли, то «в среднем» отношение экспериментов, в которых событие наступило, к общему числу экспериментов
должно дать вероятность этого события. То есть положимся на не всегда верное
предположение о том, что
P(A) ≈ νA .
Для примеров из этой лекции оно нормально работает.
7

Пример. Требуется выяснить, равновозможны ли выпадение герба и решки при
бросании идеальной монетки честным экспериментатором. Иными словами, надо
разобраться, будут ли элементарные исходы «выпала решка» и «выпал герб» равновозможными. Этим вопросом занимались в разное время разные исследователи:
XVIII в: монету подбрасывал Бюффон: на 4040 бросков пришлось 2048 гербов.
Частота для выпадения герба составила 0,507;
XIX в: Морган подбросил монету 4092 раза и получил столько же гербов. Частота
для выпадения герба составила 0,5005;
XX в: Пирсон совершил 24000 бросков, герб выпал 12012 раз. Частота для выпадения герба вновь составила 0,5005;
XX в: Романовский сделал это 80640 раз, герб выпал 39699 раз. У Романовского
частота получилась равной 0,4923.
С точностью до третьего знака все естествоиспытатели получили 0,5. Этот факт демонстрирует устойчивость частоты выпадения герба при подбрасывании правильной
монетки (правильным экспериментатором).
Пример. В некотором населенном пункте в 1935 году осуществлялся сбор данных
о новорожденных:
в январе родилось 7280 детей, из них 3743 мальчиков, частота — 0,514,
в феврале родилось 6957 детей, из них 3550 мальчиков, частота — 0,510.
В демографии вероятность рождения мальчика принимается равной 0,514.

1.2.3

Петербургский парадокс

Пример. Пусть Аня и Боря решили сыграть на деньги. Аня подбрасывает правильную монетку, так что вероятности выпадения герба и решки равны 1/2 каждая. Боря
платит Ане 2n рублей, если первый герб выпал на n-том шаге.
Проблема заключается в том, что при попытке отыскать средний выигрыш Ани
неминуемо получится бесконечность, если нигде не ошибиться. В свое время этот
факт не давал покоя некоторым исследователям. Для того, чтобы сделать игру
справедливой, Аня должна Боре перед началом подбрасываний монеты предоставить бесконечное количество рублей, этот факт устанавливается на с.38.
Кроме того, в приведённой ситуации пространство элементарных исходов счётно.
Классическая вероятность здесь просто неприменима. Так что если попробовать её
тут приложить, парадокс непременно возникнет.
Представим себе множество всех натуральных чисел, пусть это будет пространством элементарных исходов Ω = N. Объявим их равновозможными. Тогда попробуем посчитать вероятность события A, состоящего из одного любого элементарного
исхода. Попытка применить тут классическую вероятность приведет в тупик:
P(A) =

kAk
,
kΩk

если с kAk вопросов не возникает, то вот разобраться с тем, что же такое в данном случае kΩk, не получится. Эта формула тут вообще некорректна, потому что Ω
вновь счетно, а вовсе не конечно. Кроме того, сама модель не позволяет построить
вероятностное пространство. Все станет просто и очевидно после появления более
строгих формулировок и определений, но об этом — на следующей лекции.
8

Лекция 2

2.1
2.1.1

Аксиоматика А. Н. Колмогорова
Вероятностное пространство, σ-алгебра событий, вероятность

Начнём с того, что есть и другие аксиоматики. Даже с отрицательной вероятностью!
Однако, в данном курсе вполне достаточно аксиоматики Колмогорова, о которой
речь пойдет на этой лекции.
Определение 2.1. Пусть Ω — любое непустое множество. Событием будем называть любое подмножество Ω. Событие Ω называется достоверным событием, а событие ∅ — невозможным. Само множество Ω называется пространством элементарных исходов.
Замечание. Очень скоро под словом «событие» будет пониматься уже не всякое
подмножество Ω.
Определение 2.2. События A и B называются несовместными, если A ∩ B = ∅.
Определение 2.3. Множество F подмножеств Ω называется классом событий ⇐⇒ F обладает следующими тремя свойствами:
1◦ . Классу событий принадлежит достоверное событие:
Ω ∈ F.
2◦ . Класс событий для любого своего события содержит его отрицание:
A ∈ F =⇒ A ∈ F.
3◦ . Свойство счётной аддитивности:
∀ i ∈ N Ai ∈ F =⇒

∞
[

Ai ∈ F.

i=1

Замечание. Здесь важно заметить, что, имея на руках операции объединения и
отрицания, можно построить операцию пересечения следующим образом:
A ∩ B ≡ A ∪ B.
Определение 2.4. F — вырожденный класс событий ⇐⇒ F = {∅, Ω}.
Замечание. Вырожденный класс событий — это наименьший класс событий, он
обладает указанными выше тремя свойствами. Как минимум, Ω и Ω класс событий
обязан содержать. Меньше никак нельзя.
9

Определение 2.5. Множество F , обладающее указанными выше тремя свойствами, называется сигма-алгеброй. Разные «счётные» операции за пределы сигмаалгебры не выводят.
Определение 2.6. Событием называется подмножетсво Ω, являющееся элементом σ-алгебры событий.
Определение 2.7. Пусть P — отображение из класса событий F в R.
P называется вероятностью ⇐⇒ P обладает следующими тремя свойствами:
1◦ . Нормировка: вероятность достоверного события равна единице:
P(Ω) = 1.
2◦ . Вероятность неотрицательна:
∀ A ∈ F P(A) > 0.
3◦ . Счётная аддитивность вероятности или σ-аддитивность вероятности:
∀ i ∈ N Ai ∈ F, ∀ i, j ∈ N i 6= j =⇒ Ai Aj = ∅
⇓
∞
∞
[
X
P( Ai ) =
P(Ai ).
i=1

i=1

Утверждение 2.1. Вероятность невозможного события равна нулю.
P(∅) ≡ 0.
Доказательство. Рассмотрим следующую счётную последовательность событий:
Ω, ∅, ∅, ∅ . . .. События из этой последовательности попарно несовместны и объединение их равно Ω. Далее пользуемся свойством счётной аддитивности для этой последовательности:
Ω = Ω ∪ ∅ ∪ ∅ ∪ ∅ ∪ . . . =⇒ P(Ω) = P(Ω) + P(∅) + P(∅) + P(∅) + . . .
⇓
1 = 1 + P(∅) + P(∅) + . . . =⇒ 0 = P(∅) + P(∅) + P(∅) + . . . =⇒ P(∅) = 0.
Если считать понятие меры известным, то вероятность — это нормированная
мера. То есть, вероятность от меры отличается только уловием P(Ω) = 1.
Теперь несколько слов по поводу того, зачем же нужна σ-алгебра. От множества
всех подмножеств Ω σ-алгебра в общем случае существенно отличается. Пример тому, описанный наклонным шрифтом на с.12, — подмножество отрезка от нуля до
одного, не имеющее меры по Лебегу, такие множества называются неизмеримыми. Требуется именно существование меры Лебега подмножеств Ω, с которыми мы
будем работать, потому что иначе не существует для них и вероятности. Для таких
множеств просто нельзя её ввести, не потеряв при этом какое-нибудь очень нужное
из трёх её свойств. И именно членство в правильно построенной σ-алгебре событий
строго гарантирует существование вероятности безо всяких нарушений, парадоксов
и потерь. Неизмеримые множества из σ-алгебры специально исключаются, и никакими не выводящими из неё операциями получить их из измеримых множеств
нельзя.
А вот для счётного Ω такой проблемы нет.
10

Утверждение 2.2. Для любой вероятностной модели со счётным Ω в качестве
σ-алгебры событий F можно брать множество всех подмножеств Ω, мощность
F — континуум.
Доказательство. Итак, пусть у нас имеется счётное количество элементарных
исходов:
Ω = {ω1 , ω2 , ω3 , . . .}.
Покажем, что для множества всех подмножеств Ω, которое обозначим через F , определена вероятность. Выполненность для F свойств σ-алгебры очевидна.
Построим взаимно-однозначное соответствие между элементами F и строками из
нулей и единиц счётной длины B. Пусть A ∈ F — событие. Строку, соответствующую
A обозначим BA , цифру, стоящую в i-той позиции строки BA обозначим biA . BA
определим следующим образом:
(
1, если ωi ∈ A,
i
bA =
0, если ωi ∈
/ A.
⇓
∀A ∈ F ∃ !BA , ∀A1 , A2 ∈ F : A1 6= A2 =⇒ BA1 =
6 BA2 и ∀B1 ∈ B ∃A ∈ F : B1 = BA .
Теперь заметим, что множество B эквивалентно множеству всех бесконечных двоичных дробей с нулевой целой частью, то есть, множеству [ 0, 1]. Соответствующую
элементу Q ∈ B бесконечную дробь обозначим как RQ и просто прямо построим по
следующему правилу:
RQ = 0.q1 q2 q3 q4 q5 . . . , где qi — i-тый разряд Q.
Отсюда следует, что B, равно как и F , имеет мощность континуум.
Зададим вероятности событий {ωi } числами pi , i ∈ N, чтобы было верным
∞
X

pi = 1, pi > 0 ∀i ∈ N.

i=1

События эти плюс пустое попарно несовместны и любое другое событие можно представить как их счётное объединение. Вероятность Ω, которое равно счётному объединению всех {ωi }, равна единице, вероятность ∅, не содержащего никого из {ωi },
равна нулю. Любое событие представить как
(
∞
[
[
Ω, если ωi ∈ A,
A = ({ωi } ∩ Ii ) =
{ωi }, где Ii =
.
∅, если ωi ∈
/ A.
i=1
i :ω ∈A
i

События {ωi } ∩ Ii по-прежнему попарно несовместны, поскольку {ωi } ∩ Ii ⊆ {ωi }, и
можно воспользоваться свойством счётной аддитивности вероятности:
P(A) =

∞
X

P({ωi } ∩ Ii ) =

i=1

∞
X

pi bia .

i=1

Полученный ряд сходится, поскольку сходится ряд из pi , а pi bia 6 pi и оба ряда
неотрицательны. Тогда для любого события вероятность определена.
Определение 2.8. Пусть Ω — произвольное непустое множество, F — сигмаалгебра событий на Ω и P — вероятность, определённая на F . В этих терминах
тройка (Ω, F, P) называется вероятностным пространством.
11

2.1.2

Примеры вероятностных пространств

Абстракцию требуется проиллюстрировать примерами.
Конечное число элементарных исходов
Простейший пример — подбрасывание правильного игрального кубика. Он имеет
шесть граней, и на каждую из них после броска приземляется с той же вероятностью, что и на любую другую. Элементарных исходов шесть: Ω = {1, 2, 3, 4, 5, 6}, где
цифрой обозначается число на обращённой вверх после броска грани. Ω — пространство элементарных исходов.
Займемся сигма-алгеброй событий. Выпадение любой грани — это событие. То
есть, A1 = {1}, A2 = {2}, A3 = {3}, A4 = {4}, A5 = {5}, A6 = {6} — всё это события. Кроме того, событием будет само Ω. Обратимся к свойствам сигма-алгебры.
В ней с любым событием должно содержаться его отрицание. Отрицание Ω — это
невозможное событие ∅. Отрицание Aj (j ∈ Z, 1 6 j 6 6) можно представить так:
Aj =

6
[

Ak .

k=1
k6=j

Обратим внимание на то, что если у нас есть счётная аддитивность и невозможное событие, то можно получить конечную аддитивность, просто положив все
хвостовые события невозможными. То есть, если F — σ-алгебра, то в ней содержится невозможное событие (как отрицание достоверного) и есть свойство счётной
аддитивности. Значит,
A, B ∈ F =⇒ A ∪ B ∪ ∅ ∪ ∅ . . . ∈ F — это счётная аддитивность.
⇓
A ∪ B ∈ F , поскольку A ∪ B = A ∪ B ∪ ∅ ∪ ∅ . . .
Поэтому вышеупомянутые события A1 , A2 , A3 , A4 , A5 , A6 можно как угодно объединять. Полезно заметить, что они попарно несовместны. Дальше то, что получилось, можно как угодно пересекать. Событие «выпало чётное число» представимо в
виде A2 ∪ A4 ∪ A6 , событие «не единица» представляется как A2 ∪ A3 ∪ A4 ∪ A5 ∪ A6 .
Нетрудно обнаружить, что σ-алгебра событий в данном случае представляет собой
множество всех подмножеств Ω.
Раз кубик правильный, то вероятность выпадения каждой грани равна 1/6. То
есть, P(Aj ) = 1/6 (j ∈ Z, 1 6 j 6 6). Вероятность вводится как классическая, для
любого события её несложно посчитать и тем самым она полностью определена.
Другой пример вероятностного пространства — игра в рулетку. Пространство
элементарных исходов — все то, что может выпасть. В честном случае все эти элементарные исходы равновероятны, σ-алгебра событий и вероятность вводятся аналогично случаю с кубиком, но здесь интерес повыше, потому что появляются новые
события в духе «красное» и так далее.
Счётное число элементарных исходов
Более сложный пример — это игра Ани и Бори. Речь идет о Петербургском парадоксе. Здесь пространство элементарных исходов сложней. Выпадение герба будем
обозначать «Г», выпадение решки — буквой «Р». Цепочку подбрасываний будем
12

изображать в виде последовательности этих букв. При этом на выпадении первого
герба игра останавливается. Так что герб, в общем-то, всегда стоит в конце цепочки, за ним ничего уже нет. Так что пространство элементарных исходов получается
таким:
Ω = {Г, РГ, РРГ, РРРГ, РРРРГ, РРРРРГ, РРРРРРГ, РРРРРРРГ, . . .}
Ω в данном случае счётное, поэтому по утверждению на с.10 σ-алгебру событий
можно ввести как множество всех подмножеств Ω.
Обозначим событие «герб выпал при j-том подбрасывании» как Aj . События
Ai , Aj (i, j ∈ N) при i 6= j несовместны. Каждое из них состоит из одного элементарного исхода из Ω. Для симметричной монетки P(A1 ) = 1/2. Если подбрасывания
никак друг от друга не зависят, то P(A2 ) = 1/4. Это просто получить, если рассмотреть все возможные исходы двух независимых подбрасываний правильной монетки
(и отбросить вариант ГГ как соответствующий выпадению герба на первом шаге).
Так же получается, что P(Aj ) = 1/2j (j ∈ N). Любое событие можно представить
с помощью операций объединения и отрицания из {Ai }∞
1 , всё проводится точно так
же, как в доказательстве утверждения на с.10. Значит, вероятность определена для
любого события.
Континуум элементарных исходов
Теперь рассмотрим пока что новую ситуацию. Пусть некто бросает точку в отрезок от нуля до одного, причём делает это так, что все точки отрезка равноправны.
Некто может попасть как в точку 1/2, так и в 1/e или 1/π. Пространство элементарных исходов теперь имеет мощность континуум. Мы договорились о том, что все
точки равноправны. Чему тогда равна вероятность попадания в конкретную точку? Никакой ненулевой конечной величине она не может равняться, иначе сумма
вероятностей попаданий в точки последовательности xn = 1/n (а разных точек в
этой последовательности счетное число) даст бесконечность. Но она никак не может
превысить единицы. Значит, вероятность попадания в конкретную точку точно равна нулю. Никаких «мало» и «ужасно мало». С этой трудностью призвана бороться
построенная особым образом σ-алгебра.
Итак, Ω = [ 0, 1].
На с.9 уже говорилось о том, что в множестве всех подмножеств [ 0, 1] есть неизмеримые множетсва. Дальше речь пойдет об одном из них. Идея в том, что полуинтервал [ 0, 1) можно разбить на счётное количество непересекающихся множеств, мера
которых совпала бы, если бы существовала. Но предположение о её существовании
приводит к противоречию.
Возьмём в множестве [ 0, 1) любую точку. Выберем из него все её рациональные
сдвиги (то есть, все точки, что получаются из неё прибавлением любого рационального числа), которые попали в [ 0, 1). Изымем выбранные точки из [ 0, 1) в множество
W . Заметим, что так как изъято счётное количество точек, то от [ 0, 1) остался еще
континуум точек. Возьмём из остатка другую точку, выберем все её рациональные
сдвиги из [ 0, 1). Получим множество U . W ∩U = ∅, поскольку если это не так, то они
совпали бы. А мы изначально для U выбрали точку, которой нет в W . В множестве
[ 0, 1) \ W \ U по-прежнему континуум точек (потому что W и U счётные). По этому
принципу будем строить всё дальше и дальше такие же множества. Попарно они не
пересекаются, все счётные.
13

Весь полуинтервал [ 0, 1) разбивается на эти множества (потому что для любой
точки из него мы сможем указать множество, построенное по указанному выше способу, в которое эта точка попадёт). Этих множеств — континуум, иначе их объединение было бы счётным либо мощнее континуума, то есть тогда в сумме не получилось
бы [ 0, 1).
Теперь из каждого из полученных множеств возьмём по точке и положим в множество V0 . Оно целиком содержится в исходном полуинтервале. Все рациональные
сдвиги этого множества, лежащие в [ 0, 1), образуют весь этот полуинтервал (потому что все рациональные сдвиги этого V0 — это все множества из абзаца выше).
Обозначим за Vq множество, полученное из V0 сдвигом (циклическим, то есть, число,
которое «уплыло» при сдвиге за единицу, появляется со стороны нуля) на рациональное число q. Множеств Vq всего счётное число (как рациональных чисел разных). Их
объединение даёт весь полуинтервал:
[
Vq = [ 0, 1).
q∈Q

Отметим, что ∀p, q ∈ Q : p 6= q =⇒ Vp ∩ Vq = ∅. Теперь вспоминаем свойство счётной
аддитивности вероятности. Мера точно так же обладает этим свойством. Значит,
Ã
!
[
X
P
Vq =
P(Vq ).
q∈Q

q∈Q

Осталось обнаружить, что ∀p, q ∈ Q P(Vp ) = P(Vq ). Меры двух множеств, одно из
которых получено сдвигом другого, равны. Значит, ∀q ∈ Q P(Vq ) = P(V0 ). Последний
шаг:
Ã
!
[
X
X
P
Vq =
P(Vq ) =
P(V0 ) = P([ 0, 1)) = 1.
q∈Q

q∈Q

q∈Q

Нетрудно заметить, никакое вещественное P(V0 ) не может сделать это равенство
верным. Мы пришли к противоречию, тянувшемуся с предположения о том, что V0
имеет меру. Значит, у V0 меры нет.
Всё это было сделано для того, чтобы проиллюстрировать, что в множестве
всех подмножеств [ 0, 1] водятся неизмеримые типы. Для данного Ω используется
σ-алгебра, порождённая пересечением всех интервалов вещественной оси с [ 0, 1].
Вероятность на такой σ-алгебре вводится как мера Лебега элемента этого множества как множества на прямой. Вот и всё. Подробно об этом речь начинается на
с.58.

2.1.3

Свойства вероятности

Все свойства далее обсуждаются в предположении, что мы работаем с каким-то
вероятностным пространством. То есть, заданы пространство элементарных исходов
Ω, σ-алгебра событий F и вероятность P.
1◦ . Вероятность невозможного события равна нулю.
P(∅) ≡ 0.

14

Доказательство. Идентичное утверждение доказано на с.9.
2◦ (Свойство конечной аддитивности). Пусть задана σ-алгебра событий F и в
ней конечная последовательность A1 , A2 , A3 , . . . , An , в которой попарно несовместны события-члены. Тогда вероятность объединения всех этих событий — это сумма вероятностей событий-членов, т.е.:
{Ai }n1 ∈ F ; i, j ∈ N, i, j 6 n, i 6= j =⇒ Ai Aj = ∅
⇓
n
n
[
X
P( Ai ) =
P(Ai ).
i=1

i=1

Доказательство. Для доказательства просто рассмотрим специально составленную последовательность событий, а затем применим свойство счётной аддитивности
вероятности и факт равенства нулю вероятности невозможного события:
A1 , A2 , A3 , . . . , An , ∅, ∅, ∅, . . . — есть попарная несовместность,
⇓
Ãn
!
n
∞
[
[
[
P Ai = P
Ai ∪
∅ = P(A1 ) + P(A2 ) + . . . + P(An ) + P(∅) + P(∅) + . . .
i=1

i=1

i=n

1◦

= P(A1 ) + P(A2 ) + P(A3 ) + . . . + P(An ).
3◦ . Вероятность отрицания события — это единица минус вероятность самого
события:
P(A) ≡ 1 − P(A).
Доказательство.
2◦

Ω = A ∪ A, A ∩ A = ∅ =⇒ P(A) + P(A) = P(Ω) = 1
⇓
P(A) = 1 − P(A).
4◦ (Теорема сложения). Пусть A и B — произвольные события, тогда
P(A ∪ B) ≡ P(A) + P(B) − P(AB).
Доказательство. Разложим A и B следующим образом: A = AB ∪ AB, события
AB и AB несовместны; B = AB + AB, события AB и AB — тоже несовместны.
Несовместны и AB c AB. Поэтому верно следующее:
P(A) = P(AB) + P(AB), P(B) = P(AB) + P(AB).

(C)

Заметим, что A ∪ B = AB ∪ AB ∪ AB
⇓
C

P(A ∪ B) = P(AB) + P(AB) + P(AB) = P(AB) + P(B) − P(AB) + P(A) − P(AB)
= P(A) + P(B) − P(AB).

15

5◦ (Формула включения-исключения). В случае более, чем двух событий теорема сложения принимает следующий вид: ∀ A1 , . . . , An ∈ F
Ãn
!
Ãn
!
n
n
[
X
X
\
P
Ai = (−1)0
P(Ai ) + (−1)1
P(Ai Aj ) + . . . + (−1)n−1 P
Ai .
i=1

i=1

i,j=1
i<j

i=1

Доказательство. Нужно применить метод математической индукции. В качестве
базы индукции выступает теорема сложения. В качестве утверждения индукции —
утверждение теоремы. А вот индукционный переход придётся провести, в переходе
∗ используется теорема сложения: Ai ∈ F, 1 6 i 6 n + 1,
Ãn+1 !
Ã
!
Ãn
!
Ã
!
n
n
[
[
[
[
∗
P
Ai = P An+1 ∪
Ai = P(An+1 ) + P
Ai − P An+1
Ai
i=1

i=1

Ã

= P(An+1 ) + P

n
[

!
Ai

Ã
−P

i=1

i=1
n
[

!

i=1

(Ai An+1 )

i=1

Выражение для n + 1 полностью сведено к выражениям для n. Далее предстоит
техническая работа — простое раскрытие вероятностей по утверждению индукции и
группировка вероятностей пересечений двух событий, трёх и так далее. В результате
чего получится утверждение индукции, но уже для n + 1. Так что переход индукции
осуществлён, а утверждение доказано.
6◦ (Монотонность вероятности). Пусть A и B — некоторые события, причём
B содержит в себе A. Тогда вероятность A не превышает вероятности B:
A ⊆ B =⇒ P(A) 6 P(B).
Доказательство.
B \ A = B ∩ A, A ∩ (B ∩ A) = A ∩ A ∩ B = ∅ ∩ B = ∅, B = A ∪ B \ A
⇓
P(B) = P(A) + P(B \ A) > P(A) в силу неотрицательности вероятности.
Далее в выкладках если в пересечении или в объединении верхний предел меньше
нижнего, то такое пересечение следует считать равным Ω, а объединение — равным
∅. То есть,
2
[
i=3

= ∅,

5
\

= Ω.

i=6

7◦ (Счётная полуаддитивность). Пусть бесконечная последовательность {Ai }
целиком состоит из событий. Тогда вероятность счётного объединения событийчленов не превышает суммы вероятностей событий (если она вообще есть). То
есть,
Ã∞ !
∞
X
[
∞
P(Ai ).
{Ai }1 ∈ F =⇒ P
Ai 6
i=1

i=1

Замечание. Здесь никакой несовместности нету. Тут просто задана последовательность событий, однако и утверждение здесь послабей будет.
16

Доказательство. Построим новую последовательность попарно несовместных событий на основе данной в условии последовательности, положив предварительно
A0 = ∅:
D1 = A1 , D2 = A2 \ A1 , Dm = Am \

m−1
[

Ai . i, j ∈ N, i 6= j (пусть i > j)

i=1

⇓
Di Dj = Ai ∩

i−1
[

j−1

Ak ∩ Aj ∩

k=1

= Ai ∩ Aj ∩

[

Ak = Ai ∩ Aj ∩

k=1
i−1
\

i−1
\

j−1

Ak = Ai ∩ Aj ∩ Aj ∩

k=1

k=1

Ak ∩

Ak

k=1

k=1
j−1

\

\

Ak ∩

i−1
\

Ak = Ai ∩ ∅ ∩

k=j+1

i−1
\

Ak

k=1

= ∅ — в {Di } события попарно несовместны.
Теперь заметим, что
∞
[

Ai =

i=1

∞
[

Di

i=1

и воспользуемся для {Di } счётной аддитивностью:
Ã∞ !
Ã∞ !
∞
∞
[
[
X
X
P
Ai = P
Di =
P(Di ) 6
P(Ai ).
i=1

i=1

i=1

i=1

Определение 2.9. Последовательность событий {Ai } — неубывающая
m
A1 ⊆ A2 ⊆ A3 ⊆ A4 ⊆ A5 ⊆ . . . ⊆ Ai ⊆ Ai+1 ⊆ . . . (∀i ∈ N Ai ⊆ Ai+1 )
Определение 2.10. Последовательность событий {Ai } — невозрастающая
m
A1 ⊇ A2 ⊇ A3 ⊇ A4 ⊇ A5 ⊇ . . . ⊇ Ai ⊇ Ai+1 ⊇ . . . (∀i ∈ N Ai ⊇ Ai+1 )
Определение 2.11. Событие Q называется пределом неубывающей последовательности {Ai } (обозначается Q = lim Ai )
i→∞

Q=

m
∞
S

Ai .

i=1

Определение 2.12. Событие Q называется пределом невозрастающей последовательности {Ai } (обозначается Q = lim Ai )
Q=

m
∞
T

i→∞

Ai .

i=1

Определение 2.13. Последовательность событий {Ai } — монотонная, если она
является невозрастающей либо неубывающей.

17

В обоих случаях монотонности тот факт, что Q —
событие, следует из свойства счётной аддитивности
σ-алгебры. Ещё в обоих случаях монотонности наглядной иллюстрацией может послужить цепь матрёшек! Каждая точка вложенной матрёшки принадлежит множеству точек объемлющей (точки внутри
полой фигуры здесь тоже считаются принадлежащими ей). Так что ничего мистического в этих последовательностях на самом деле нет.
Вообще, здесь идёт речь о простых вещах длинным научным языком. Для облегчения понимания
рекомендуется пользоваться сначала кругами Эйлера, а затем аналитическим аппаратом теории множеств. На самом деле, всё то, что пойдёт дальше,
весьма и весьма просто и наглядно, если всякое неясное место иллюстрировать себе таким способом.
8◦ (Непрерывность по монотонной последовательности). Пусть {Ai } — монотонная последовательность событий. Тогда вероятность предела
{Ai } равна пределу вероятности события Ai . Иными словами,
{Ai } — монотонная последовательность событий
⇓
³
´
P lim Ai = lim P(Ai )
i→∞

i→∞

Доказательство. Для неубывающей последовательности событий построим последовательность несовместных событий на базе данной в условии последовательности и для неё воспользуемся свойством счётной аддитивности:
Dn = A n \
n
[

n−1
[

Ai =

i=1

Ai = An \ An−1 , что следует из неубывания {Ai }

i=1
n
[

Di ∀n ∈ N — это наглядно и почти очевидно,

i=1

⇓
³
P

´
lim An =

n→∞

∞
X
n=1

P(Dn ) = lim

n
X

n→∞

Ã

P(Di ) = lim P
n→∞

i=1

n
[

i=1

!
Di

= lim P(An ).
n→∞

Факт попарной несовместности событий-членов {Di } обоснован в процессе доказательства свойства счётной полуаддитивности.
Для невозрастающей последовательности заметим, что если {Bi } — невозрастающая последовательность, то {Bi } — неубывающая. А поскольку известен простой и очень важный факт о том, что
n
\

Bi ≡

i=1

n
[
i=1

18

Bi ,

то справедливо соотношение
QB = lim Bn =
n→∞

∞
\

∞
[

Bn =

n=1

Bn = lim Bn = QB

n=1

n→∞

Всё это означает, что мы можем с помощью операции отрицания из невозрастающей последовательности событий {Bn } сделать неубывающую {Bn }, а для неё уже
доказано, что
³
´
¡ ¢
P lim Bn = lim P Bn .
n→∞

n→∞

Остаётся провести маневр с отрицанием:
³
´
³
´
³
´
¡ ¢
1 − lim P(Bn ) = lim P Bn = P lim Bn = P lim Bn = 1 − P lim Bn
n→∞

n→∞

³
lim P(Bn ) = P

n→∞

n→∞

lim Bn

n→∞

⇓

´

n→∞

n→∞

теперь уже для невозрастающей последовательности.

Определение 2.14. Невозрастающая последовательность событий {An }
имеет нулевой предел ⇐⇒ lim An = ∅.
n→∞

Замечание. Вместо аксиомы о счётной аддитивности вероятности можно требовать
выполнения конечной аддитивности и непрерывности по неубывающей последовательности либо непрерывности по невозрастающей последовательности или даже по
неубывающей последовательности с нулевым пределом. Поскольку выше мы показали, что из счётной аддитивности можно получить непрерывность по монотонным
последовательностям событий, то доказав ниже обратное (плюс случай невозрастающей последовательности с нулевым пределом) сможем утверждать, что все эти
вещи равносильны.
Утверждение 2.3. Из конечной аддитивности и непрерывности по неубывающей
последовательности следует счётная аддитивность.
Доказательство. Пусть задана бесконечная последовательность событий {Bi },
причём события в ней попарно несовместные. Запишем условие конечной аддитивности:
i, j ∈ N, i 6= j =⇒ Bi Bj = 0 — несовместность
⇓
!
Ãn
n
X
[
P(Bi ) ∀n ∈ N
Bi =
P
i=1

i=1

Построим неубывающую последовательность {An } следующим образом:
An =

n
[

Bi .

i=1

Для этой последовательности работает неперывность и, кроме того,
n
[
i=1

Bi =

n
[

Ai ∀n ∈ N.

i=1

19

Всё, почва для выкладок подготовлена. Выкладки:
Ã∞ !
Ã∞ !
n
∞
´
³
[
[
X
X
P
Bi = P
Ai = P lim An = lim P(An ) = lim
P(Bi ) =
P(Bi ).
i=1

n→∞

i=1

n→∞

n→∞

i=1

i=1

Утверждение 2.4. При наличии конечной аддитивности из непрерывности по
невозрастающей последовательности следует непрерывность по неубывающей последовательности и наоборот.
Доказательство. Тесная связь между этими двумя свойствами уже демонстрировалась. Продемонстрируем её ещё раз несколькими равносильными переходами:
Пусть {Bi } — любая невозрастающая последовательность событий и есть непрерывность по невозрастающей последовательности:
³
´
∀k ∈ N Bk ⊇ Bk+1 , P lim Bn = lim P(Bn );
n→∞

n→∞

Пусть {Ai } — любая неубывающая последовательность. Рассмотрим определние предела для последовательности {Ai }:
lim An =

n→∞

∞
[

Ai =

i=1

∞
\

Ai = lim An

i=1

n→∞

Последовательность {Ai } невозрастает, поэтому для неё бесконечное пересечение —
это и есть предел, а для невозрастающей последовательности есть непрерывность
Ã∞ !
Ã∞ !
\
\
¡ ¢
Ai = 1 − P
Ai = 1 − lim P An .
P
i=1

i=1

n→∞

Всё, остаётся собрать это всё вместе:
Ã∞ !
Ã∞ !
Ã∞ !
³
´
[
\
\
¡ ¢
P lim An = P
Ai = P
Ai = 1 − P
Ai = 1 − lim P An
n→∞

i=1

i=1

¡ ¢
= lim (1 − P An ) = lim P(An ).
n→∞

i=1

n→∞

n→∞

Доказательство в обратную сторону проводится точно так же. Тут все переходы
равносильные, нужно только отрицания иначе расставить. Конечная аддитивность
нужна здесь неявно, чтобы было обоснованным равенство P(A) + P(A) = 1.
Замечание. Последний установленный факт позволяет заявить, что из непрерывности по невозрастающей последовательности событий и конечной аддитивности следует счётная аддитивность.
Замечание. Поскольку из счётной аддитивности следует непрерывность по невозрастающей последовательности, то непрерывность по невозрастающей последовательности с нулевым пределом следует подавно. Осталось доказать обратное.
Утверждение 2.5. Из конечной аддитивности и непрерывности по невозрастающей последовательности событий с нулевым пределом следует счётная аддитивность.

20

Доказательство. Пусть есть бесконечная последовательность событий {Ai }, и
события-члены попарно несовместны. Событие
∞
[

Ai =

i=1

n
[

∞
[

Ai ∪

i=1

Ai ∀n ∈ N

i=n+1

разбили на два события, тоже несовместных. Дальше воспользуемся конечной аддитивностью вероятности, которая есть по условию:
!
!
Ãn
Ã ∞
Ã∞ !
[
[
[
Ai + P
Ai
P
Ai = P
i=1

i=1

P

Ã∞
[

!
Ai

Ã
−P

i=1

Ã
P

i=n+1

⇓
!

∞
[

Ai

Ã
=P

i=n+1
n
[

!

Ai

=

i=1

n
[

!
Ai

∀n ∈ N,

(A)

i=1
n
X

P(Ai ) ∀n ∈ N,

(B)

i=1

а теперь, воспользовавшись непрерывностью по невозрастающей последовательно∞
P
Ai c нулевым пределом (переход помечен *), получим желанный
сти событий
i=n+1

факт:
P

Ã∞
[
i=1

!
Ai

=P

Ã∞
[

!
Ai

∗

−0=P

Ã∞
[

i=1

!
Ai

i=1

Ã
− lim P
n→∞

∞
[

!
Ai

i=n+1

Ã Ã∞ !
Ã ∞
!!
Ãn
!
[
[
[
A
= lim P
Ai − P
Ai
= lim P
Ai
n→∞

B

= lim

n→∞

i=1
n
X
i=1

P(Ai ) =

i=n+1
∞
X

n→∞

i=1

P(Ai ).

i=1

Так что получается, что если отображение P из σ-алгебры событий F в R, такое
что ∀A ∈ F P(A) > 0, P(Ω) = 1 и P — конечно-аддитивное, то следующие три
свойства эквивалентны:
• P — счётно-аддитивное;
• P — непрерывно по любой монотонной последовательности событий;
• P — непрерывно по невозрастающей последовательности с нулевым пределом.

21

Лекция 3

3.1

Урновые схемы

Далее будут разобраны два важных примера конечных вероятностных пространств.

3.1.1

Выборка с возвращением, биномиальное распределение

Пусть имеется урна, в которой находится mw > 0 белых шаров и mb > 0 чёрных,
m = mw +mb . Причём урна не простая, а особенная: всякий раз, как из неё берут шар,
что-то с ним делают и кладут обратно, в ней происходит процесс, обеспечивающий
независимость того, какой шар вынут, от того, какой вынули (и вернули обратно) в
любой момент до этого.
Пусть экспериментатор берёт из этой урны один шар, каким-то образом фиксирует его цвет и кладёт обратно. Пусть это действо происходит n раз. Требуется
выяснить, какова вероятность того, что белый цвет экспериментатор зафиксирует k
раз.
Представим себе все возможные результаты эксперимента как 2n возможных цепочек результатов (длины n, как легко видеть). В каждой позиции цепочки может
стоять либо «Ч», либо «Б», символизирующие соответствующие цвета. Так вот взять
все эти цепочки, среди них выделить те, в которых белый шар попался нужное число
раз, посчитать их, поделить это на 2n и выдать за ответ — заведомо неправильно.
При таком ходе мыслей неявно используем классическую вероятность, а для её применения требуется равновозможность элементарных исходов. А цепочки результатов
могут быть неравновозможными (нигде ведь не сказано, что mb = mw ).
Сделаем все шары уникальными. Проще всего их для этого перенумеровать числами от одного до n. Теперь цепочки, характеризующие результат вытаскиваний
шариков, состоят из чисел. Номеров, попавших на белые шары — mw штук, на чёрные шары попадёт mb номеров.
Всего цепочек теперь mn . Есть n позиций, в каждой из которых может находиться
любое из m чисел. Теперь цепочки равновероятны! У всех шаров шанс оказаться
снаружи урны один и тот же. Вероятность любой конкретной цепочки равна 1/mn .
Пересчитаем цепочки, в которых на первых k позициях оказались числа с белых
шаров, а на оставшихся — числа с чёрных шаров. На каждой из k «белых» позиций
может стоять любое из mw чисел, точно так же, на каждой из n−k «чёрных» позиций
может стоять любое из mb чисел. Значит, таких цепочек всего mkw mbn−k .
Теперь заметим, что цепочек, в которых просто (безо всякого порядка) k позиций
с «белыми» номерами и n − k позиций с «чёрными» номерами ровно столько же,
сколько цепочек, где k первых номеров — «белые», а оставшиеся — чёрные. Как
там между собой расположены «белые» и «чёрные» позиции, совершенно неважно.
Важно количество!
Остаётся выяснить, сколькими различными способами можно из n позиций выбрать k «белых» (всё равно, что выбрать n − k «чёрных»). Как известно, ответ на

22

этот вопрос даётся формулой
n!
= Cnk .
k!(n − k)!
Просто число сочетаний из n по k.
Теперь осталось вспомнить, что всего у нас исходов — mn штук. Из них нашему
событию подходит Cnk mkw mn−k
. Классическую вероятность можно смело применять,
b
так что в итоге имеем
P(Белых — ровно k штук) =

n−k
k
k mw mb
Cn
n

m

=

³
´k ³
mbn−k
mw ´n−k
k mw
= Cn
1−
m mn−k
m
m

k
k mw
Cn k

Теперь обозначим mw /m за p, P(Белых — ровно k штук) как pk и получим выражение
pk = Cnk pk (1 − p)n−k , 0 6 k 6 n.
Определение 3.1. Набор вероятностей (p0 , p1 , . . . , pn ) называется геометрическим распределением с параметрами n и p.

3.1.2

Выборка без возвращения, гипергеометрическое распределение

Пусть теперь экспериментатор просто выбирает из урны n шаров, не возвращая их
на место. Спрашивается, какова вероятность вытащить ровно k белых шаров, причём
считается, что в урне шаров нужного цвета хватит.
Как это ни печально, но если вновь попытаться представить исходы эксперимента
как цепочки из «Ч» и «Б», то ничего вновь не получится. Ситуация осложняется ещё
и тем, что не вссякую цепочку, вообще говоря, удастся получить. Если в прошлом
эксперименте шары возвращались в урну и их всегда хватало, то в этот раз шаров
нужного цвета ещё и не хватить может. Так что тут этот подход не годится ещё и
потому, что его использование грозит излишними трудностями.
Снова перенумеруем все шары и рассмотрим все цепочки длины n из чисел, которые могут получиться в результате эксперимента. Пусть всего шаров снова m, при
этом m > n, иначе задача исчезает. Пусть из этих m шаров опять mw > 0 белых и
mb > 0 чёрных. Опять же, mw > k, иначе задача вновь исчезнет.
Посчитаем все возможные цепочки: на первом месте может стоять m чисел, на
втором — уже m − 1. На j-том месте — m− j + 1. Поскольку n-тое место — последнее,
то последним в этом произведении окажется число m − n + 1. Итого в пространстве
равновероятных элементарных исходов насчитывается
kΩk = m · (m − 1) · . . . · (m − n + 1) =

m!
исходов.
(m − n)!

Теперь зафиксируем позиции для белых шаров в цепочке, для первого места из
«белых» имеется mw возможностей, для второго — mw − 1. Для k-го получается
mw − k + 1, на этом числе произведение остановится. Однако, осталось ещё n − k
чёрных мест. Точно таким же образом получаем, что для фиксированных позиций
получается вариантов
mw · (mw − 1) · . . . · (mw − k + 1) · mb · (mb − 1) · . . . · (mb − (n − k) + 1) вариантов.

23

При этом выбрать k «белых» позиций можно по-прежнему Cnk способами. Теперь
остаётся собрать все формулы в одну. Обозначим вероятность того, что белых шаров
выпало ровно k штук как pk . Получаем
mw · (mw − 1) · . . . · (mw − k + 1) · mb · (mb − 1) · . . . · (mb − (n − k) + 1)
m!
(m − n)!
mw !
mw !
mb !
mb !
n!
n−k
k
Cm
(mw − k)! (mb − n + k)!
k!(mw − k)! (n − k)!(mb − n + k)! Cm
w
b
=
=
=
n
Cm
m!
m!
k!(n − k)!
(m − n)!
n!(m − n)!
n−k
k
C Cm−m
= mw n w .
Cm

pk = Cnk

Нельзя забывать, что k 6 mw и k 6 n. Однако при этих условиях может оказаться,
что n − k > mb , то есть надо вытащить чёрных шаров больше, чем их вообще есть
в урне. Поэтому для k получаем две границы: снизу max(0, n − m + mw ) и сверху
min(mw , n).
Определение 3.2. Набор вероятностей (pt , pt+1 , . . . , pl ), где l = min(mw , n) и t =
max(0, n − m + mw ), называется гипергеометрическим распределением с параметрами n,m и mw .

3.2

Условная вероятность

Пусть у нас имеется два события A и B. Пусть событие B вдруг произошло. И тут
потребовалось определить вероятность A! Та вероятность, что мы вычислим при
уже произошедшем B, называется условной вероятностью.
Пример. Экспериментатор подбрасывает монету дважды. Событие A — за эти два
броска выпал хотя бы один герб. Событие B — выпала хотя бы раз решка. Точно
известно, что B произойдёт. Требуется выяснить, чему при таком раскладе равна
P(A). Монетка правильная.
Решение. Поскольку точно известно, что за два подбрасывания решка хоть раз
да появится, то элементарных исходов, среди которых нужно искать событие A,
остаётся три: РГ, РР, ГР. Они равновероятны. Событие A из этих исходов содержит
два. Получаем, пользуясь подходом классической вероятности, что P(A) = 2/3.
Сама по себе вероятность A (кстати, всё равно что условная относительно Ω
вероятность) равна 3/4, как и вероятность B. Вероятность события AB равна 1/2.
Возможно, это не просто так случилось, что условная вероятность P(A|B) оказалась
равной P(AB)/ P(B).
Определение 3.3. Условной вероятностью происхождения события A при
уже произошедшем (при условии) B (обязательно P(B) > 0) называется величина
P(AB)
= P(A|B) — это её обозначение.
P(B)
Замечание. Эта формула не используется практически никогда. Используется ценное следствие: P(AB) = P(A|B) P(B) = P(B|A) P(A), которое имеет некий смысл,
если потребовать P(A) 6= 0 6= P(B).
24

Определение 3.4. События A и B независимы ⇐⇒ P(AB) = P(A) P(B).
Замечание. Связь со здравым смыслом и наглядностью, кажется, на этом утеряна. Но, если приглядеться, она есть. Посмотрим, что даёт формула для условной
вероятности при независимых событиях:
P(A|B) =

P(AB)
P(A) P(B)
=
= P(A), P(B) 6= 0, P(A) 6= 0.
P(B)
P(B)

Произошло событие B или не произошло — вероятность события A от этого никак
не меняется. То есть, не зависит от события B. Точно так же всё это правильно для
независимости вероятности события B от того, что там происходит с событием A:
P(B|A) =

P(AB)
P(A) P(B)
=
= P(B).
P(A)
P(A)

Наглядного смысла можно попробовать найти здесь.
Замечание. Событие с нулевой вероятностью независимо с любым другим событием:
AB ⊆ B =⇒ P(AB) 6 P(B), P(B) = 0
⇓
P(AB) 6 P(B) = 0 =⇒ P(AB) = 0 = P(B) = P(B) P(A).
Утверждение 3.1. События A и B независимы =⇒ A и B независимы.
Доказательство. Вспомним, что A = AB ∪ AB, причём пересечение их пустое:
AB ∩ AB = A ∩ A ∩ (B ∩ B) = A ∩ ∅ = ∅. Так что мы разложили событие в два
несовместных. Поэтому P(A) = P(AB) + P(AB), а тогда P(A) − P(AB) = P(AB).
Теперь прямо показываем независимость:
P(A) P(B) = P(A)(1 − P(B)) = P(A) − P(A) P(B) = P(A) − P(AB) = P(AB).
Замечание. Событие с вероятностью единица независимо с любым другим событием. Просто возьмём его отрицание и получим событие с вероятностью ноль. Оно
независимо с любым другим, а значит, независимо с любым другим и его отрицание.
Пример. Пусть есть урна с N перенумерованных шаров (числами от 1 до N ). Из неё
выбирается шар и фиксируется его номер, причём у всех шаров шансов оказаться
снаружи поровну. Первый игрок ставит на множество A, второй — на множество B
(A, B ⊂ {1, . . . , N }) чисел, пытаясь тем самым угадать номер шара, оказавшегося
снаружи урны. Вопрос в том, всегда ли существуют A и B, такие что события «номер
шара оказался в A» и «номер шара оказался в B» независимы. Примеры в духе
A = ∅ или A = {1, . . . , N } интереса не представляют.
Решение. Требуется отыскать подмножества Ω = {1, . . . , N }, непустые и не равные
Ω, A и B, такие что P(AB) = P(A) P(B). Поскольку все элементарные исходы тут
равновозможны, пользуемся подходом классической вероятности:
P(A) =

kBk
kAkkBk
kAk
, P(B) =
, P(A) P(B) =
.
N
N
N2

Рассмотрим два случая: N — простое и N — составное.
25

В первом случае в знаменателе P(AB) обязательно будет N , в числителе — число
от нуля до N − 1 (в силу того, что kAk < N ). Знаменатель простой и никаких общих
делителей с числителем не имеет, дробь несократима. А вот в знаменателе P(A) P(B)
окажется N 2 , в числителе — произведение чисел, никаких общих делителей с N
вновь не имеющих. Дробь опять несократима. Так что ни при каких A и B добиться
равенства P(AB) = P(A) P(B) не удастся.
Во втором случае N составное, значит, его можно разложить на два множителя,
каждый из которых не меньше двух.
N = a · b, a, b ∈ N; a, b > 2 =⇒ min(a, b) > 2; a + b 6 2 · max(a, b) 6 ab
Разобьём всё множество N на два, одно — из a элементов (его обозначим A), второе — из b элементов (обозначим его B). Как показано выше, a + b 6 ab = N . Значит,
можно сделать это так, чтобы множества эти пересекались только в одном элементе.
Более того, делается это неединственным образом (прибавим ко всем числам из A
и B единицу, возьмём остаток от деления на N и затем к тем числам, что получим, прибвавим единицу к каждому — получатся отличные от предыдущих наборы
чисел, так как N > 4 — составное число). Значит, получаем kABk = 1. Теперь
независимость показывается прямо:
P(A) P(B) =

kAk kBk
ab
1
kABk
= 2 =
=
= P(AB).
N N
N
N
N

Пример хорошо иллюстрирует тот факт, что интуитиция в вопросах зависимости
или независимости событий может подвести. Вообще, ей не следует злоупотреблять
в этом курсе.
Замечание. Если два несовместных события независимы, то у одного из них нулевая вероятность: 0 = P(AB) = P(A) P(B). Если два события несовместны и имеют
ненулевые вероятности, то они зависимы. Это согласуется с наглядным представлением о зависимости: если уж одно из событий «запрещает» другое, то вероятностная
связь между ними есть, а значит, они зависимы.
Утверждение 3.2. Пусть (Ω, F, P) — вероятностное пространство и B — любое
событие с ненулевой вероятностью. Тогда (Ω, F, PB ) — вероятностное пространство, где PB (A) = P(A|B) ∀A ∈ F .
Доказательство. Поскольку изменения коснулись из всей тройки только вероятности, то надо только для неё доказать присутствие трёх свойств:
1. PB (A) = P(AB)/ P(B) > 0 — неотрицательность есть;
2. PB (Ω) = P(B ∩ Ω)/ P(B) = P(B)/ P(B) = 1 — нормировка присутствует;
3. счётная аддитивность тоже на месте:
A1 , A2 , A3 , . . . ∈ F, ∀i, j ∈ N, i 6= j Ai Aj = ∅, BAi ∩ BAj = B ∩ Ai Aj = ∅
Ã∞ !
Ã
!
Ã∞
!
∞
∞
[
[
[
1
1
1 X
PB
Ai =
P B∩
Ai =
P
BAi =
P(BAi )
P(B)
P(B)
P(B) i=1
i=1
i=1
i=1
=

∞
X
P(BAi )
i=1

P(B)

=

∞
X

PB (Ai ).

i=1

26

3.3

Независимость множества событий

Определение 3.5. Пусть имеется конечное или счётное множество событий
A = {Ai }. События Ai называются независимыми или независимыми в совокупности
m
Для любого конечного подмножества B ⊆ A выполнено
\
Y
P(
Ai ) =
P(Ai ).
i : Ai ∈B

i : Ai ∈B

Определение 3.6. Пусть имеется конечное или счётное множество событий
A = {Ai }. События Ai называются попарно независимыми
m
∀i, j : i 6= j P(Ai Aj ) = P(Ai ) P(Aj )
В случае, когда событий всего два, независимость в совокупности и попарно —
это одно и то же. В случае большего количества событий это неправильно. Это
иллюстрируется примером Бернштейна.

3.3.1

Пример Бернштейна

Представим тетраэдр, у которого одна грань покрашена в красный цвет, вторая — в
зелёный, третья — в синий, а четвёртая содержит рисунок, на котором присутствуют
все три цвета одновременно (лучше без смешивания, в полосочку). Тетраэдр подбросим и зафиксируем цвета, присутствующие на грани, на которую он упал. Событие
R состоит в том, что на нижней грани присутствует красный, событие G — в том,
что присутствует зелёный, событие B — в том, что там есть синий.
Потребуем от тетраэдра, чтобы падения на любую из четырёх граней были равновероятными. Посчитаем вероятности событий RG, GB, RB и RGB:
P(RG) =

kRGk
1
kGBk
1
1
kRGBk
1
= , P(GB) =
= , P(RB) = , P(RGB) =
= .
4
4
4
4
4
4
4

Теперь соответствующие произведения вероятностей:
P(R) P(G) =

kRk kGk
2 2
1
= · = , P(G) P(B) =
4 4
4 4
4
1 1
P(R) P(G) P(B) = · ·
2 2

1
1
, P(R) P(B) = аналогично;
4
4
1
1
= .
2
8

Как видно, события R, G и B попарно независимы, но вот P(R) P(G) P(B) 6= P(RGB).
Тем самым пример демонстрирует, что попарная независимость и независимость
в совокупности — это не одно и то же. Но, разумеется, попарная независимость
следует из независимости случайных величин в совокупности. Далее независимость
событий возникнет при построении понятия независимости случайных величин (на
с.33 и ??). Пока придётся его оставить.

27

3.4

Формула полной вероятности

Пусть есть 2 студента, которые на момент начала экзамена знают 20 из 25 билетов,
причём одни и те же. Требуется установить, у кого больше шансы вытянуть «счастливый» билет (один из 20 выученных): у первого или у второго. У всех билетов
шансы оказаться в руках студента одинаковые.
Вероятность вытянуть «счастливый» билет для первого считается очень просто:
P(счастливый) = 20/25 = 4/5. Со вторым сложней: если первому повезло, то для
второго «счастливых» билетов останется 19 из 24, а если первому не повезло — 20
из 24. Вопрос легко решается с помощью формулы полной вероятности.
Определение 3.7. Множество событий (конечное или счётное) Q = {Ei } называется разбиением пространства элементарных исходовSΩ ⇐⇒ события из Q
попарно несовместны, имеют ненулевые вероятности и
Ei = Ω.
i :Ei ∈Q

Утверждение 3.3 (Формула полной вероятности). Пусть Q — разбиение Ω,
тогда для любого события A
X
P(A) =
P(Ei ) P(A|Ei ).
i :Ei ∈Q

Доказательство. Вспомним, что любое событие A можно представить как объединение по всему разбиению несовместных событий AEi , то есть
[
[
AEi = A Ei = AΩ = A; ∀i, j : Ei , Ej ∈ Q, i 6= j AEi AEj = AEi Ej = A∅ = ∅.
i :Ei ∈Q

i :Ei ∈Q

Значит, по свойству счётной либо конечной аддитивности вероятности имеем
X
X
P(A) =
P(AEi ) =
P(Ei ) P(A|Ei ).
i :Ei ∈Q

i :Ei ∈Q

Утверждение 3.4 (провокация). В аудиторию вносят урну с двумя шарами,
каждый из которых может быть либо чёрным, либо белым равновероятно и при
вытаскивании одного шара шансы оказаться снаружи у обоих одинаковы
⇓
принесли урну с чёрным и белым шарами.
Доказательство. Доказательство опирается на тот факт, что если в урне имеется
три шара, каждый из которых имеет те же шансы оказаться снаружи, что и другие,
и P(вытащили белый шар) = 2/3, то в ней два белых и один чёрный шар. Легко
доказывается от противного.
В той урне, что принесли в аудиторию, может быть два чёрных шара — обозначим это событие как E1 , P(E1 ) = 1/4, там может быть два белых шара — событие
E3 , P(E3 ) = 1/4 и могут быть чёрный и белый шары — событие E2 , P(E2 ) = 1/2.
События E1 , E2 , E3 образуют разбиение пространства элементарных исходов Ω =
{ЧЧ,ЧБ,БЧ,ББ}.
Теперь возьмём эту урну, забросим в неё белый шар и осуществим процесс, в
результате которого при вытаскивании одного шара шансы каждого из трёх шаров
оказаться снаружи станут равными. Посчитаем, чему равна вероятность вытащить
белый шар:
P(Б) =

3
X
i=1

P(Ei ) P(Б|Ei ) =

1 2 1 1
3+4+1
2
1
·1+ · + · =
=
4
2 3 4 3
12
3

28

Мы получили, что для урны с тремя равноправными шарами вероятность вытащить белый равна 2/3, значит, в ней два белых шара и один чёрный. А поскольку
один белый мы туда подложили, то изначально там были два шара разных цветов.
Утверждение доказано.
Замечание. Утверждение неверное, это очевидно. Для этого достаточно подложить
в урну два чёрных шара и осуществить процесс, в результате которого шансы обоих
шаров оказаться снаружи сравняются при вытаскивании одного. Значит, доказательство тоже неправильное. И вот почему.
Неверен переход от «вероятность вытащить белый равна 2/3» к «в ней два белых
шара и один чёрный». Тонкость в том, что формула полной вероятности учитывает
урны со всеми возможными комбинациями сразу с соответствующими вероятностями. Можно представить себе ряд из урн, в которых реализованы все возможные
комбинации шаров. Теперь положим во все из них по белому шару. Как из всех этих
урн выбрать ту, из которой будет выбираться в итоге шар?
Формула полной вероятности смешивает их все в одну, учитывая вероятности
комбинаций шаров внутри них, а затем из этой «средней» урны тянет шар. Кстати,
«средней» урной оказалась урна с чёрным и белым шарами. Здесь урна — средняя,
составленная из всех возможных.
А тот, кто вносит урну в аудиторию, — не формула полной вероятности. Он выбрал какую-то одну, с конкретной комбинацией шаров. И совершенно необязательно
ему попадётся «средняя». Тут она — конкретная, фиксированная урна.
Мы получили результат P(Б) = 2/3, но для «средней» урны, а вывод сделали
так, будто она конкретная и фиксированная.
Можно изменить условие утверждения: потребовать, чтобы в урнах были два
шара одного цвета — белого или чёрного, равновероятные варианты. В этом случае
ход мыслей доказательства приводит к тому же «принесли урну с чёрным и белым
шарами». Тут ярче видно, что происходит при использовании формулы полной вероятности.
Нельзя вот так взять и подменить реальную конкретную урну средней! И в
любых других задачах подмена чего-либо на среднее недопустима (конечно, если
нет тому обоснования), потому что обязательно приведёт к неверному результату. И
хорошо ещё, если этот неверный результат удаётся так легко обнаружить.

3.5

Формула Байеса

Несложные преобразования формулы условной вероятности в комбинации с формулой полной вероятности позволяют получить формулу Байеса:
Утверждение 3.5 (Формула Байеса). Пусть Q — разбиение Ω, A — некоторое
событие, P(A) > 0. Тогда ∀i : Ei ∈ Q
P(Ei ) P(A|Ei )
P(Ei |A) = P
P(Ei ) P(A|Ei )
i :Ei ∈Q

Доказательство.
P(Ei |A) =

P(Ei ) P(A|Ei )
P(AEi )
=P
.
P(A)
P(Ei ) P(A|Ei )
i :Ei ∈Q

29

Числитель расписан по определению условной вероятности, знаменатель — по формуле полной вероятности.
Определение 3.8. В формуле Байеса вероятности {P(Ei )} называются априорными, до наcтупления события A, обычно они известны заранее. Вероятности
{P(Ei |A)} называются апостериорными, после наступления события A, заранее
обычно неизвестны.
Замечание. Рассмотрим процесс признания человека страдающим либо не страдающим от редкой болезни. Пусть событие H состоит в том, что человек от данной
болезни не страдает, S состоит в том, что человек ею болен, P — в том, что его
признали носителем этого заболевания и D — в том, что не признали таковым. Проблема начинается с того, что множества H и D не совпадают. А выливается в то,
что для редких болезней P(H|P ) получается большим. Иллюстрируется это нехитро: просто применим формулу Байеса. Поскольку болезнь редкая, то P(S) обозначим
для наглядности как ε — очень маленькое число, тогда P(H) = 1 − ε и
P(H|P ) =

(1 − ε) P(P |H)
=
(1 − ε) P(P |H) + ε P(P |S)

1

.
ε
P(P |S)
·
1+
1 − ε P(P |H)

Конечно, если страшно мало P(P |H), то P(H|P ) не окажется таким уж большим и
P(S|P ) таким уж малым, однако положим ε = 10−6 , P(P |S) = 0.999999 и P(P |H) =
10−5 , выйдет P(H|P ) = 0.(90) > 0.9. В реальной жизни попадаются редкие болезни
с P(H|P ) > 0.9. Кстати, вероятность того, что признанный здоровым болен, выражается следующим образом:
P(S|D) =

ε P(D|S)
=
(1 − ε) P(D|H) + ε P(D|S)

1
.
1 − ε P(D|H)
1+
·
ε
P(D|S)

Производит впечатление маленькой величины. Просто взять предел при ε → 0 и
посмотреть, где получается ноль, а где один, нельзя, потому что величины P(D|H),
P(D|S), P(P |H) и P(P |S) в общем случае зависят от ε. Но вид формул показателен.
Роковую роль играет отношение вероятности быть больным к вероятности ошибки
P(P |H). Если P(P |H) не превышает ε, то, скорее всего, окажется P(H|P ) > 0.5.

3.6

Дискретные случайные величины, индикаторы
событий

Определение случайной величины короткое и простое. Пусть задано пространство
элементарных исходов Ω, пока ещё коечное либо счётное:
Определение 3.9. Случайная величина — измеримое относительно σ-алгебры
событий отображение из Ω в R.
Замечание. Слово «измеримое» пока не комментируется, потому что в случае конечных или счётных пространств элементарных исходов любое отображение из Ω в
R "измеримо". Это связано с тем, что σ-алгебру событий можно в данном случае
брать как множество всех подмножеств Ω. О том, что происходит, если Ω может
оказаться мощности континуум можно почитать на с.60.
30

Замечание. Вообще, если Ω — не более, чем счётное и имеется несколько случайных
величин, то можно строить на их базе какие угодно функции (лишь бы соблюдались
области определения). Всё равно получится случайная величина. Это обстоятельство
неявно используется в разговоре о мат. ожидании, дисперсии и других моментах
случайных величин. Там правомерность сложения случайных величин, возведения
в степень и смещения на константу считается обоснованной в этом замечании.
Самое простое отображение — это константа. Чем бы ни было Ω, константа —
случайная величина.
Определение 3.10. Случайная величина называется дискретной, если она принимает не больше счётного числа значений.
При наших условиях на Ω в области определения случайной величины есть только счётное количество элементарных исходов, так что она неминуемо дискретная.
Можно это размышление для яркости провести от обратного.
Определение 3.11. Пусть задано множество A ⊆ Ω. Индикатором IA множества A называется следующая случайная величина:
(
1, если ω ∈ A,
IA (ω) =
0, если ω ∈
/ A.
Замечание. Индикатор множества — не всегда случайная величина. Но если множество является событием, то индикатор случайной величиной обязательно будет.
Отсюда видно, между прочим, что отображение, принимающее два разных значения, уже может не быть случайной величиной.
С помощью индикаторов можно любую дискретную случайную величину X представить с помощью ряда. Пусть имеется разбиение Ω {Ai }, то есть множество попарно несовместных непустых событий (счётное или конечное), объединение которых
даёт Ω. Тогда ряд (индексы приведены для счётного разбиения)
∞
X

xi IAi (ω)

i=1

является дискретной случайной величиной. В силу того, что события из разбиения
попарно несовместны, при любом ω во всём ряду все индикаторы кроме одного обратятся в ноль. Так что больше чем счётное количество значений ряд не примет.
В случае не более чем счётного Ω любую дискретную случайную величину можно
разложить в такой ряд, просто взяв как разбиение события, состоящие из одного
элементарного исхода, а как xi — значения X на соответствующих событиях. В случае более мощного Ω надо брать прообразы множеств {xi }. В силу того, что X —
случайная величина, они будут событиями, но об этом позже (на с.58).
Определение 3.12. Распределением или распределением вероятности дискретной случайной величины X называется совокупность её значений x1 , x2 , . . . с
соответствующим набором вероятностей pi = P(X = xi ).
Замечание. Иногда можно считать, что случайная величина принимает ещё континуум каких-нибудь значений, но только с вероятностью ноль. Тогда в определении
говорят «совокупность её возможных значений», выбрасывая те, что принимаются с
нулевой вероятностью. Строго говоря, проделывая такой манёвр, мы подменяем пространство элементарных исходов, так что не следует этим злоупотреблять. Потерь
строгости лучше избегать.
31

Пример. Пусть осуществляется выбор шаров двух цветов (разных, если угодно) из
урны по схеме с возвращением, вероятность вытащить шар цвета 1 равна p. Пусть
X — это количество шаров первого цвета 1 в цепочке таких экспериментов, длина
которой равна n. Каким бы пространством элементарных исходов ни описывался эксперимент (шары ведь можно занумеровать, что и проделывалось на с.21), оно будет
конечным (если оно вменяемое). Так что тут отображение X — случайная величина, дискретная. Распределение дискретной случайной величины удобно представить
таблицей:
P(X = k) = Cnk pk (1 − p)n−k ;

0 1 ... n
— распределение X.
p0 p1 . . . pn

Замечание. Случайные величины, имеющие одинаковые распределение, могут оказаться совершенно непохожими друг на друга. Простой пример — два «противоположных» индикатора, характеризующие результат подбрасывания правильной монетки: индикатор герба и индикатор решки. Пример посложнее: пусть Ω — это целые
числа от нуля до девяти, исходы равновозможны. Одна случайная величина — это
X(ω) = sin(ω/3), вторая — Y , полученная из X простой перестановкой порядка следования точек. Получится другая случайная величина с тем же распределением.
Слева на рисунке изображена X, дальше — разные варианты Y :
.
Все четыре случайных величины распределены одинаково, но выглядят совершенно
по-разному. А вообще, эти десять точек можно переставить 10! способами, при этом
будет много случайных величин, не равных как функции ни в одной точке.

3.7

Схема Бернулли

Пусть имеется некоторый эксперимент, при проведении которого событие A наступает либо не наступает, обозначим p = P(A). При неизменных условиях эксперимент проводится n раз. Пространство элементарных исходов принимает вид
Ω = {ε1 , ε2 , . . . , εn }, где каждый из εi , i ∈ Z, 1 6 i 6 n может быть либо нулём, если
событие A в i-том эксперименте не наступило, либо единицей, в противном случае. Причём если p 6= 1/2, то равновозможности элементарных исходов нет. Такие
эксперименты с двумя возможными результатами называются ещё испытаниями
Бернулли. Причём обязательно подразумевается их независимость друг от друга,
если специально не оговорено что-нибудь другое.
В качестве σ-алгебры можно брать множество всех подмножеств Ω. Вероятность
полностью определяется, если задать её для всех событий, состоящих из одного элементарного исхода, что делается следующим образом:
n
P

εi

n−

P({ω}) = pi=1 (1 − p)

n
P

εi

i=1

, где ω = (ε1 , ε2 , . . . , εn ) — набор из нулей и единиц.

Объясняется это следующим образом. Пусть цепочка фиксированная, то есть жёстко заданы позиции, на которых нужен ноль и так же жёстко заданы позиции под
единицы. Независимо от номера позиции в цепочке (эксперименты ведь проводятся
при одинаковых условиях) вероятность того, что в ней оказалась единица, равна
p, а вероятность того, что ноль — 1 − p. Эксперименты между собой независимы в
совокупности — значит, вероятность пересечения событий, состоящих в том, что на
конкретных позициях стоят нужные цифры, равна произведению этих вероятностей.
32

То есть, вероятность конкретной цепочки с k единицами и n − k нулями получается
равной pk (1 − p)n−k . Между прочим, она не зависит от того, на каких конкретно
позициях какие цифры стоят.
Определение 3.13. Вероятностное пространство, отвечающее модели из n одинаковых независимых испытаний, дающих два результата («успех» с вероятностью p и «неуспех» с вероятностью 1 − p), называется схемой Бернулли.
Пусть X — это количество наступлений события A в n испытаниях, случайная
величина.
Пусть событие Ai состоит в том, что на i-том шаге A наступило. Тогда X можно
представить в виде суммы индикаторов Ai :
X=

n
X

IAi .

i=1

Эксперименты между собой полностью независимы, тогда события {Ai } независимы в совокупности. Вероятность того, что IAi = 1 равна вероятности того, что Ai
произошло, то есть p. Опираясь на эти соображения, можно отыскать распределение
случайной величины X: всё почти так же, как и в урновой схеме с возвращением,
правда, теперь p может оказаться иррациональным.
Разных цепочек длины n с k единиц и n − k нулей можно составить, как известно
k
Cn штук (всё равно что Cnn−k ). Цепочки с единицами в разных наборах позиций общих между собой не имеют. Поэтому соответствующие им события не пересекаются
и вероятность их объединения равна сумме их вероятностей. То есть, вероятность
того, что в результате n экспериментов произошло k удач и n − k неудач равна
Cnk pk (1 − p)n−k . Возвращаемся к случайной величине X:
0
1
...
n−1
n
— распределение X — биномиальное.
(1 − p)n np(1 − p)n−1 . . . npn−1 (1 − p) pn
Везде в моделях из n независимых одинаковых экспериментов с вероятностью «успеха» p случайная величина, равная общему количеству «успехов» за эти n экспериментов, будет иметь биномиальное с параметрами n и p распределение.
Немного позже выяснится, что среднее X/n равно p (на с.39) и что при n → ∞
X/n к нему стремится (на с.47). Так что, имея на руках много испытаний Бернулли,
можно оценивать вероятность «успеха» в одном испытании.

33

Лекция 4

4.1

Независимость дискретных случайных величин,
теорема о независимости двух функций от непересекающихся совокупностей независимых дискретных случайных величин

В продолжение разговора о независимости событий (который шёл на с. 26) речь
пойдёт о независимости случайных величин, пока дискретных.
Пусть задано вероятностное пространство (Ω,F ,P) и на нём все упоминаемые
ниже случайные величины.
Определение 4.1. Пусть имеется конечный либо счётный набор случайных величин {Xi }. Случайные величины {Xi } независимы или независимы в совокупности
m
Для любого набора вещественных чисел {xij } независимы события {ω : Xi = xij }.
Снова попарная независимость нескольких случайных величин и их независимость в совокупности — в общем случае не одно и то же. Достаточно взять пример
Бернштейна и добавить в него три соответствующих случайных величины.
Замечание. Пусть имеется случайная величина X. Спрашивается, при каких условиях случайные величины из набора {X, X} независимы.
Должны быть независимыми события {X = xi } при любых xi . Пусть для X
имеется два различных значения xi и xj , причём P(X = xi ) 6= 0. Тогда должны
выполняться равенства:
0 = P(∅) = P({X = xi } ∩ {X = xj }) = P(X = xi ) P(X = xj ),
P(X = xi ) = P({X = xi } ∩ {X = xi }) = P(X = xi )2 .
Так что одно своё значение эта случайная величина принимает с вероятностью один,
а остальные — с вероятностью ноль. Тогда, во-первых, любое количество констант
с вероятностью один можно прибавить к независимому набору случайных величин,
и зависимым он от этого не станет. Во-вторых, если имеется набор независимых
случайных величин, в котором есть одинаковые члены, то они — константы с вероятностью один. Вообще, у константы событие A(x) = {ω : C = x} будет либо пустым,
либо равным Ω. Поэтому константа с вероятностью один никогда и ни от кого не
зависит в силу того, что ∅ и Ω всегда независимы с любым событием.
Теорема 4.1. Пусть X1 , X2 , . . . , Xk и Y1 , Y2 , . . . , Yn — независимые случайные величины. Пусть f и g — измеримые функции (с.60), причём f : Rk → R и g : Rn → R.
Тогда случайные величины f (X1 , X2 , . . . , Xk ) и g(Y1 , Y2 , . . . , Yn ) независимы.

34

Замечание. Измеримость нужна для того, чтобы f (X1 , . . . , Xk ) и g(Y1 , . . . , Yn ) были случайными величинами. Опять же, если Ω конечное либо счётное, то любое
отображение из Ω в R измеримо.
Доказательство. Возьмём произвольные вещественные числа a и b. Построим
события A и B следующим образом:
A = {ω : f (X1 (ω), X2 (ω), . . . , Xk (ω)) = a} и B = {ω : g(Y1 (ω), Y2 (ω), . . . , Yn (ω)) = b}.
Нужно показать независимость этих двух событий.
Заметим, что векторы X(ω) и Y (ω) (равные соответственно (X1 (ω), . . . , Xk (ω)) и
(Y1 (ω), . . . , Yn (ω))) составлены из дискретных случайных величин и, следовательно,
принимают не более счётного количества значений. Это значит, что любые подмножества множеств значений этих векторов EX и EY можно представить как счётные
объединения конкретных значений этих векторов. Это используется в выкладках
ниже в переходе ♠.
Пусть теперь D и T — некоторые множества из Rk и Rn соответственно. Покажем,
что события {ω : X(ω) ∈ D} и {ω : Y (ω) ∈ T } независимы:



♠

P(X ∈ D, Y ∈ T ) = P(X ∈ D∩EX , Y ∈ T ∩EY ) = P 

z

=

X

♣

P(X = Di , Y = T i ) =

Di ∈D∩EX
T i ∈T ∩EY



♥

=

X


P({X = Di }) 

Di ∈D∩X

X

[



{X = Di , Y = T i }


Di ∈D∩EX
T i ∈T ∩EY

P(X = Di ) P(Y = T i )

Di ∈D∩EX
T i ∈T ∩EY

X



P({Y = T i })

T i ∈T ∩EY

= P(X ∈ D∩EX ) P(Y ∈ T ∩EY ) = P(X ∈ D) P(Y ∈ T ).
Переход ♣ — это независимость случайных величин X1 , X2 , . . . , Xk и Y1 , Y2 , . . . , Yn .
Переход z — это не что иное, как счётная или конечная аддитивность вероятности.
Как известно, декартово произведение не более, чем счётных множеств не более,
чем счётно, поэтому объединение по множеству Di ∈ D ∩ EX , T i ∈ T ∩ EY — не
более, чем счётное. В ♥ произошла перегруппировка слагаемых. Сумма от этого
не изменится — ряды, из членов которых составлены члены нового ряда, сходятся
абсолютно. Так что полученный ряд тоже абсолютно сходится и суммировать его
можно в любом порядке (факт доказывается в курсе мат. анализа и ещё попадётся
впереди).
Теперь остаётся в качестве множеств D и T взять множества A и B, предварительно заметив, что они представимы в виде
A = {ω : (X1 (ω), X2 (ω), . . . , Xk (ω)) ∈ f −1 (a)},
B = {ω : (Y1 (ω), Y2 (ω), . . . , Yn (ω)) ∈ g −1 (b)}.
Всё, теперь остаётся воспользоваться обоснованным выше фактом и получить:
P(AB) = P(X ∈ f −1 (a), Y ∈ g −1 (b)) = P(X ∈ f −1 (a)) P(Y ∈ g −1 (b)) = P(A) P(B).
35

4.2

Математическое ожидание дискретной случайной величины

Пусть пространство элементарных исходов Ω — не более чем счётное, σ-алгебра
событий F — множество всех подмножеств Ω, P — вероятность, то есть, задано вероятностное пространство (Ω,F ,P), в котором определена случайная величина X(ω).
Определение 4.2. Математическим ожиданием или средним случайной
величины X(ω) называется сумма ряда
X
X(ω) P({ω}),
ω∈Ω

при условии абсолютной его сходимости. Обозначается EX.
Замечание. Абсолютная сходимость понадобится далее в доказательствах некоторых свойств мат. ожидания. Это во-первых. Во-вторых, в каком порядке по Ω надо
суммировать — нигде не указано и в общем случае как-то этот порядок не изобрести.
Так что если ряд из определения сходится условно, то оно попросту некорректно,
потому что по теореме Римана (которая присутствует в курсе мат. анализа) можно
так переставить ω в сумме, что ряд сойдётся к любому наперёд заданному вещественному числу. Ну а абсолютно сходящийся ряд имеет единственный предел, так
что мат. ожидание для каждой случайной величины единственно.

4.2.1

Свойства математического ожидания

1◦ . Мат. ожидание константы ей же и равно. X(ω) = C(константа) =⇒ EX = C.
Доказательство. Потребуется всего-то счётная или конечная аддитивность вероятности для суммирования вероятностей попарно несовместных событий вида {ω}:
Ã
!
X
X
[
EX =
X(ω) P({ω}) = C ·
P({ω}) = C · P
ω = C · P(Ω) = C.
ω∈Ω

ω∈Ω

ω∈Ω

Хотя утверждение само по себе совершенно очевидное: среднее от константы!
Далее возникнет сложение и перемножение случайных величин. Если возникает
вопрос, по какому такому праву произведение и сумма случайных величин является
случайной величиной, его нужно устранить с помощью замечания на с.30.
2◦ . Пусть в нашем вероятностном пространстве имеется две случайных величины X и Y , тогда если мат. ожидание обеих существует, то существует мат.
ожидание их суммы и равно оно сумме их мат. ожиданий. То есть,
∃ EX, ∃ EY =⇒ ∃ E(X + Y ) = EX + EY.
Доказательство. Факт попросту повторяет известное свойство абсолютно сходящихся рядов, а переносить сюда выкладки из математического анализа совершенно
излишне. Так что доказательство очевидно.
3◦ . Умножение на константу из-под знака мат. ожидания можно выносить:
E(C · X) = C · EX.
36

Доказательство. Как известно, из-под знака суммирования для абсолютно сходящегося ряда константу можно вынести.
Замечание. Раз уж умножение на константу и сложение из-под знака мат. ожидания можно выносить, то можно выносить и вычитание.
4◦ . Пусть набор значений (x1 , x2 , . . .) с набором вероятностей (p1 , p2 , . . .) — распределение случайной величины X (здесь везде символы стоят для случая, когда X
имеет бесконечное количество значений, но для конечного случая всё проделывается точно так же). Тогда
EX =

∞
X

xk pk .

k=1

Доказательство. Пусть событие Ai состоит в том, что X приняла значение xi . То
есть, Ai = {ω : X(ω) = xi }. Заметим, что P(Ai ) = pi по определению распределения.
Остаётся провести простое преобразование ряда мат. ожидания:
EX =
=

X
ω∈Ω
∞
X
i=1

∗

X(ω) P(ω) =
xi

X
ω∈Ai

∞ X
X

X(ω) P(ω) =

i=1 ω∈Ai
∞
X

P(ω) =

xi P(ω)

i=1 ω∈Ai

xi P(Ai ) =

i=1

∞ X
X

∞
X

xi pi ,

i=1

помеченный ∗ переход отличен тем, что при нём происходит перегруппировка слагаемых при суммировании. Поскольку ряд сходится абсолютно, на сумму его это
никак не влияет.
Замечание. Особенность и отличие этого свойства от определения в том, что исходное вероятностное пространство бесследно исчезло. Осталось только распределение.
А в определении требуется знать X как функцию ω и P как функцию, заданную
на элементах класса событий. Часто речь будет заходить о случайной величине, её
распределении и мат. ожидании, но ни слова не будет о вероятностном пространстве,
так как распределение случайной величины само по себе может нести достаточное
для задачи количество информации.
Замечание. Мат. ожидание индикатора IA равно вероятности его события P(A):
EIA = 1 · P(A) + 0 · P(A) = P(A).
5◦ . Пусть g : R → R — измеримое отображение (что это значит, объясняется на
с.60). Тогда g(X) — случайная величина и
Eg(X) =

∞
X

g(xi )pi .

i=1

Опять символы стоят такие, будто X имеет бесконечное количество значений и
опять в конечном случае всё точно так же.

37

Доказательство. Доказательство повторяет доказательство предыдущего свойства с незначительными изменениями. Снова вводим события Ai = {ω : X(ω) = xi },
снова P(Ai ) = pi и снова распишем мат. ожидание по определению:
Eg(X) =
=

X
ω∈Ω
∞
X

g(X(ω)) P(ω) =
g(xi )

i=1

∞ X
X

g(X(ω)) P(ω) =

i=1 ω∈Ai
∞
X

X

P(ω) =

ω∈Ai

g(xi ) P(Ai ) =

i=1

∞ X
X

g(xi ) P(ω)

i=1 ω∈Ai
∞
X

g(xi )pi .

i=1

6◦ (Мультипликативность мат. ожидания). Пусть заданы две независимых
случайных величины X и Y , и у обеих существует мат. ожидание. Тогда существует мат. ожидание произведения, равное произведению мат. ожиданий исходных случайных величин:
X, Y — независимы и ∃ EX, ∃ EY =⇒ ∃ E(XY ) = EXEY.
Доказательство. Пусть X принимает значения a1 , a2 , a3 , . . . на исходах ω из событий A1 , A2 , A3 , . . ., а Y — значения b1 , b2 , b3 , . . . на событиях B1 , B2 , B3 , . . .. Далее в
индексах суммирования будет стоять бесконечность, будто X и Y принимают бесконечное количество значений. Для конечного случая всё точно так же — изменения
чисто символические, для случая с континуумом значений все совсем иначе (см.
с.??). Итак:
EXEY =
♠

=

∞
X

ai P(Ai )

i=1
∞
X
i,j=1

∞
X

bj P(Bj ) =

j=1

ai bi P(Ai Bi ) =

∞ X
∞
X

♣

ai P(Ai )bj P(Bj ) =

i=1 j=1
∞
X
X

X(ω)Y (ω) P(ω) =

i,j=1 ω∈Ai Bj

∞ X
∞
X

ai bi P(Ai Bj )

i=1 j=1

X

X(ω)Y (ω) P(ω) = EXY.

ω∈Ω

Переход ♣ — это независимость X и Y . А вот с ♠ сложней: до него суммирование
велось сначала по j, а затем по i, после него порядок произвольный. Так поступать
можно, потому что каждый член нового ряда — это произведение соответствующих
членов двух абсолютно сходящихся рядов. Тогда полученный ряд тоже сходится
абсолютно, и в каком порядке его суммировать — совершенно неважно. В курсе
мат. анализа этот вопрос разобран под заголовком «Элементарная теория двойных
и повторных рядов».
Математическое ожидание — это не то же самое, что медиана, причём разница
очень существенна. Медиана — это значение, слева и справа от которого (на вещественной оси) лежит одинаковое количество значений случайной величины. В США
в 1992 году медиана доходов обладателей работающих домашних хозяйств составила
примерно 31000$, в то время как формула мат. ожидания давала 40000$. 9000$ —
это существенная разница. А вообще, за словом «среднее» может скрываться ещё
что-нибудь.
Итак, смысл мат. ожидания — это среднее случайной величины. На практике это
станет полезным с появлением Закона больших чисел (а точнее, на с.47) плюс его
можно применять как критерий сравнения некоторых сложных объектов. Например,
доходности некоторого финансового инструмента. Учебная (не надо воспринимать
написанное ниже как руководство к действию, нужно ещё много обсудить) ситуация
38

такова: на рисунках имеется два графика — один для цены одного финансового
инструмента, другой — для цены второго, время разбито по месяцам:
Требуется выяснить, какой из них лучше подходит для вложений.
Вводится такая характеристика, как относительная доходность в момент времени
t, обозначается как Dt и определяется так:
Dt =

pt − pt−1
, где pt — цена в момент времени t.
pt−1

Предположим, Dt известна в условные моменты времени t = 0, 5, . . . , 500. Средняя
доходность вычисляется как
D0 + D5 + D10 + . . . + D490 + D495 + D500
.
101
Среди D0 , D5 , . . . , D500 есть одинаковые — сгруппируем их и получим новый набор
значений d0 , d1 , . . . , dk с набором натуральных чисел n0 , n1 , . . . , nk , в котором ni (0 6
i 6 k) — это число вхождений значения di в набор D0 , D5 , . . . , D500 , так что неминуемо
n0 + n1 + . . . + nk = 101. Тогда выражение для средней доходности приводится к
выражению мат. ожидания Dt :
D0 + D5 + . . . + D495 + D500
n0
n1
nk−1
nk
= d0
+ d1
+ . . . + dk−1 +
+ dk
= EDt .
101
101
101
101
101
Хотя и не приведено вероятностное пространство, распределение Dt , которого здесь
вполне достаточно, присутствует: в наборе n0 , n1 , . . . , nk все числа остаётся поделить
на 101 — и получатся соответствующие вероятности.
Дальше выводы о том, какой из финансовых инструментов лучше всех подходит
для вложений, можно делать на основе обычного сравнения между собой вещественных чисел. Например, мат. ожиданий доходностей.

4.2.2

Пример случайной величины, не имеющей мат. ожидания

Пример. Пришло время раскрыть Петербургский Парадокс. Проблема была в том,
что сделать игру справедливой посредством предварительных расчётов между игроками нельзя. И вот почему: посчитаем выигрыш подбрасывающего, который будем
считать случайной величиной S: он получает 2n рублей, если первый герб выпадает на n-том шаге. Элементарных исходов здесь счётное число, вероятность того,
что первый герб выпадет на n-том шаге, равна 2−n . Вероятностное пространство
подробно описано на с.11. Считаем мат. ожидание S:
ES =

X

S(ω) P({ω}) =

∞
X
i=1

ω∈Ω

2n 2−n =

∞
X

1.

i=1

Этот ряд не сходится абсолютно. Строго говоря, мат. ожидания у этой случайной
величины не существует. А вообще, оно кажется невообразимо большим, а точней
его не ограничить никаким положительным числом, как и средний выигрыш подбрасывающего. А поскольку передать перед игрой второму игроку неограниченное
количество рублей для подбрасывающего не представляется возможным, сделать
игру справедливой таким способом нельзя.
Это был пример случайной величины, не имеющей мат. ожидания.
39

4.2.3

Мат. ожидание биномиально распределённой случайной
величины

Пример. Пусть X — случайная величина, имеющая биномиальное распределение
с параметрами n и p. Вычислим мат. ожидание X. Попытка прямого вычисления
приведёт к небольшим трудностям:
EX =

n
X

Cnk kpk (1 − p)n−k =

k=0

=

n
X

k=1

np

k=1

= np

n
X

n
X

n!
pk (1 − p)n−k
(n − k)!(k − 1)!

(n − 1)!
pk−1 (1 − p)(n−1)−(k−1)
((n − 1) − (k − 1))!(k − 1)!
k−1 k−1
Cn−1
p (1 − p)(n−1)−(k−1) = np

n−1
X

m
Cn−1
pm (1 − p)(n−1)−m

m=0

k=1
n−1

= np(p + (1 − p))

= np,

а небольшие трудности всегда приятней обойти. Представим лучше X в виде суммы
индикаторов успехов на i-том шаге. Иными словами, X = I1 + I2 + I3 + . . . + In .
Почему так можно поступить, объясняется на с.32. Мат. ожидание каждого индикатора равно вероятности того, что произошёл «успех», то есть p. Всего индикаторов
n штук и мат. ожидание их суммы равно сумме их мат. ожиданий. Так что легко и
просто получаем
EX =

n
X

EIi =

i=1

4.3

n
X

p = np.

i=1

Моменты и центральные моменты k-го порядка

Определение 4.3. Моментом k-го порядка случайной величины X, k ∈ N,
называется математическое ожидание случайной величины X k .
Определение 4.4. Центральным моментом k-го порядка случайной величины X, где k ∈ N, называется математическое ожидание случайной величины
(X − EX)k .
Если возникает вопрос о том, с чего вдруг X k и (X − EX)k будут случайными
величинами, следует обратиться к замечанию на с.30.
Замечание. Центральный момент первого порядка всегда равен нулю:
E(X − EX) = EX − EEX = EX − EX = 0.
Нередко бывает удобно чтобы на месте мат. ожидания какой-нибудь случайной величины оказался ноль. И тогда случается так, что вместо исходной случайной величины Y в таких случаях рассматривают случайную величину Y − EY , мат. ожидание
которой — ноль. Такой ход называется центрированием, а случайная величина
Y − EY — центрированной.
Утверждение 4.1. Пусть существует момент n-го (n ∈ N) порядка случайной
величины X. Тогда ∀ k ∈ N : k < n существует момент k-го порядка случайной
величины X.
40

Доказательство. Поскольку для существования мат. ожидания ряд (из определения мат. ожидания) должен сходиться абсолютно, то существует E|X|n . Тогда в
силу факта ∀ y ∈ R |y|k 6 |y|n + 1 имеем |X|k 6 |X|n + 1, а это — оценка членов
неотрицательного ряда сверху членами сходящегося. Так что получаем, что мат.
ожидание |X|k тоже существует.

4.4

Дисперсия и её свойства

Определение 4.5. Дисперсией случайной величины X называется её центральный момент второго порядка:
DX = E(X − EX)2 .
Дисперсия характеризует разброс случайной величины X относительно своего
мат. ожидания. Что замечательно, маленькие отклонения возводятся в квадрат и
становятся от того ещё меньше, а большие — наоборот, увеличиваются. В экономических моделях эта конструкция встречается под именем «волатильность».
1◦ . Дисперсия константы равна нулю: DC ≡ 0.
Доказательство.
DC = E(C − EC)2 = EC 2 − 2E(CEC) + E(EC)2 = EC 2 − 2E(C 2 ) + E(C 2 ) = 0.
2◦ . Изменение случайной величины на константу не влияет на её дисперсию:
D(X + C) = DX.
Доказательство.
D(X + C) = E(X + C − E(X + C))2 = E(X − EX + C − EC)2
= E(X − EX + C − C)2 = E(X − EX)2 = DX.
3◦ . Константа выносится из-под знака дисперсии с квадратом:
D(CX) = C 2 DX.
Доказательство.
D(CX) = E(CX − E(CX))2 = E(CX − CEX)2 = E(C(X − EX))2
= E(C 2 (X − EX)2 ) = C 2 E(X − EX) = C 2 DX.
4◦ . Для любой случайной величины X
DX > 0.
Доказательство. Дело в том, что ряд из определения дисперсии абсолютно сходится и состоит из неотрицательных членов.
5◦ . Пусть X и Y — две независимых случайных величины. Тогда если существуют их дисперсии по отдельности, то существует дисперсия суммы, равная сумме
дисперсий по отдельности, то есть
X, Y — независимы и ∃ DX, ∃ DY =⇒ ∃ D(X + Y ) = DX + DY.
41

Доказательство.
D(X + Y ) = E(X + Y − E(X + Y ))2
= E((X − EX)2 + (Y − EY )2 + 2E(X − EX)(Y − EY )).
Поскольку X − EX и Y − EY — измеримые функции от независимых случайных
величин X и Y , то они — сами независимые случайные величины. Тогда
E((X − EX)2 + (Y − EY )2 + 2E(X − EX)(Y − EY )) = DX + DY
+ 2E(X − EX)E(Y − EY )
= DX + DY,
потому что центральный момент первого порядка всегда нулевой. Кстати, в этом
доказательстве не использовалась в явном виде дискретность X и Y , которая скрывается пока что за фактом мультипликативности мат. ожидания. Но когда последний
факт будет доказан для более общего случая случайных величин, это доказательство
аддитивности дисперсии автоматически перейдёт на этот более общий случай.
Следствие 4.1 (Аддитивность дисперсии). Пусть Y1 , Y2 , . . . , Yn — независимые
случайные величины. Тогда если для каждой из них существует дисперсия, то
существует дисперсия их суммы, равная сумме их дисперсий. То есть:
Y1 , Y2 , . . . , Yn — независимы и ∃ DY1 , ∃ DY2 , . . . , ∃ DYn
⇓
∃ D(Y1 + Y2 + . . . + Yn ) = DY1 + DY2 + . . . + DYn .
Доказательство. Доказательство — привычная мат. индукция. База только что
была доказана, предположение имеется в условии следствия, а дальше простой индукционный переход: за X1 надо взять Y1 + Y2 + . . . + Yn , за X2 — Yn+1 . Нужно не
забыть заметить, что X1 и X2 — независимые случайные величины, что у них существуют дисперсии (у X1 — по предположению индукции), и применить для них
базу.
Замечание. В реальных условиях большое количество независимых случайных величин — это ненормально. Как минимум, подозрительно!
Замечание. Часто используется преобразованный вид дисперсии, а именно:
DX = E(X − EX)2 = E(X 2 − 2XEX + (EX)2 ) = E(X 2 ) − 2E(XEX) + E(EX)2
= E(X 2 ) − 2(EX)2 + (EX)2 = EX 2 − (EX)2 .

4.4.1

Дисперсия биномиально распределённой случайной величины

Пример. Вычислим дисперсию случайной величины, имеющей биномиальное распределение с параметрами n и p. Мат. ожидание вычислено на с.39 и равно оно np.
Попытка прямого вычисления дисперсии приводит к более серьёзным трудностям,
которые вновь обходятся с помощью индикаторов. Пусть Ii , 1 6 i 6 n — индикатор успеха в i-том испытании Бернулли, эти n индикаторов независимы (переход ♣)
и одинаково распределены (переход ♠). Заметим, кроме того, что квадрат любого
индикатора всегда точно равен самому индикатору (переход z). Тогда
♣

♠

DX = D(I1 + I2 + . . . + In ) = DI1 + DI2 + . . . + DIn = nDI1
z

= nE(I1 − EI1 )2 = n(EI12 − (EI1 )2 ) = n(EI1 − (EI1 )2 ) = n(p − p2 ).
42

4.4.2

Среднеквадратичное отклонение

Определение 4.6. Среднеквадратичным отклонением называется квадратный корень из дисперсии.
Все свойства среднеквадратичного отклонения вытекают из свойств дисперсии.
Оно нелинейно: константу приходится выносить с модулем, отклонение суммы в
общем случае не равно сумме отклонений. Зато размерность его совпадает с размерностью исходной случайной величины. Нужно это для того, чтобы экспериментатор после проведения измерений мог вычислить величину отклонения и сравнить её
со средней величиной своих результатов. Дальше, получив относительную погрешность, он может принимать решение о том, верить своим результатам или нет.

4.5

Ковариация и коэффициент корреляции

Определение 4.7. Пусть заданы две случайных величины, имеющих мат. ожидание: X и Y . Ковариацией случайных величин X и Y называется число
cov(X, Y ) = E((X − EX)(Y − EY )).
Полезно провести небольшие преобразования выражения в определении:
cov(X, Y ) = E((X − EX)(Y − EY )) = E(XY − Y EX − XEY + EXEY )
= EXY − EY EX − EXEY + EXEY = EXY − EXEY.
Замечание. Ковариация не изменяется при изменении случайных величин на константы:
cov(X + CX , Y + CY ) = E((X + CX )(Y + CY )) − E(X + CX )E(Y + CY )
= E(XY + Y CX + XCY + CX CY ) − E(X + CX )E(Y + CY )
= EXY − EXEY = cov(X, Y ).
Теперь очевидно, что ковариация независимых случайных величин равна нулю.
Обратное, во-первых, почти верно, а во-вторых, в прикладных областях.
Пример. Из равенства нулю ковариации случайных величин не следует их независимость. Пример будет следующий: рассмотрим конечное вероятностное пространство Ω = {0, 1, 2, 3, 4, 5, 6, 7, 8} с равновероятными элементарными исходами. Рассмотрим случайные величины
πω
πω
X = sin( ) и Y = cos( ) :
4
4
Их мат. ожидания равны нулю, выясним мат. ожидание их произведения:
πω
πω
1
πω
1
1
1
1
1
EXY = E(sin( ) cos( )) = E sin( ) = (0 + + 0 − + 0 + + 0 − + 0) = 0
4
4
2
2
18
2
2
2
2
Так что EXY = EXEY и ковариация их равна нулю. Однако события X и Y зависимы: рассмотрим события A и B:
1
1
A = {ω : X = √ }, B = {ω : Y = √ }.
2
2
2
2
4
1
P(A) = , P(B) = =⇒ P(A) P(B) = , но P(AB) = 6= P(A) P(B).
9
9
81
9
Так что равенство нулю ковариации слабее независимости.
43

Дисперсия суммы двух случайных величин в общем случае имеет следующий
вид:
D(X + Y ) = E((X − EX) + (Y − EY ))2 = DX + DY + 2E((X − EX)(Y − EY ))
= DX + DY + 2 cov(X, Y ).
Выражение для большего количества слагаемых получается точно так же — нужно
раскрыть квадрат и собрать нужные слагаемые. Сама дисперсия случайной величины X выражается как cov(X, X).
Раз из независимости случайных величин следует равенство нулю ковариации,
то из неравенства нулю ковариации следует зависимость случайных величин. Это
наводит на мысль о том, что величина ковариации характеризует меру зависимости
случайных величин. Однако от умножения на константу (не равную нулю) зависимость случайных величин не изменяется никак, а вот ковариацию можно сделать
(если она не равна нулю) любым числом, а именно:
cov(CX, Y ) = ECXY − ECXEY = C(EXY − EXEY ) = C cov(X, Y ).
Так что чтобы спасти возникшую мысль, ковариацию необходимо нормировать.
Определение 4.8. Коэффициентом корреляции случайных величин X и Y , имеющих дисперсии, не равные нулю, называется число
cov(X, Y )
ρ(X, Y ) = √
.
DXDY
Замечание. Если дисперсия случайной величины равна нулю, то эта случайная
величина с вероятностью 1 равна своему мат. ожиданию, т.е. является константой с
вероятностью один. Для характеристики независимости случайной величины с такой
константой коэффициент корреляции не нужен. На с.33 всё и без него ясно.
Коэффициент корреляции лучше ковариации тем, что от умножения случайных
величин на константы его модуль не изменяется:
cov(aX, bY )
ab cov(X, Y )
ab
∀ a, b ∈ R : ab 6= 0 ρ(aX, bY ) = √
=
=
ρ(X, Y ).
|ab|DXDY
|ab|
DaXDbY

4.5.1

Свойства коэффициента корреляции

1◦ . Коэффициент корреляции независимых случайных величин равен нулю.
Доказательство. В числителе дроби, которой равен коэффициент корреляции,
окажется ноль. В знаменателе нуля быть не должно, это обеспечивается определением.
2◦ . Для любых двух случайных величин (для которых выполнены условия определения) их коэффициент корреляции по модулю не превосходит единицы.
Доказательство. Обозначим эти две случайные величины как X и Y и центрируем: Xc = X − EX и Yc = Y − EY . Недавно показывалось, что cov(X, Y ) = cov(Xc , Yc ),
а что дисперсия случайной величины не меняется от смещения случайной величины
на константу — ещё раньше (если это уже забыто, то можно вспомнить о факте
DX = cov(X, X) = cov(X + C, X + C) = D(X + C)). Так что центрирование никак
44

не повлияет и на коэффициент корреляции. Понадобятся следующие соотношения,
оба из которых вытекают из того, что EXc = EYc = 0:
DXc = EXc2 − (EXc )2 = EXc2 , DYc = EYc2 , cov(Xc , Yc ) = E(Xc Yc ) − EXc EYc = E(Xc Yc ).
Далее идут те же рассуждения, что часто используются при доказательстве неравенства Коши-Буняковского:
∀ a ∈ R 0 6 D(Xc − aYc ) = E(Xc − aYc )2 − (E(Xc − aYc ))2 = E(Xc − aYc )2 .
Полученное неравенство можно рассматривать как квадратное неравенство относительно a, а именно
E(Xc − aYc )2 = EXc2 − 2aE(Xc Yc ) + a2 EYc2 > 0.
Поскольку верно это для любого a, то дискриминанту нельзя ни в коем случае быть
больше нуля. То есть:
p
p
(E(Xc Yc ))2 − EXc2 EYc2 6 0 ⇐⇒ |E(Xc Yc )| 6 EXc2 EYc2 ⇒ | cov(Xc , Yc )| 6 DXc DYc .
Поскольку стирание индексов c никаких значений в последнем выражении не изменит, то получено то, что сформулировано в условии.
3◦ . Если |ρ(X, Y )| = 1, то с вероятностью один X и Y линейно выражаются друг
через друга. То есть,
|ρ(X, Y )| = 1 =⇒ ∃ b 6= 0, c ∈ R : P(X − bY = c) = 1.
Доказательство. Доказательство этого свойства целиком опирается
на доказа√
тельство предыдущего: если выполнилось равенство | cov(X, Y )| = DXDY , то квадратное неравенство относительно a может обращаться в равенство при некотором
a = b. Но это равенство означает, что равна нулю D(X − bY ), а это сразу говорит о
том, что с вероятностью один X − bY равна константе. Обозначим эту константу за
c и получим то, что нужно было доказать.
Выражаясь нестрого, чем ближе модуль коэффициента корреляции к единице,
тем сильнее зависимость между случайными величинами. Но эта зависимость — не
причинная, это важно понимать. О смысле вероятностной зависимости несколько
слов было сказано на с.24. Если коэффициент корреляции равен нулю, то о независимость случайных величин ещё не гарантирована, но степень зависимости слаба.
Определение 4.9. Случайные величины называются некоррелированными, если
для них существует коэффициент корреляции и равен он нулю.
Для некоррелированных случайных величин дисперсия суммы равна сумме дисперсий — там в доказательстве использовалось соотношение E(XY ) = EXEY безотносительно к его происхождению.

4.6

Неравенство А. А. Маркова

Утверждение 4.2 (Неравенство Маркова). Пусть случайная величина X неотрицательна. Тогда
∀ a > 0 P(X > a) 6

45

EX
a

Доказательство. Пусть IX>a и IX<a — индикаторы событий {ω : X(ω) > a} и
{ω : X(ω) < a} соответственно. Тогда:
X = X · 1 = X · (IX>a + IX<a ) > X · IX>a
Последнее произведение равно нулю, если X < a и равно X, когда X > a. Второе
обстоятельство даёт право сделать следующую оценку:
X · IX>a > aIX>a
Теперь, собрав начало и конец этой цепочки вместе и вспомнив, что мат. ожидание
индикатора события равно вероятности его события, имеем
X > aIX>a =⇒ EX > aEIX>a =⇒ EX > a P(X > a) =⇒ P(X > a) 6

4.7

EX
.
a

Неравенство Чебышева

Утверждение 4.3 (Неравенство Чебышева).
∃ DX =⇒ ∀ ε > 0 P(|X − EX| > ε) 6

DX
.
ε2

Замечание. Пользуясь тем фактом, что P(A) = 1 − P(A), условие можно переформулировать так:
∃ DX =⇒ ∀ ε > 0 P(|X − EX| 6 ε) > 1 −

DX
.
ε2

Кроме того, вместо ∃ DX можно требовать ∃ EX 2 — тогда существование EX гарантируется утверждением на с.39, а DX = EX 2 − (EX)2 , так что эти два требования
равносильны.
Доказательство. Случайная величина |X−EX|2 неотрицательна, используем для
неё неравенство Маркова:
∗

P(|X − EX| > ε) = P(|X − EX|2 > ε2 ) 6 P(|X − EX|2 > ε2 ) 6

E|X − EX|2
DX
=
.
ε2
ε2

Замечание. Начав с перехода ∗, докажем неравенство в виде
P(|X − EX| > ε) 6

DX
DX
или P(|X − EX| < ε) > 1 − 2 .
2
ε
ε

В общем-то, изменения незначительные и неважные, однако в разных местах это
неравенство может появиться в любой из четырёх упомянутых форм, и вопросов
это вызывать не должно.

46

4.7.1

Правило трёх сигм

В неравенстве Чебышева в качестве ε можно брать любое положительное число.
Ничто не мешает для этого использовать корень из дисперсии, например. Но при
таком выборе в правой части неравенства (где после вероятности стоит 6) окажется
единица, такая оценка едва ли представляет интерес.
Однако если взять в качестве ε величину 3σ, где σ — стандартное отклонение (то
есть именно корень из дисперсии), то получится уже более информативное
P(|X − EX| > 3σ) 6

DX
1
1
8
= или то же самое P(|X − EX| 6 3σ) > 1 − = .
9DX
9
9
9

То есть, вероятность того, что случайная величина находится от своего мат. ожидания не дальше, чем на три стандартных отклонения, не меньше 0,888 . . ., что уже
что-то да означает. Полученное соотношение и называется правилом трёх сигм.
Можно попробовать взять два или четыре стандартных отклонения вместо трёх,
но тогда в случае двух отклонений получится
P(|X − EX| 6 2σ) > 1 −

1
3
= ,
4
4

то есть точность попадания случайной величины в интервал уже равна 75%. Для
четырёх отклонений имеем
P(|X − EX| 6 4σ) > 1 −

1
15
= .
16
16

Тут точность — гораздо больше, но зато отрезок в два раза больше, чем для двух
отклонений. Разумеется, в конкретной ситуации каждое из этих правил может оказаться более подходящим, чем другие. Всё зависит от конкретных условий.

47

Лекция 5

5.1

Закон больших чисел Чебышева

Закон больших чисел (он же ЗБЧ) будет софрмулирован не один раз, от имени не
одного и того же исследователя и не с одними и теми же условиями. Поэтому всякий
раз рядом с ЗБЧ будет присутствовать указание на то, чей он, если это не будет ясно
из контекста.
Теорема 5.1 (ЗБЧ в форме Чебышева). Пусть X1 , X2 , . . . , Xn — независимые
случайные величины и дисперсия каждой из них существует и ограничена сверху
некоторой константой: ∀ i : 1 6 i 6 n ∃ DXi 6 C. Тогда
¯
µ¯
¶
¯ X1 + . . . + Xn EX1 + . . . + EXn ¯
¯
¯
∀ε > 0 P ¯
−
−−→ 1.
¯<ε −
n→∞
n
n
Доказательство. Сконструируем новую случайную величину X и вычислим её
мат. ожидание и дисперсию:
n
n
X
X1 + . . . + Xn
Xi ∗ 1 X
EX1 + . . . + EXn
X=
, EX =
, DX = D
= 2
DXi .
n
n
n
n i=1
i=1

В переходе ∗ используется независимость Xi . Просто так сложение за знак дисперсии
выносить нельзя.
Дальше для X воспользуемся неравенством Чебышева и оценим правую часть,
используя ограничение на дисперсии Xi :
P(|X − EX| < ε) > 1 −

DX
DX1 + . . . + DXn
nC
C
=1−
>1− 2 2 =1− 2
2
2
2
ε
nε
nε
nε

Остаётся вспомнить, что такое X и устремить n к бесконечности:
¯
µ¯
¶
¯ X1 + . . . + Xn EX1 + . . . + EXn ¯
C
¯
¯
P ¯
−
< ε = P(|X − EX| < ε) > 1 − 2 −−−→ 1.
¯
n
n
nε n→∞
Таким образом, искомое утверждение доказано.

5.2

Теорема Бернулли

Как следствие из только что доказанной теоремы легко получается ЗБЧ Якова Бернулли. В роли независимых случайных величин выступают индикаторы успехов в
независимых испытаниях:
Теорема 5.2 (Бернулли). Пусть Sn — число успехов в n испытаниях Бернулли с
вероятностью успеха p. Тогда
¯
¶
µ¯
¯
¯ Sn
∀ ε > 0 P ¯¯ − p¯¯ < ε −−−→ 1.
n→∞
n
48

Доказательство. Представим Sn как сумму n индикаторов успеха Ii в i-том испытании:
(
1, если в i-том испытании произошёл успех,
Sn = I1 + . . . + In ; Ii =
, 1 6 i 6 n.
0, в противном случае.
Как уже отмечалось, EIi = p и DIi = p − p2 при любом допустимом i. Дисперсии
ограничены сверху константой 0,25, а индикаторы независимы. Остаётся применить
ЗБЧ в форме Чебышева:
¯
¯
¯
µ¯
¶
µ¯
¶
µ¯
¶
¯ Sn
¯ Sn EI1 + . . . + EIn ¯
¯ Sn np ¯
Sn ¯¯
¯
¯
¯
¯
¯
P ¯ −E ¯<ε =P ¯ −
¯<ε =P ¯n − n¯<ε
n
n
n
n
¯
¶
µ¯
¯
¯ Sn
¯
¯
= P ¯ − p¯ < ε −−−→ 1.
n→∞
n

5.3

Пуассоновское распределение

В каком-то смысле распределение Пуассона является продолжением биномиального
распределения на бесконечное количество испытаний Бернулли. Причём этот факт
доказан (правда, оценка погрешности здесь приводится без обоснования).
Определение 5.1. Дискретная случайная величина X имеет распределение
Пуассона с параметром a (считается a > 0) тогда и только тогда, когда
P(X = k) =

ak −a
e , k = 0, 1, 2, . . . ,
k!

обозначается это так: X ∼ P oiss(a) или X ∼ П(a).
Замечание. Тот факт, что случайная величина X имеет биномиальное распределение с параметрами n и p кратко записывается как X ∼ Bi(n, p).
Известно, что количество посетителей (закусочной или торговой точки) представляет собой пуассоновский поток (но только не в час пик). Это означает следующее: пусть на момент времени t1 насчиталось Q(t1 ) клиентов (счёт ведётся от
любого подходящего момента времени), а на момент t0 — Q(t0 ). Тогда при всяких
t 1 > t0
Q(t1 ) − Q(t0 ) ∼ P oiss(λ(t1 − t0 )),
где λ называется интенсивностью процесса. Любопытно, что Q можно представить
как возрастающую на единицу в моменты времени τ0 , τ1 , τ2 . . . величину, где промежутки от τi−1 до τi — это независимые случайные величины, имеющие показательное
распределение с параметром λ (о нём — на с.??).

5.4

Теорема Пуассона

Теорема 5.3 (Пуассона). Пусть проводится n обобщённых испытаний Бернулли
(то есть, вероятность успеха испытания зависит от n) с вероятностью успеха
pn , Sn — количество успехов в этих испытаниях и npn −−−→ a. Тогда
n→∞

∀ k ∈ Z: 0 6 k 6 n

P(Sn = k) −−−→
n→∞

49

ak −a
e .
k!

Доказательство. Тем, кто помнит мат. анализ, доказательство покажется элементарным. Для тех, кто его не помнит, здесь всё расписано вплоть до теоремы о
произведении пределов. Как известно, Sn имеет биномиальное распределение с параметрами n и pn . Требуется перейти к пределу при большом n, больше ничего:
pkn n!
(1 − pn )n (1 − pn )−k
k!(n − k)!
(npn )k
n!
(1 − pn )n
=
·
·
.
k!
(n − k)!nk (1 − pn )k

P(Sn = k) = Cnk pkn (1 − pn )n−k =

k — это константа. Поэтому безо всяких неопределённостей
(npn )k
ak
= ,
n→∞
k!
k!
lim

После простых преобразований очевиден предел второй дроби:
lim

n→∞

n!
1
2
k−2
k−1
= lim (1)(1 − )(1 − ) · . . . · (1 −
)(1 −
)
k
n→∞
(n − k)!n
n
n
n
n
1
2
k−2
k−1
= lim (1 − ) lim (1 − ) · . . . · lim (1 −
) lim (1 −
) = 1.
n→∞
n→∞
n n→∞
n
n n→∞
n

При выяснении предела третьей дроби требуется второй замечательный предел и
непрерывность показательной функции. Кроме того, отметим, что раз npn −−−→ a,
n→∞
то pn −−−→ 0. Так что
n→∞

lim (1 − pn )n
lim (1 − pn )n
1
(1 − pn )n
np
n→∞
n→∞
pn n
lim
=
=
=
lim
(1
−
p
)
n
n→∞ (1 − pn )k
n→∞
lim (1 − pn )k
1
n→∞
¶−npn
¶a−npn −a
µ
µ
1
1
−
−
= lim (1 − pn ) pn
= lim (1 − pn ) pn
n→∞
n→∞
¶
µ
¶a−npn
µ
−a
1
1
−
−
p
p
n
n
= lim (1 − pn )
(1 − pn )
n→∞
µ
¶−a
µ
¶a−npn
1
1
−
−
= lim (1 − pn ) pn
lim (1 − pn ) pn
n→∞

n→∞

Последовательность a − npn является бесконечно малой, обозначим её как γn . Разберёмся отдельно со второй скобкой:
¶γn
µ
ln(1−pn )
ln(1−pn )
ln(1−pn )
1
lim γn
lim γn lim
γ
−
pn
= lim e n pn = en→∞
lim (1 − pn ) pn
= en→∞ n→∞ pn = e0·1 = 1.
n→∞

n→∞

С первой же скобкой всё гораздо проще:
¶−a µ
¶−a
µ
1
1
−
−
p
p
n
n
= lim (1 − pn )
= e−a .
lim (1 − pn )
n→∞

n→∞

Всё, теперь, собрав всё это вместе, получаем требуемое
(npn )k
n!
(1 − pn )n
·
·
n→∞
k!
(n − k)!nk (1 − pn )k
(npn )k
n!
(1 − pn )n
ak
ak −a
−a
= lim
· lim
·
lim
=
·
1
·
e
=
e .
n→∞
n→∞ (n − k)!nk n→∞ (1 − pn )k
k!
k!
k!

lim P(Sn = k) = lim

n→∞

50

5.4.1

Оценка близости биномиальных вероятностей к пуассоновским

Насколько близко биномиальное распределение приближается пуассоновским, говорит следующее утверждение, которое здесь не доказано:
Утверждение 5.1. Пусть Sn — число успехов в n (теперь обычных) испытаниях
Бернулли. Тогда
¯
¯
k
¯ a2
¯
a
−a
∀ k ∈ Z : n > k > 0 ¯¯P(Sn = k) − e ¯¯ 6
= np2 ,
k!
n
где a = np.
Замечание. Указанная оценка теряет всякий смысл при «больших» p. Например,
при p = 0,5 в правой части оценки уже при n = 2 наблюдается 1/2. Но вот при
p = 0,01 вплоть до n = 100 получается не такое уж плохое 0,01.

5.5

Задача о конкуренции (завязка)

Пример. Пусть каждое утро имеется станция с двумя поездами от разных компаний-перевозчиков и 1000 пассажиров, которым требуется уехать на одном из этих
поездов. Каждый пассажир выбирает поезд случайным образом безо всяких пристрастий. Имеется в виду, равновероятно. Для того, чтобы гарантированно перевезти всех пассажиров, в каждом из поездов должно быть по 1000 мест. Требуется
выяснить, сколько нужно мест в каждом из поездов, чтобы наверняка перевезти 90%
клиентов.
Логично подойти к задаче так: пусть Sn — количество пассажиров, выбравших
поезд первой компании-перевозчика. Каждый пассажир — это своего рода испытание
Бернулли: с вероятностью 1/2 он выбирает один из поездов и делает это независимо
от остальных. Отсюда видно, что Sn имеет биномиальное распределение с параметрами 1000 и 1/2. В переводе на язык вероятностей вопрос «сколько нужно мест,
чтобы наверняка перевезти 90% клиентов» приобретает вид «найти m, такое что
P(Sn 6 m) > 0,9». Причём это m хочется сделать поменьше. Знак > стоит в условии
вместо = потому, что P(Sn 6 m) вместе с m меняется скачками, и для условия со
знаком «=» решения может и не быть вовсе. Попробуем отыскать m:
Ãm
!
µ ¶n
m
m
[
X
X
1
k
P(Sn 6 m) = P
Sn = k =
P(Sn = k) =
Cn
.
2
k=0
k=0
k=0
n у нас, вообще-то, тысяча, так что в итоге приходим к неравенству
µ ¶1000
m
m
X
X
1
k
k
> 21000 · 0,9.
C1000
> 0,9 ⇐⇒
C1000
2
k=0
k=0
Решить его не так, чтобы очень сложно, но и не так, чтобы совсем просто. При
наличии некоторой хитрости довольно быстро получается наименьшее из всех возможных m — 520. А вовсе не 900, как хотелось бы предположить. Всякий раз, когда
возникают небольшие трудности, приятней их обойти. Немного ниже будет показано,
как это делается в данном случае (с.52).
51

5.6

Локальная предельная и интегральная теоремы
Муавра-Лапласа

Первая из теорем приводится без доказательства.
Теорема 5.4 (Локальная предельная теорема Муавра-Лапласа). Пусть Sn —
число успехов в n испытаниях Бернулли с вероятностью успеха p. Если
np(1 − p) −−−→ ∞, то
n→∞

∀ m ∈ Z: 0 6 m 6 n
где x =

x2
1
P(Sn = m) = √
e− 2
2πσ

µ

µ ¶¶
1
1+O
,
σ

p
√
m − np
, а σ = DSn = np(1 − p).
σ

С её помощью несложно доказывается интегральная теорема.
Теорема 5.5 (Интегральная теорема Муавра-Лапласа). Если выполнено условие локальной теоремы и C — произвольная положительная константа, то равномерно по a и b из отрезка [−C, C] (пусть b > a)
Ã

Sn − np
P a6 p
6b
np(1 − p)

!

1
−−−→ √
n→∞
2π

Zb

x2

e− 2 dx.
a

Замечание. Вообще, утверждение верно ∀ a, b ∈ R. Здесь излишнее ограничение
присутствует для простоты доказательства.
Доказательство. Обозначим за q величину 1−p и проведём небольшие выкладки
с использованием локальной предельной теоремы в переходе ♦. А переход ∗ — это
на самом деле перенос знака.
Ã
!
Sn − np
√
√
∗
P a6 p
6 b = P(np + a npq 6 Sn 6 np + b npq) =
np(1 − p)
Пусть множество M — это все целые числа m, такие что выполнено неравенство в
последней вероятности. То есть,
√
√
M = {m : np + a npq 6 m 6 np + b npq}
⇓
µ
µ ¶¶
X
X
x2
1
1
∗
♦
− m
√
=
P(Sn = m) =
e 2 1+O
,
σ
2πσ
m∈M
m∈M
m − np
. Обозначим как ∆xm разность xm − xm−1 . Присмотримся
под xm понимается
σ
к этой разности внимательней:
∆xm = xm − xm−1 =

m − np m − 1 − np
m − np − m + 1 + np
1
−
=
= .
σ
σ
σ
σ

52

1
Так что после замены в последней сумме на ∆xm становится очевидно, что она —
σ
привычная интегральная
сумма Римана для интегрируемой на любом отрезке функµ
¶
x2
1
ции e− 2 плюс ещё O
, которое исчезнет и вот почему:
σ
∆xm =

1
1
=p
−−−→ 0 по условию локальной теоремы.
σ
np(1 − p) n→∞

Так что, во-первых, всё лишнее исчезает, а, во-вторых, диаметр разбиения стремится
к нулю. Поэтому на отрезке [−C, C] сумма сходится к интегралу:
X
m∈M

x2
1
1
− m
√ ∆xm e 2 (1 + O (∆xm )) −−−→ √
n→∞
2π
2π

Zb

x2

e− 2 dx.
a

Ну а на любом подотрезке, таким образом, тоже неминуемо сойдётся. Причём в
силу свойств сумм Римана, разность между суммой и предельным значением будет
меньше ε при n не меньше некоторого Nε , которое для всех допустимых a и b будет
одним и тем же — это и есть равномерность.
Если кто забыл, почему это так, рекомендуется вспомнить один из критериев интегрируемости. Нужен тот, в котором речь идёт о пределе разности верхней и нижней
сумм Дарбу. Всё, здесь воспоминания об этом разделе мат. анализа заканчиваются.
А утверждение тем самым доказано.

5.7

Задача о конкуренции (развязка)

Замечание. При прямом решении задачи о конкуренции возник вопрос расправы с
неравенством мало того , что с очень большими числами, так ещё и не очень-то охотно поддающемся каким-то преобразованиям. Это настолько усложняет расчёты, что
ручной труд исключается. С помощью последней теоремы (правда, с условием для
вещественной оси) и таблиц для функции нормального распределения (с.??) задача
решается даже без калькулятора (почти). Сложности приятно обходятся следующим
образом:
µ

Sn − np
m − np
0,9 6 P(Sn 6 m) = P −∞ <
6
σ
σ

¶

1
≈√
2π

m−np
Zσ

e

−

x2
2 dx.

−∞

Здесь n достаточно велико, чтобы пользоваться интегральной теоремой (каков критерий применимости на практике — нужно выяснять на кафедре, в разных источниках встречаются разные советы по этому поводу). Дальше надо брать таблицу
значений функции стандартного нормального распределения (этот интеграл с дробью — она и есть) и подбирать подходящее m. Получится, что
√
m − np
> 1,282, значит, m > np + 1,282σ = 500 + 1,282 · 250 = 520,27.
σ
Значит, надо в качестве m брать 521. Между прочим, от точного ответ отличается
только на 1, а это меньше, чем 0,2% разницы. Так что получается весьма точный
результат, причём довольно быстро и безболезненно.

53

Лекция 6

6.1

Задача о различении двух гипотез о доле шаров
в урне

На этой лекции произойдёт небольшое вторжение в математическую статистику:
речь идёт о проверке статистических гипотез (с.??, если не терпится).
Пусть имеется урна с чёрными и белыми шарами. Она обладает тем свойством,
что шансы всех шаров внутри неё оказаться снаружи абсолютно равны, если мы проводим эксперимент по извлечению шара. Пусть есть две гипотезы о том, какова доля
белых шаров в урне: первая гласит, что эта доля равна p0 (саму гипотезу обозначим как H0 ), вторая — что доля составляет p1 (и обозначается соответственно H1 ).
Разумеется, считаем p0 6= p1 . Пусть далее для определённости p1 > p0 . Требуется
установить, какая из гипотез ближе к реальности.
Проведём выборку с возвращением шаров из урны (конечно, для данной задачи было бы проще высыпать их все и пересчитать по цветам, но природа иногда
ставит задачи с такой же моделью, где высыпать все «шары» никак нельзя). Пусть
её объём — n. Мы n раз вытащили шар, зафиксировали его цвет и положили шар
обратно. Нужно одну из гипотез признать более вероятной, как-то основываясь на
полученной выборке. Понятно, что поделив число белых шаров выборки на n точно
равного p0 или p1 числа мы можем и не получить. Может вообще случиться так, что
экспериментатор n раз вытащит один и тот же шар — тут никаких гарантий нет. Другое дело, что вероятность такого «неправильного» события может оказатсья крайне
малой.
Итак, имеем выборку размера n, то есть последовательность элементов, каждый из которых может принимать два значения. Одно соответствует чёрному шару,
второе — белому. Обозначим тот вариант последовательности, что получится после
эксперимента, как A — событие такое. Разумно правдоподобие гипотез устанавливать на основе следующих условных вероятностей:
h0 = P(A|H0 ) и h1 = P(A|H1 ).
Если h0 больше, то «побеждает» H0 , иначе H1 лучше. Вопрос в том, что будет при
равенстве h0 = h1 и в каких вообще отношениях состоят h0 и h1 .
Рассмотрим случай, когда A = {БББ. . .БББ} — все шары получились белыми.
Вычислим вероятности: P(A|H0 ) означает вероятность цепочки A при верной H0 , а
P(A|H1 ) — вероятность цепочки A при верной H1 . То есть,
h1 = P({БББ . . . БББ}|H1 ) = pn1 .

h0 = P({БББ . . . БББ}|H0 ) = pn0 ,

Поскольку p1 > p0 , то h1 > h0 и H1 правдоподобней. С цепочкой {ЧЧЧ. . .ЧЧЧ} всё
будет точно наоборот — «победит» H0 . Дальше от одной из этих цепочек (пойдём от
белой) будем постепенно двигаться к другой. То есть, по одному будем менять цвета
шаров (у нас с белого на чёрный) в цепочке. В зависимости от соотношения между
54

p0 и p1 , на каком-то из шаге этого «перекрашивания» знак неравенства между h1
и h0 изменится (в нашем случае с > на <). Возможно, он сделает это с переходом
через равенство, но в случае такой цепочки указанный подход не позволит различить гипотезы H0 и H1 . Так вот пусть в этой цепочке, при переходе через которую
знак меняется, bc чёрных шаров. Это число будем называть критическим. Теперь
правило, по которому принимается решение о том, какая гипотеза лучше, выглядит
так: если чёрных шаров в выборке больше критического, то правдоподобней H0 , если меньше — H1 . Если число чёрных шаров равно критическому, то если h1 6= h0 ,
решение принять просто: по принципу сравнения h0 и h1 . Но может случиться так,
что h1 = h0 . В этом случае статистика призывает подбросить монетку (но только не
обязательно правильную) — об этом подробно позже, в разделе статистики (если не
терпится, то на с.??). Пока предположим, что количество чёрных шаров не равно
критическому. Так вот правило, по которому решается судьба гипотез, называется
критерием.

6.1.1

Ошибки первого и второго рода

Уже говорилось о том, что экспериментатор может вытащить один и тот же шар n
раз, получить маловероятную цепочку и сделать неправильные выводы. Гарантировать то, что этого не произойдёт, нельзя. Но какой-то способ контроля таких ошибок
должен быть! Для начала следует получше разобраться с тем, что же мы понимаем
под словом «ошибка». Итак, пусть в цепочке, которую получил экспериментатор,
чёрных шаров имеется b штук. Ошибка произойдёт, если наше правило даст неверный результат, а именно если b > bc при на самом деле верной H1 или b < bc при на
самом деле верной H0 . Случай b = bc пока оставим за кадром. Вероятность первой
ошибки записывается как P(b > bc |H1 ), но поскольку событие b > bc означает признание гипотезы H0 , то эта вероятность будет записываться короче как P(H0 |H1 ).
Вероятность второй ошибки — как P(H1 |H0 ).
Теперь проведём небольшую дискриминацию: будем считать, что мы проверяем, верна ли гипотеза H0 . А гипотезу H1 будем называть конкурирующей. В такой
ситуации несложно понять следующих два определения:
Определение 6.1. При проверке гипотезы H0 происходит ошибка первого рода
тогда и только тогда, когда отвергается верная гипотеза H0 .
Определение 6.2. При проверке гипотезы H0 происходит ошибка второго рода
тогда и только тогда, когда принимается неверная гипотеза H0 .
Что можно сделать строго и точно, так это посчитать вероятности этих ошибок.
Определение 6.3. Вероятность ошибки первого рода называется значимостью
или уровнем значимости критерия и обычно обозначается как α:
α = P(H1 |H0 ).
С вероятностью ошибки второго рода связано другое понятие. Здесь оно не потребуется и договоримся о том, что её будем обозначать как β:
β = P(H0 |H1 ).
Ну а контроль за этими ошибками можно осуществлять посредством условий на
эти вероятности. Потребовать, например, чтобы α < 0,001 и β < 0,001.
55

Замечание. Искать какой-то алгебраической связи между α и β в общем случае
лучше и не пытаться. За символами H0 и H1 могут оказаться не только гипотезы о
биномиальном и гипергеометрическом распределении, но и что-нибудь пострашней.
И вот при этих в общем случае заведомо неизвестных гипотезах о распределении
надо вычислять вероятности того, что в результате эксперимента получаются те или
иные значения параметра, по которому мы принимаем решение. В общем случае это
сделать-то не всегда толком получается! Так что вопрос о какой-то простой связи
между α и β отбрасывается.
При фиксированных возможностях экспериментатора нельзя сделать α и β сколь
угодно малыми. В случае урны с шарами для уменьшения α и β нужно увеличивать
длину выборки — сделать ряд из цветов вынутых шаров длинней.
При построении критерия α обычно считается известным, а β пытаются сделать
поменьше. Так получают правило для проверки гипотезы на основе результата эксперимента. Причём вероятности ошибок при использовании этого правила известны,
их можно цивилизованно учесть.

6.1.2

Оценка для числа наблюдений, необходимых для различения гипотез с заданной точностью

Пусть некто зафиксировал для α и β верхние границы α0 и β0 , предоставил две
гипотезы насчёт доли белых шаров в урне и потребовал критерий для их различения. Поскольку сделать α и β одновременно сколь угодно малыми при фиксированном объёме выборки заведомо не получится, мы в ответ потребуем сделать выборку
достаточно длинной. Некто в ответ спросит, насколько длинной она должна быть.
Поскольку на вытаскивание каждого шара, фиксацию его цвета и возвращение в урну тратятся силы, время и финансы, то некто требует минимальную необходимую
длину. Выясним, как разобраться с этим вопросом.
Далее вместо «вероятность ошибки i-го рода» будет употребляться «ошибка i-го
рода». Будем искать критерий с ошибкой первого рода, равной α0 и ошибкой второго
рода, не превышающей β0 .
Пусть H1 гласит, что доля белых шаров в урне равна p1 , а H0 — что она составляет
p0 . Не ограничивая общности, будем считать, что p1 > p0 . Пусть в выборке оказалось
m белых шаров. Если верна H1 , то m — случайная величина, имеющая биномиальное
распределение с параметрами n и p1 . Если H0 — то с параметрами n и p0 . Представим
себе, что критерий построен и мы принимаем H1 , если m > mкрит . Вычислим ошибку
первого рода, обозначив 1 − p0 как q0 :
µ
¶
µ
¶
m − np0
mкрит − np0
m − np0
mкрит − np0
P(m > mкрит |H0 ) = P √
> √
=1−P √
6 √
.
np0 q0
np0 q0
np0 q0
np0 q0
Интуиция подсказывает, что некто потребует качественный критерий. Это означает, что ошибки должны будут оказаться маленькими. Кроме того, интуиция уверена в том, что малость ошибок влечёт за собой весьма и весьма большую длину
выборки. А раз длина выборки «весьма» велика, можно воспользоваться интегральной теоремой Муавра-Лапласа:
µ
α=1−P

mкрит − np0
m − np0
6 √
√
np0 q0
np0 q0

56

¶
≈1−

mкрит −np0
√
Znp0 q0 2
x
1
√
e− 2 dx

2π

−∞

= α0 .

Подобным образом поступим с ошибкой второго рода (q1 = 1 − p1 ):
µ
β 6 P(m 6 mкрит |H1 ) = P

m − np1
mкрит − np1
6 √
√
np1 q1
np1 q1

¶
≈

mкрит −np1
√
Znp1 q1 2
x
1
√
e− 2 dx

2π

6 β0 .

−∞

Пусть tα0 и tβ0 — решения уравнений
Zt
−

1 − Φ(tα0 ) = α0 и Φ(−tβ0 ) = β0 , где Φ(t) =

e

x2
2 dx.

−∞

Сопоставив это с выражениями для вероятностей ошибок, получаем
mкрит − np0
√
= tα0 =⇒ mкрит = np0 + tα0 np0 q0 и
√
np0 q0
mкрит − np1
√
6 −tβ0 =⇒ mкрит 6 np1 − tβ0 np1 q1 .
√
np1 q1
Остаётся исключить переменную mкрит и затем разрешить полученное неравенство
√
√
np0 + tα0 np0 q0 6 np1 − tβ0 np1 q1 относительно n, после чего окончательно имеем
µ √
¶
√
tα0 p0 q0 + tβ0 p1 q1 2
n>
.
p1 − p0
Так что чем ближе гипотезы, тем трудней их различить. Знаменатель это наглядно
демонстрирует. Посмотрим, что даёт формула на конкретных числах:
p0 = 0,5, q0 = 0,5, p1 = 0,6, q1 = 0,4, α0 = 0,05, β0 = 0,25, tα0 = 1,645, tβ0 = 0,674
⇓
¶2
µ
0,822 + 0,33
> 132 =⇒ n > 133.
n>
0,1
При n = 144 mкрит = 81.
В жизни эта схема наполняется самыми разными способами. Например, старые
и новые лекарства можно сравнивать с помощью такого метода.

6.2

Определение вероятностного пространства в общем случае

Пришло время покончить со счётностью пространства элементарных исходов Ω. Чтобы строго и аккуратно построить для Ω мощности континуум класс событий, нужно
для начала разработать почву. Определение σ-алгебры уже встречалось (под видом определения класса событий), и оно остаётся основным. Появится ещё немного
другой объект, называемый алгеброй. Далее он призрачно возникнет в одном месте: оказывается, заданную на алгебре функцию, удовлетворяющую первым двум
требованиям на вероятность, можно продолжить до полноценной вероятности единственным образом при одном условии на элементы алгебры. Об этом ниже (на с.??,
правда, без доказательства). Но в целом алгебра присутствует здесь потому, что
понадобится однажды в доказательстве одного важного факта.
Алгебра от σ-алгебры отличается только конечной аддитивностью (вместо счётной):
57

Определение 6.4. Множество A подмножеств (не всех!) Ω называется σ-алгеброй ⇐⇒ A обладает следующими тремя свойствами:
1◦ . σ-алгебре принадлежит само Ω:
Ω ∈ A.
2◦ . Вместе с любым множеством σ-алгебра содержит его дополнение до Ω.
B ∈ A =⇒ B ∈ A.
3◦ . Свойство счётной аддитивности:
∀ i ∈ N Bi ∈ A =⇒

∞
[

Bi ∈ A.

i=1

Далее под отрицанием будет пониматься дополнение до Ω. Не более, чем счётное объединение и отрицание далее будут называться допустимыми в σ-алгебре
операциями.
Замечание. Счётные пересечения тоже не выводят за границу σ-алгебры. Это сразу
следует из того, что
∞
\

Bi ≡

i=1

∞
[

Bi .

i=1

Этот факт, в свою очередь, устанавливается по определению объединения, пересечения и дополнения.
Определение 6.5. Множество A0 подмножеств (не всех!) Ω называется алгеброй ⇐⇒ A0 обладает следующими тремя свойствами:
1◦ . Алгебре принадлежит само Ω:
Ω ∈ A0 .
2◦ . Алгебра вместе с любым множеством содержит его дополнение до Ω:
B ∈ A0 =⇒ B ∈ A0 .
3◦ . Свойство конечной аддитивности:
B1 , B2 ∈ A0 =⇒ B1 ∪ B2 ∈ A0 .
Замечание. Свойство конечной аддитивности сформулировано для двух множеств,
однако с помощью мат. индукции может быть получено для любого количества слагаемых, лишь бы количество это было конечным.
Раз уж Ω имеет мощность континуум, то и события в общем случае могут иметь
мощность континуум. Уже приводилось множество мощности континуум, для которого не существует меры (с.12). В σ-алгебру событий нельзя включать множества, не
имеющих меры, потому что на всех элементах класса событий должна быть определена вероятность. Попробуем определиться, какие же множества можно допускать в

58

кандидаты на события. Начнём с простого: как известно, в случае отрезков и интервалов меру (которая дальше будет обозначаться буквой µ) можно ввести как модуль
разности концов множества: µ(( a, b)) = µ([ a, b)) = µ(( a, b]) = µ([ a, b]) = |b − a|,
где a и b — соответствующие действительные числа. Если вместо a или b окажется ±∞, то меру такого множества считаем бесконечной. Сначала на основе таких
множеств построим алгебру: пусть Ω = R и B0 — это все множества вида (−∞, a),
[ a, b), [ b, +∞) и всевозможные их конечные объединения. Это определение включает в себя отрицания — это обеспечено тремя видами множеств и возможностью их
объединять. Нетрудно установить, что B0 удовлетворяет всем условиям определения
алгебры. Разберёмся с тем, что из себя представляет σ-алгебра, получаемая из этих
множеств.

6.3

Сигма-алгебра, порождённая классом множеств

Пусть у нас есть какие-то множества, состоящие из элементов некоторого множества
Ω. Предположим, мы хотим изготовить содержащую их σ-алгебру. Бывает так, что
можно в какую-нибудь σ-алгебру добавить ещё какое-нибудь не содержавшееся там
ранее множество и получить всё то же, что мы хотели изготовить. Поэтому отдельно
выделяют σ-алгебру, ничего лишнего не содержащую:
Определение 6.6. σ-алгеброй, порождённой классом множеств E, называется наименьшая σ-алгебра, содержащая все элементы E и обозначается S(E).
Замечание. Вероятно, стоит отметить, что если E окажется σ-алгеброй, то S(E) =
E. Это напрашивается само по себе: E ⊆ S(E) и является σ-алгеброй. Но чтобы
сделать σ-алгебру ещё меньше, придётся выбрасывать какие-то её элементы. Но все
они принадлежат E, так что если кого выбросить, то все элементы E в полученной
σ-алгебре присутствовать не будут. А это уже нарушает определение.
Замечание. Подобно тому, как доказывалась конечная аддитивность вероятности,
легко показывается, что в σ-алгебре, порождённой классом множеств E, присутствуют всевозможные конечные объединения множеств из E — хвост множеств в счётном
объединении можно составить из пустых множеств, которые в σ-алгебре есть всегда
как Ω.
Следующий интуитивно понятный факт приводится без доказательства:
Утверждение 6.1. σ-алгебра, порождённая E, всегда существует и совпадает с
пересечением всех σ-алгебр, содержащих E.

6.4

Борелевская сигма-алгебра

На этой лекции везде, где речь заходит об алгебре либо σ-алгебре, порождённой
числовыми множествами, в качестве Ω подразумевается R, если не оговорено чтонибудь другое.
Определение 6.7. Борелевская σ-алгебра — это σ-алгебра, порождённая всеми
открытыми множествами вещественной прямой. Обозначается символом B.
Определение 6.8. Элемент B называется борелевским множеством.

59

Без специальной подготовки представить себе неборелевское множество крайне
трудно. С очень большой вероятностью, любое множество, которое студент может
себе представить за минуту, окажется борелевским. Неизмеримое множество со с.12
борелевским не явлется, но и представить его себе не так-то просто.
Утверждение 6.2. σ-алгебра, порождённая B0 , совпадает с B. Или, в кратких
обозначениях
S(B0 ) = B.
Доказательство. Покажем, что S(B0 ) ⊆ B и B ⊆ S(B0 ).
Первое включение следует из того, что все полуинтервалы и отрезки присутствуют в B: счётное (и конечное) пересечение за пределы B не выводят, а
¶
∞ µ
\
1
[ b, a) =
b − ,a .
n
n=1
Это значит, что B является в том числе и σ-алгеброй, порождённой всеми множествами из B0 . А значит, она включает в себя S(B0 ).
Второе включение следует из того, что все открытые множества прямой присутствуют в S(B0 ). Любое открытое множество можно представить как счётное
объединение интервалов. Например, взять рациональные точки с нужного размера окрестностями и объединить. А любой интервал можно представить как счётное
объединение полуинтервалов:
¶
∞ ·
[
1
( b, a) =
b + ,a .
n
n=1
Так что любое открытое множество есть в S(B0 ). Ну а вместе со всеми открытыми
множествами в порождённой σ-алгебре неминуемо появится и B. Таким образом,
второе включение обосновано.
Пример. Борелевскую σ-алгебру можно спокойно использовать в качестве класса
событий. В качестве Ω возьмём R, а вероятность для любого открытого множества
определим как интеграл по этому множеству функции
x2
1
f (x) = √ e− 2 .
2π

Все аксиомы будут выполнены. Кстати, вероятность любого множества, состоящего
из одной или нескольких точек, получается равной нулю. Может показаться странным, что любые события состоят из событий с нулевой вероятностью. Тем не менее,
«любое» событие может состоять из конинуума точек. Как видно, в таком случае
точное равенство нулю вероятности составляющих событий не гарантирует равенста
нулю вероятности их объединения.
Пример. Кроме B в качестве класса событий можно использовать массу кажущихся другими конструкций. В качестве Ω опять возьмём R, в качестве класса событий —
S(B1 ), где B1 — это совокупность всех множеств вида (−∞, a). В качестве вероятности берём всё тот же интеграл по множеству. В частности, для того же (−∞, a)
получаем
Za
x2
1
e− 2 dx.
P((−∞, a)) = √
2π
−∞

60

Покажем, что S(B1 ) = B. Заметим, что ∀ a ∈ R (−∞, a) = [ a, +∞), так что все
множества вида [ a, +∞) в S(B1 ) тоже присутствуют. При любых действительных a и
b, таких что b > a, [ a, b) = (−∞, a) ∪ [ b, +∞), так что все множества вида [ a, b) тоже
присутствуют в S(B1 ). Всё вместе это означает, что S(B1 ) = S(B0 ) = B. Поэтому
что S(B1 ), что S(B0 ), что B — это всё равно и все множества одного из этих классов
можно получать из множеств другого из этих классов с помощью допустимых в
σ-алгебре операций. Этот пример будет уместно вспомнить во время разговора о
функции распределения (с.62).

6.5

Случайные величины как измеримые отображения

Здесь, наконец, будет разъяснено, что же такое измеримость. Приводимое определение — это измеримость для частного случая отображений (из σ-алгебры событий
в R). Общий случай здесь не понадобится. Так что мы под измеримостью будем
понимать следующее:
Определение 6.9. Пусть задано вероятностное пространство (Ω, A, P). Отображение X : Ω → R называется A-измеримым (измеримым относительно A
или для краткости просто измеримым) тогда и только тогда, когда для любого
борелевского множества B прообраз X −1 (B) принадлежит классу событий A:
∀ B ∈ B X −1 (B) = {ω : X(ω) ∈ B} ∈ A.
Замечание. В общем-то, смысл всей затеи в том, чтобы факт X ∈ B (B ∈ B) в
терминах вероятностного пространтсва был событием. То есть, чтобы взятые вместе
ω, для которых это возможно (а это и есть прообраз B), образовывали бы множество
из класса событий: {ω : X(ω) ∈ B} ∈ A. В таком случае можно будет говорить
о вероятности события, например, в духе «потери не превысят 9000$», где потери
вычисляются как случайная величина. Вот и всё.
Любое измеримое отображение из Ω в R — это случайная величина. Если быть
построже, то
Определение 6.10. Пусть задано вероятностное пространство (Ω, A, P). Отображение X : Ω → R называется случайной величиной тогда и только тогда,
когда оно измеримо относительно A. То есть,
∀ B ∈ B X −1 (B) = {ω : X(ω) ∈ B} ∈ A.
В общем-то, определение измеримости всего-то скопировано. А вот то, что будет
написано далее — уже не просто копия.
Замечание. Понадобится то обстоятельство, что отрицание прообраза множества —
это прообраз отрицания множества и объединение прообразов множеств — это прообраз объединения множеств. То есть, если I — некоторое множество индексов (не
более, чем счётное), то
(
)
[
[
{ω : X(ω) ∈ B} = {ω : X(ω) ∈ B} и
{ω : X(ω) ∈ Bi } = ω : X(ω) ∈
Bi .
i∈I

i∈I

Это обстоятельство легко проверяется с помощью определений объединения и дополнения.
61

Утверждение 6.3. Пусть задано вероятностное пространство (Ω, A, P) и отображение X : Ω → R. Если все множества вида {ω : X(ω) < a}, где a ∈ R, принадлежат A, то X — случайная величина. Или, в кратких обозначениях,
∀ a ∈ R {ω : X(ω) < a} ∈ A =⇒ ∀B ∈ B {ω : X(ω) ∈ B} ∈ A.
Доказательство. Из прообразов лучей (−∞, a) можно с помощью отрицания и
объединения (не более, чем счётного) делать прообразы любых борелевских множеств. Это следует из того, что, во-первых, любое борелевское множество можно
получить с помощью отрицания и не более, чем счётного объединения из лучей вида (−∞, a) (доказательство имеется в примере на с.59). А, во-вторых, отрицание и
объединение можно выносить за скобки множеств-прообразов (это только что было в
замечании). Так что теперь берём любое борелевское множество, получаем его допустимыми операциями из лучей, выносим операции за скобки множеств-прообразов и
в общем итоге получаем прообразы лучей, над которыми производятся допустимые
в σ-алгебре операции.
Но поскольку у X прообразы множеств лучей лежат в классе событий, то в классе
событий окажутся и прообразы всех борелевских множеств, которые получились из
событий-прообразов лучей с помощью допустимых в σ-алгебре операций. Так что X
измеримо относительно A. Значит, X является случайной величиной.
Пример. Как и в случае менее мощного Ω, константа — всегда случайная величина.
Потому что у константы прообразов бывает два: ∅ и Ω. Пусть X(ω) ≡ C:
(
Ω, если C ∈ B,
∀ B ∈ B {ω : X(ω) ∈ B} =
∅, в противном случае.
Ну а в σ-алгебре событий Ω и Ω присутствуют всегда. Тем самым измеримость доказана.
Замечание. В случае не более, чём счётного Ω, не было множеств, для которых не
существовало меры и класс событий строился как множество всех подмножеств. В
случае Ω мощности континуум появилось неизмеримое подмножество, из-за которого
весь сыр-бор и загорелся. Понятие σ-алгебры согласовано с понятием вероятности —
проблемы проистекают от свойства счётной аддитивности, с ним и конфликтует
предположение об измеримости описанного на с. 12 множества. Это множество —
объединение мощности континуум борелевских множеств (точек), которое, как видно, выводит за пределы σ-алгебры.
Все неугодные множества из класса событий исключаются, тем самым устраняются вопросы и обрекаются на провал попытки обрушить построенную теорию
каким-нибудь шокирующим примером или рассуждением. Все результаты, полученные для случайных величин ранее, переносятся на случай Ω мощности континуум,
их доказательства постепенно появятся.
Ну, а множество всех подмножеств для не более, чем счётного Ω формально
является σ-алгеброй, и все рассуждения, приводимые для Ω мощности континуум,
можно провести и для не более, чем счётного Ω.

62

Лекция 7

7.1

Функция распределения случайной величины

Определение 7.1. Функцией распределения (кумулянтой, кумулятивной
функцией распределения) Fψ (x) случайной величины ψ называется вероятность
P(ψ < x), то есть:
Fψ (x) = P(ψ < x).
Определение корректное: все множества вида (−∞, x) — борелевские, так что
если ψ — действительно случайная величина, то прообразы их окажутся в классе
событий, и вероятность для них определена.
Замечание. Функция распределения может определяться и иначе: вместо P(ψ < x)
может быть P(ψ 6 x). Принципиальных изменений это не вносит, однако существенные различия имеются. При первом варианте определения функция обладает
непрерывностью слева, при втором — справа. Иногда это обстоятельство оказывается важным, например условия задач могут подразумевать одно из этих определений и требовать что-нибудь доказать, что для одного из определений неправильно.
Чтобы студент в таком случае не оказался в тупике в безысходности, о втором определении надо помнить и быть начеку.

7.1.1

Свойства функции распределения

Везде, где речь идёт о свойствах функции распределения, подразумевается, что ψ —
произвольная случайная величина.
1◦ . Функция распределения — всегда неубывающая:
∀ x1 , x 2 : x1 6 x2

Fψ (x1 ) 6 Fψ (x2 ).

Доказательство.
Fψ (x2 ) − Fψ (x1 ) = P(ψ
= P(ψ
= P(ψ
= P(ψ

< x2 ) − P(ψ < x1 )
∈ (−∞, x1 ) ∪ [ x1 , x2 )) − P(ψ ∈ (−∞, x1 ))
∈ (−∞, x1 )) + P(ψ ∈ [ x1 , x2 )) − P(ψ ∈ (−∞, x1 ))
∈ [ x1 , x2 )) > 0.

2◦ . Функция распределения непрерывна слева:
lim Fψ (x) = Fψ (x0 − 0) = Fψ (x0 ).

x→x0 −0

Замечание. Вот это свойство и изменяется при определении функции распределения как P(ψ 6 x) на непрерывность справа.
63

Доказательство. Функция Fψ (x) монотонна. Так что если доказать, что она стремится к какому-то числу по некоторой последовательности, сходящейтся к x слева,
то она к нему будет стремиться и по любой другой последовательности, сходящейся
к x слева. А это — уже определение предела функции по Гейне, но только опять
слева. Итак, рассморим разность
1
1
1
Fψ (x) − Fψ (x − ) = P(ψ < x) − P(ψ < x − ) = P(x − 6 ψ < x).
n
n
n
Имеем невозрастающую (при увеличении n) последовательность событий
{ω : x −

1
6 ψ(ω) < x}.
n

Она обладает нулевым пределом:
∞
\

{ω : x −

n=1

1
1
6 ψ(ω) < x} = lim {ω : x − 6 ψ(ω) < x} = {ω : x 6 ψ(ω) < x} = ∅.
n→∞
n
n

Вероятность, как известно, непрерывна по невозрастающей последовательности событий, воспользуемся этим в переходе ∗:
¶
µ
1
1
lim Fψ (x) − Fψ (x − ) = lim P(ψ ∈ [ x − , x))
n→∞
n→∞
n
n
1
∗
= P( lim {ω : ψ(ω) ∈ [ x − , x)}) = P(∅) = 0.
n→∞
n
Так что, по одной из последовательностей, стремящихся к x слева, Fψ стремится к
своему значению Fψ (x).
3◦ . Предел функции распределения на +∞ равен одному, на −∞ — нулю.
Fψ (x) −−−−→ 1 и Fψ (x) −−−−→ 0.
x→+∞

x→−∞

Доказательство. Опять нужно воспользоваться непрерывностью вероятности по
монотонной последовательности событий: в этот раз последовательности такие:
Bn = {ω : ψ(ω) ∈ (−∞, n)} =⇒ Bn ⊆ Bn+1 ,
Cn = {ω : ψ(ω) ∈ [−n, +∞)} =⇒ Cn ⊆ Cn+1 ,

∞
[

Bn = {ω : ψ(ω) ∈ R} = Ω,

n=1
∞
[

Cn = {ω : ψ(ω) ∈ R} = Ω.

n=1

Обе — неубывающие. Первая из них позволяет отыскать предел Fψ (x) на +∞:
lim Fψ (n) = lim P(Bn ) = P( lim Bn ) = P(Ω) = 1.

n→∞

n→∞

n→∞

Чтобы отыскать предел второй последовательности, функцию распределения отнимем от 1:
lim (1 − Fψ (−n)) = lim P(ψ > −n) = lim P(Cn ) = P( lim Cn ) = P(Ω) = 1

n→∞

n→∞

n→∞

n→∞

⇓
lim Fψ (−n) = 0.

n→∞

Ну, а поскольку функция распределения всегда монотонна, то, найдя пределы по
этим конкретным подпоследовательностям, мы тем самым нашли пределы по всем
остальным. Так что вновь по определению Гейне, пределы функции на +∞ и −∞
найдены.
64

7.2

Распределение случайной величины

Далее считается, что задано произвольное вероятностное пространство (Ω, A, P) и в
нём произвольная случайная величина ψ.
Определение 7.2. Распределением случайной величины ψ называется отображение Pψ : B → R, при любом B ∈ B равное вероятности P(ψ ∈ B). Или, покороче,
∀B ∈ B

Pψ (B) = P(ψ ∈ B) — распределение ψ.

Утверждение 7.1. Тройка (R, B, Pψ ) образует вероятностное пространство.
Доказательство. Доказательство целиком заключается в проверке аксиом. Проверить, то, что B будет σ-алгеброй на R — это всё равно что вспомнить определение
борелевской σ-алгебры. Так что остаётся убедиться в том, что Pψ — вероятность.
Для этого нужно проверить три аксиомы вероятности: вероятность Ω — единица,
вероятность неотрицательна и счётно-аддитивна. Проверим:
1. Pψ (R) = P(ψ ∈ R) = 1.
2. ∀ B ∈ B

Pψ (B) = P(ψ ∈ B) > 0.

3. ∀ {Bi }∞
i=1 ∈ B : i, j ∈ N, i 6= j =⇒ Bi Bj = ∅
Ã∞ !
Ã
!
Ã
Ã∞
!!
Ã∞
!
∞
[
[
[
[
−1
−1
Pψ
Bi = P ψ ∈
Bi = P ψ
Bn
=P
ψ (Bn )
i=1

i=1
∗

=

∞
X
i=1

i=1

P(ψ −1 (Bn )) =

∞
X

i=1

Pψ (Bi ).

i=1

В переходе ∗ использован тот факт, что прообразы непересекающихся множеств не пересекаются. Предположить противоположное — и получим очевидное противоречие с реальностью {ω : ψ(ω) ∈ ∅} 6= ∅. Ну, а тогда можно
воспользоваться счётной аддитивностью обычной вероятности.
Таким образом, доказано, что (Ω, B, Pψ ) — вероятностное пространство.
Замечание. В общем-то, дело дошло до того, что можно забыть про исходное вероятностное пространство (Ω, A, P) и в нём случайную величину ψ, а оперировать в
терминах (R, B, Pψ ) — с вещественными числами работать удобно и привычно.
Если известно распределение случайной величины, то функция распределения
также известна. В каждой точке её можно вычислить через распределение:
Fψ (x) = P(ψ < x) = Pψ ((−∞, x)).
Более того, если известна функция распределения, то известно распределение. Но
этот факт доказывается уже не так просто. Суть заключается в том, что:
• функция распределения однозначно задаёт вероятность прообразов всех множеств вида (∞, a),
• отняв функцию распределения от единицы, получим вероятность прообразов
всех множеств вида [ a, +∞),
• отняв от вероятности прообраза (−∞, b) вероятность прообраза (−∞, a), где
a < b, получим вероятность прообраза [ a, b).
Появились множества, которые вместе со своими конечными объединениями образуют уже знакомую нам алгебру подмножеств R B0 . А S(B0 ) = B. Намёк окончен.
65

7.3

Теорема о единственности продолжения вероятности с алгебры на порождённую ею σ-алгебру

Теорема 7.1 (О продолжении меры). Пусть F0 — алгебра подмножеств Ω,
пусть на F0 задана функция P и выполнены три условия:
1. ∀ F ∈ F0

P(F ) > 0.

2. P(Ω) = 1.
3. Внутри F0 P счётно-аддитивна. То есть,
∀ {Fn }∞
n=1 ∈ F0 : ∀ i, j ∈ N : i 6= j Fi Fj = ∅ и
µ
P

∞
S
n=1

¶⇓ ∞
P
Fn =
P(Fn ).

∞
S
n=1

Fn ∈ F0

n=1

Тогда P единственным образом продолжается до вероятности на S(F0 ).

7.4

Взаимно однозначное соответствие между функциями распределения и вероятностными распределениями

Теорема 7.2. Функция распределения случайной величины однозначно задаёт её
распределение.
Доказательство. Зная функцию распределения, мы можем легко установить вероятности попадания случайной величины (обозначим её как ψ) во все множества
следующих видов:
P(ψ ∈ (−∞, a)) = Fψ (a), P(ψ ∈ [ b, +∞)) = 1 − Fψ (b) и P(ψ ∈ [ a, b)) = Fψ (b) − Fψ (a).
Множества этих трёх видов вместе со всевозможными их конечными объединениями
образуют алгебру B0 , которая подробно обсуждалась на с.58. Там же показано, что
S(B0 ) = B. Это означает, что ∀ B ∈ B вероятность P(ψ ∈ B) определена и выражается через известные нам вероятности множеств указанных выше видов. А значит,
известно распределение. Теорема доказана.
Замечание. На самом деле, всё, что произошло в доказательстве, уже встречалось,
причём почти в том же контексте. Уверждение на с.61 — практически клон последней
теоремы по ходу мыслей. Если что-то осталось неясным, рекомендуется посмотреть
туда.
Теперь можно делать вывод о том, что любое распределение однозначно
задаёт функцию распределения и любая функция распределения однозначно задаёт распределение.

66

Замечание. Пусть, кто-нибудь задал счётно-аддитивное (внутри B0 — о счётных
объединениях, оказавшихся вне B0 , пока ещё ничего не утверждается) отображение f : B0 → [ 0, 1], такое что f (Ω) = 1. Тогда, по теореме о продолжении меры, f
единственным образом продолжается до вероятности на S(B0 ) = B. Именно единственным, так что для тех счётных объединений, что оказались за границей B0 ,
возможное значение f не только обязательно существует но и единственно.
Утверждение 7.2. Пусть имеется некоторая непрерывная слева неубывающая на
всей оси функция f , у которой предел на +∞ равен единице, а на −∞ — нулю. Тогда
существуют вероятностное пространство и в нём случайная величина ψ, такие
что f — функция распределения ψ.
Замечание. ψ и вероятностное пространство заведомо неединственны. Распределение не фиксирует вид отображения, не говоря уже о том, что о пространстве
элементарных исходов ничего сказать не может.
Доказательство. В качестве пространства элементарных исходов проще всего
взять R, в качестве σ-алгебры событий — B. Остаётся разобраться с вероятностью
и случайной величиной.
Сделаем это следующим образом: будем f трактовать как отображение F из B0
в [ 0, 1], а именно
∀ a, b ∈ R : b > a F ((−∞, a)) = f (a), F ([ a, +∞) = 1 − f (a) и F ([ a, b)) = f (b) − f (a),
а для всевозможных конечных объединений множеств этих трёх видов F доопределяем с помощью формулы конечной аддитивности. Для любого конечного объединения множеств из B0 она трансформируется в формулу включения-исключения
(с.15), и в итоге F будет задано на всей B0 :
Ãn
!
n
[
X
n
∀ {Ai }i=1 ∈ B0 : 1 6 i, j 6 n, i 6= j ⇒ Ai Aj = ∅ F
Ai =
F (Ai ).
i=1

i=1

Если присмотреться, то попросту фабрикуется заданное на всех элементах B0 распределение ψ.
Покажем, что F — счётно аддитивно. Для этого докажем пару неравенств: пусть
∞
S
{Kn }∞
∈
B
,
K
=
Kn , K ∈ B0 и ∀ i, j ∈ N : i 6= j Ki Kj = ∅,
0
n=1
n=1

F (K) >

∞
X

F (Ki ) и F (K) 6

i=1

∞
X

F (Ki ).

i=1

Первое неравенство. Чем бы на самом деле ни были Ki , они лежат в алгебре
B0 . Значит, они представимы с помощью конечных объединений из множеств вида
(−∞, a), [ a, b) и [ b, +∞) (отрицания не нужны — они тоже выражаются как конечные объединения из множеств этих трёх видов). «Развернём» все Ki в эти конечные объединения — получим новую последовательность попарно непересекающихся
множеств Li . Точно так же поступим и с K. Несмотря на то, что K — счётное объединение непересекающихся множеств указанного вида, оно всё же из B0 , а потому
раскладывается в их конечное объединение. Конечную последовательность непересекающихся множеств, на которые разбивается K, обозначим как {Mj }kj=1 . Последовательность из Ki распалась на несколько последовательностей (не исключено,
67

правда, что она чем была, тем и осталась), объединение каждой из которых сходится к одному из Mj , при этом все Ki и Mj — множества одного из трёх хорошо
известных видов.
Поэтому если доказать, что для таких последовательностей выполнена счётная
аддитивность, то она будет доказана для любых последовательностей из B0 . Потом
просто объединим конечное количество этих последовательностей и для F воспользуемся конечной аддитивностью.
Пусть K = [ a, b), где b > a — конечные числа. Ki = [ ai , bi ), попарно непересекающиеся множества. Поскольку множества не бывают «разного знака», то в
рядах-объединениях множеств порядок объединения можно свободно менять. Строгое обоснование этого факта можно получить по определению объединения множеств. Зафиксируем произвольное n и множества перенумеруем так, чтобы были
выполнены условия a 6 a1 < b1 6 a2 < b2 6 . . . 6 an < bn 6 b. Получаем, что
n
n
X
X
∗
F (Ki ) =
(f (bi ) − f (ai )) 6 f (b) − f (a) = F (K).
i=1

i=1

В переходе ∗ использована монотонность f . Поскольку это верно при любом n, то
можно учинить переход к пределу с обеих сторон знака неравенства. И первое неравенство обосновано. Если вдруг a либо b окажется бесконечным, то изменения в ходе
мыслей будут число символическими.
Второе неравенство. По тем же простым соображениям, будем работать со случаем K = [ a, b) и Ki = [ ai , bi ). В силу непрерывности слева функции f ,
ε
ε
∀ ε > 0, ∀ i ∈ N ∃ a0i < ai : f (a0i ) > f (ai ) − i+1 , ∃ b0 < b : f (b0 ) > f (b) − .
2
2
∞
∞
[
[
[ a, b0 ] ⊆ [ a, b) = [ ai , bi ) ⊆ (a0i , bi ).
i=1

i=1

0

[ a, b ] — это компактное множество. Большое объединение справа — это его открытое
покрытие. В такой ситуации возникает соблазн выбрать из открытого покрытия
конечное подпокрытие. Выберем:
m
[
0
∃ m ∈ N : [ a, b ] ⊆ (a0i , bi ).
i=1

(a0i , bi )

Интервалы
уже могут пересекаться, а объединение их содержит в себе [ a, b0 ].
Продемонстрируем, что
m
X
(**)
(f (bi ) − f (a0i )) − f (b0 ) + f (a) > 0.
i=1

Факт следует, по сути, из того, что f неубывает. Перенумеруем интервалы из покрытия в том порядке, в котором они встречаются на вещественной оси, если идти
слева-направо. Картина будет примерно следующей:
a01 < a 6 a02 < b1 < a03 < b2 < a04 < . . . < bm−3 < a0m−1 < bm−2 < a0m < bm−1 6 b0 < bm .
Теперь перепишем выражение в левой части ∗∗, так что неравенство станет очевидным: каждая разность в сумме, что идёт после ♣, неотрицательна:
n
X
♣
(f (bi )−f (a0i ))−f (b0 )+f (a)=f (bm )−f (b0 )+f (bm−1 )−f (a0m )+f (bm−2 )−f (a0m−1 )+f (bm−3 )−. . .
i=1

. . .−f (a04 )+f (b2 )−f (a03 )+f (b1 )−f (a02 )+f (a)−f (a01 ) > 0.
68

Для завершения мысли вспомним, что f (a0i ) > f (ai ) −
n

f (b) − f (a) −

ε
2i+1

ε
и f (b0 ) > f (b) − :
2

∞

X
X
ε
< f (b0 ) − f (a) 6
(f (bi ) − f (a0i )) <
(f (bi ) − f (a0i ))
2
i=1
i=1
∞ ³
´
X
ε
<
f (bi ) − f (ai ) + i+1
2
i=1
⇓

ε
f (b) − f (a) − <
2

∞ ³
X

f (bi ) − f (ai ) +

i=1

ε ´
2i+1

=

∞
X

(f (bi ) − f (ai )) +

i=1

ε
2

⇓
∀ ε > 0 f (b) − f (a) − ε <

∞
X
(f (bi ) − f (ai )).
i=1

В силу произвольности ε в итоге получаем
∞
∞
X
X
F (K) = f (b) − f (a) 6
(f (bi ) − f (ai )) =
F (Ki ).
i=1

i=1

Всё, счётная аддитивность показана. Применяем теорему о продолжении меры
и обнаруживаем, что задано отображение из B в R, обладающее всеми свойствами
вероятности. Вот её и назначим вероятностью в том пространстве, что мы строим с
самого начала доказательства. Тем самым, задано распределение, ну а вместе с ним
и функция распределения, которая, если присмотреться, в каждой точке совпадает
с f . А случайная величина, кстати, подойдёт тождественная, то есть, ψ(ω) = ω.
Утверждение доказано.
Пусть F — множество всех непрерывных слева неубывающих на R функций,
у которых предел на +∞ равен 1, на −∞ равен 0. Пусть P — класс всевозможных вероятностных распределений на действительной оси. Последнее утверждение
наглядно демонстрирует, что между F и P можно построить взаимно-однозначное
соответствие, посредством функции распределения. Эти множества эквивалентны.
Речь даже заходит об изоморфизме, но для этого сначала нужно ввести групповые
операции, а для линейной алгебры места здесь не выделено.
На функцию распределения наложены весьма мягкие условия — она может быть
непрерывной на всей оси, может состоять из полуотрезков прямых, параллельных
горизонтальной оси (это и наблюдается для дискретных случайных величин), а может просто иметь счётное количество разрывов. Всё это — в рамках наложенных
условий.

69

Лекция 8

8.1
8.1.1

Неравенство и УЗБЧ Колмогорова
Неравенство Колмогорова

Теорема 8.1 (Неравенство Колмогорова). Пусть X1 , X2 , ..., Xn — независимые
случайные величины, EXi = 0, EXi2 < ∞, i = 1, . . . , n. Тогда ∀a > 0 справедливо
неравенство:
n
P
µ
¶
EXi2
i=1
P sup |X1 + X2 + ... + Xk | > a <
.
a2
16k6n
Замечание. Неравенство Чебышева в тех же условиях, таким образом, является
частным случаем неравенства Колмогорова, только в неравенстве Чебышева речь
идет о сходимости по вероятности, а в неравенстве Колмогорова — почти всюду.
Если положить k = n, то получится уже знакомое нам неравенство Чебышева.
Доказательство. Положим Sk = X1 + X2 + ... + Xk . Вектор из случайных величин
(X1 , . . . , Xn ) обозначим как Y . Понадобятся следующие четыре факта:
EXi Xj = EXi · EXj = 0 при i 6= j

ESn2 =

=⇒

n
X

EXi2 ;

(1)

i=1
n
X
E(Sn − Sk ) = E Xi = 0;

½
Введем события A =

¾
Y : sup |Sk | > a

i=k+1

и Ak =

16k6n

(2)

½

¾
Y:

sup
16m6k−1

|Sm | 6 a, |Sk | > a

⇓
A=

n
[

Ak и Ai Aj = ∅ ∀i 6= j;

(3)

k=1

Рассмотрим случайные величины (Sn − Sk ) и Sk IAk . Первая из них конструируется как борелевская функция от Xk+1 , . . . , Xn , вторая — от X1 , . . . , Xk , а случайные
величины X1 , . . . , Xn независимы в совокупности. А тогда будут независимыми случайные величины (Sn − Sk ) и Sk IAk . А произведение мат. ожиданий независимых
случайных величин равно произведению их мат. ожиданий. То есть, верно следующее:
X1 , . . . , Xn — независимые случайные величины
⇓
(Sn − Sk ) и Sk IAk независимы
⇓
E((Sn − Sk ) · (Sk IAk )) = E(Sn − Sk ) · ESk IAk .
70

(4)

Далее происходят небольшие выкладки:
n
X

(1)
EXi2 =

ESn2

=

ESn2

·1>

ESn2

· IA =

ESn2

·

n
X

i=1

IAk =

k=1

>
(2)

=

n
X

(ESk2 IAk

k=1
n
X

n
X

E(Sk + (Sn − Sk ))2 · IAk

k=1

n
(4) X
+ 2E(Sn − Sk )Sk IAk ) =
(ESk2 IAk + 2E(Sn − Sk )ESk IAk )
k=1
∗

ESk2 IAk > a2

k=1

n
X

EIAk = a2

k=1

n
X

(3)

P(Ak ) = a2 P(A).

k=1

Помеченный * переход может вызвать вопросы. Только один из индикаторов в сумме
может быть единицей, тогда множитель при нём обязательно превысит a2 — так
определялось событие Ak . Множители же при остальных индикаторах нам вовсе
неинтересны, потому что умножаться они всё равно будут на ноль. Сведя конец
этой цепочки с ее началом, получим желанное
µ
¶
P sup |X1 + X2 + ... + Xk | > a <

n
P
i=1

16k6n

8.1.2

EXi2

a2

.

Усиленный закон больших чисел Колмогорова

Теорема 8.2 (Усиленный закон больших чисел Колмогорова). Пусть
X1 , .., Xn — независимые случайные величины
∞
X
DXn
n=1

n2

<∞

⇓
X1 + X2 + ... + Xn EX1 + EX2 + ... + EXn
−
−−−→ 0 почти всюду.
n→∞
n
n
Замечание. В законе больших чисел вместо
∞
X
DXn
n=1

n2

< ∞ было DXi 6 C,

последнее сильнее первого ограничивает множество подходящих под условие теоремы последовательностей случайных величин.
Доказательство. Центрируем случайные величины Xi :
Yi = Xi − EXi ;

EYi = 0;

DYi = DXi = σi2

Обозначим Sn = Y1 + Y2 + . . . + Yn и вектор из величин Yi как просто Y . Для доказательства теоремы достаточно показать, что
Y1 + Y2 + ... + Yn
Sn
=
→ 0 почти всюду.
n
n
m
µ
¶
|Sk |
∀ ε > 0 P sup
> ε −−−→ 0.
n→∞
k>n k
71

Будем работать с событиями Ak , которые определим следующим образом:
¯
¯
¾
½
¯ Sk (Y ) ¯
¯
¯
>ε
An = Y : n−1
max n ¯
2
6k<2
k ¯
Ã∞
!
¶
µ
[
|Sk |
Заметим, что P
> ε −−−→ 0.
Ak −−−→ 0 ⇐⇒ ∀ ε > 0 P sup
n→∞
n→∞
k>n k
k=n
Чтобы было верным стоящее слева от знака равносильности утверждение, достаточно показать, что
∞
X
P(Ak ) < ∞.
k=1

В самом деле:
P(An ) 6 P(

max

2n−1 6k<2n

|Sk | > ε2n−1 ) 6 P(maxn |Sk | > ε2n−1 )
k<2

6 {По неравенству Колмогорова} 6

X
DS2n
−2 −2n
=
4ε
2
σk2
ε2 22(n−1)
k62n

Получив оценку сверху для P(Ak ), оценим теперь сверху сумму ряда из этих вероятностей, умноженного на константу:
∞
∞
∞
X
X
X
X
ε2 X
2−2n
σk2
P(An ) 6
2−2n
σk2 =
4 n=1
n=1
n : 2n >k
k62n
k=1
µ
¶
∞
∞
∗ X
1
4 X σk2
σk2 k −2
6
=
·
< ∞ по условию.
1
2
3
k
1
−
4
k=1
k=1

В помеченном * переходе мы поменяли порядок суммирования ряда. Поскольку он
знакопостоянный и сходится, то можно менять порядок суммирования, не разрушив
сходимость. Остается воспользоваться тем фактом, что остаток сходящегося ряда
стремится к нулю:
Ã∞
!
∞
∞
[
X
X
P(Ak ) < ∞ =⇒ P
Ak 6
P(Ak ) −−−→ 0.
k=1

8.1.3

k=n

k=n

n→∞

Применение УЗБЧ: метод Монте-Карло

Пусть дана функция f (t), непрерывная на [ 0, 1]. Не ограничивая общности, будем
считать, что 0 6 f (t) 6 1 (в противном случае отнимем от функции ее минимальное
на сегменте значение, а потом полученную функцию поделим на ее же максимум, если эта функция — не константа). Оказыватся, интеграл от этой функции на сегменте
[ 0; 1] можно вычислить с помощью УЗБЧ.
Пусть X и Y — независимые случайные величины, равномерно распределенные
на отрезке [ 0; 1]. Введем случайную величину z следующим образом:
(
1, если f (X) > Y
z=
.
0, если нет

72

Математическое ожидание этой случайной величины оказывается равным интегралу, о котором говорилось выше:
Z1
Ez = P(f (x) > y) =

f (z) dz.
0

Объясняется это тем, что случайный вектор (X, Y ) имеет в квадрате ( 0; 0)×( 1; 1)
на XY-плоскости плотность, равную единице, за пределами квадрата плотность равна нулю. Далее заметим, что из-за выбранного вида величины z её мат. ожидание
будет равняться двойному интегралу от единицы по фигуре Λ = {(x, y) : 0 6 y <
f (x), x ∈ [ 0; 1]}. А поскольку функция на сегменте [ 0; 1] расположена между нулем
и единицей, то фигура Λ — это не что иное, как площадь под графиком f (x). Двойной интеграл от единицы по этой фигуре даст площадь под графиком f (x), то есть
тот самый интеграл от f (x) от нуля до одного.
Теперь пусть у нас имеется 2n независимых случайных величин, равномерно распределенных на сегменте от нуля до одного: X1 , . . . , Xn и Y1 , . . . , Yn . Сконструируем
из них n случайных величин z1 , . . . , zn по следующему закону:
(
zi =

1, если f (Xi ) > Yi
, у всех zi одинаковое мат. ожидание: Ezi =
0, если нет

Z1
f (t) dt.
0

Остается только применить УЗБЧ Колмогорова, предварительно заметив, что дисперсии zi ограничены, и сами zi независимы в совокупности. Тогда
z1 + . . . + zn
−−−→
n→∞
n

Z1
f (t) dt почти всюду.
0

Здесь, однако, имеются серьезные проблемы: во-первых, надо где-то взять очень
много независимых равномерно распределенных на сегменте от нуля до одного случайных величин. Это совсем не так просто, как хотелось бы! Кроме того, не приведена оценка погрешности для n-того шага. Так что перед тем, как воспользоваться
сим методом, с проблемами этими надо разобраться. Здесь этого не сделано.

8.2

Сходимость в среднем

Определение 8.1. Последовательность Xn сходится к случайной величине X в
среднем порядка k, где k — натуральное число
m
E|Xn − X|k −−−→ 0.
x→∞

Если k = 2, то говорят, что имеется сходимость "в среднем квадратично".
Если k = 1, то просто "в среднем".
Утверждение 8.1. Из сходимости в среднем следует сходимость по вероятности:
E|Xn − X|k −−−→ 0, k ∈ N
n→∞

=⇒

p

Xn →
− X — стремление по вероятности.

73

Доказательство.
1
E|Xn − X|k
εk
В последнем переходе использовалось неравенство Маркова
P(|Xn − X|k > εk ) = P(|Xn − X| > ε) <

E|Xn − X|k −−−→ 0
n→∞

=⇒

∀ε > 0

P(|Xn − X|k > ε) −−−→ 0.
n→∞

Утверждение 8.2. Обратное неверно.
Доказательство. Построим последовательность случайных величин, стремящуюся к случайной величине ноль по вероятности, но в среднем расходящуюся:


n, 0 6 ω 6 1 ,
n
Ω = [ 0; 1]; Xn (ω) =
1

0,
6 1.
n
Z1/n
nk dt = nk−1 > 1, k ∈ N.
E|Xn − 0|k =
0

Стремление построенной последовательности к нулю по вероятности очевидно, а
отсутствие сходимости в среднем показано последней формулой. Тем самым, утверждение оправдано.

8.3

Производящие функции

Определение 8.2. Производящей функцией неотрицательной целочисленной
случайной величины x называется функция ϕx (z) = Ez x ; |z| 6 1; z ∈ C.

8.3.1

Свойства производящих функций

1◦ . Указанное выше мат. ожидание всегда существует, поскольку по неравенству
треугольника (ну, или свойству интегралов)
|Ez x | 6 E|z|x 6 1, потому что |z| 6 1.
Значит, для неотрицательной целочисленной случайной величины производящая
функция всегда существует.
Замечание. В открытом круге |z| < 1 (речь идет о комплексной плоскости) ϕx (z)
является равномерно сходящимся рядом. Каждое слагаемое можно дифференцировать бесконечное количество раз. При этом те, кто помнят неравенство КошиАдамара, заметят, что ряд из производных любого порядка в этом круге равномерно
сходится, а значит, производящую функцию можно дифференцировать и производная равна ряду из производных того же порядка слагаемых. А вообще, это — степенной ряд. Этот факт неявно используется при доказательстве следующего утверждения.
2◦ . Пусть ϕx (z) — производящая функция случайной величины x, тогда
(k)

ϕx (0)
, k ∈ Z, k > 0 — известна функция распределения x.
k!
То есть, по производящей функции однозначно восстанавливается распределение случайной величины.
P(x = k) =

74

Доказательство. По определению распишем математическое ожидание случайной величины для дискретного распределения:
Ez x = P(x = 0) + z P(x = 1) + z 2 P(x = 2) + . . . = ϕx (z).
Дальше действуем по индукции либо так: положим z = 0 и обнаружим факт P(x =
0) = ϕx (0), затем возьмем от производящей функции производную, уже там положим
z = 0 и обнаружим, что P(x = 0) = ϕ0x (0). Далее, взяв n-тую производную и положив
(k)
в ней z = 0, получим P(x = k) = ϕx (0)/k!. Возможно, стоит заметить, что в данном
случае 00 следует считать единицей.
Из последнего факта следует, что между производящими функциями и распределениями целочисленных неотрицательных случайных величин есть взаимнооднозначное соответствие.
3◦ . Пусть две случайных величины x и y независимы и имеют производящие функции ϕx (z) и ϕy (z). Тогда
ϕx+y (z) = ϕx (z) · ϕy (z).
Это означает, что производящая суммы независимых случайных величин
равна произведению производящих.
Доказательство. Доказательство маленькое и симпатичное. Независимость x и
y используется в помеченном звездочкой переходе:
∗

ϕx+y (z) = Ez x+y = Ez x z y = Ez x Ez y = ϕx (z)ϕy (z).
Последнее утверждение - важнейшее свойство производящих функций. По индукции легко доказывается аналогичный факт для суммы n независимых случайных
величин. Задача о выяснении распределения суммы целочисленных неотрицательных случайных величин в отдельных случаях сильно упрощается.
Пример. Отыщем производящую функцию для случайной величины x, распределенной по биномиальному закону с параметрами n и p:
Будем действовать по определению:
x

ϕx (z) = Ez =

n
X

k

z P(x = k) =

k=0

=

n
X

n
X

Cnk z k pk (1 − p)(n−k)

k=0

Cnk (pz)k (1 − p)(n−k) = (pz + 1 − p)n .

k=0

Бинома Ньютона для решения этой задачи вполне достаточно.
Пример. Пусть x1 , . . . , xn — независимые случайные величины, имеющие распределение Пуассона с параметрами λ1 , . . . , λn соответственно. Требуется выяснить, как
распределена их сумма.
Найдем производящую функцию случайной величины xi :
ϕxi (z) = Ez xi =

∞
X
k=0

∞

z k λki

X (λi z)k
e−λi
= e−λi
= eλi (z−1) .
k!
k!
k=0

75

Производящую функцию суммы x1 +. . .+xn найдем как произведение производящих
функций слагаемых:
ϕx1 +...+xn (z) = e(λ1 +...+λn )(z−1) .
Здесь в глаза бросается тот факт, что производящая функция суммы по виду сильно
напоминает производящую функцию одиночной случайной величины. Очевидно, что
мы получили производящую случайной величины, распределенной по закону Пуассона с параметром λ1 + . . . + λn . Теперь, пользуясь фактом взаимно-однозначного
соответствия между производящими функциями и распределениями целочисленных
неотрицательных случайных величин, заключаем, что сумма независимых пуассоновских случайных величин есть пуассоновская случайная величина с параметром,
равным сумме параметров распределений слагаемых.
Замечание. Случаи, когда по виду производящей функции суммы можно «угадать» ее распределение, не исчерпываются случаем суммы независимых пуассоновских случайных величин. Такое встретится для некоторых других дискретных распределений.

76

Лекция 9

9.1

Характеристические функции

Аппарат характеристических функций является одним из основных средств аналитического аппарата теории вероятностей. Наиболее ярко это будет продемонстрировано через 2 лекции при доказательстве некоторых предельных теорем. На этой
лекции мы изложим основные свойства и теоремы, связанные с характеристическими функциями.
Наряду с действительными случайными величинами теория характеристических
функций требует привлечения комплекснозначных случайных величин.
Многие из определений и свойств, относящихся к действительным случайным
величинам переносятся на случай комплекснозначных случайных величин.
Введем теперь определение характеристической функции.
Определение 9.1. Характеристической функцией случайной величины X называется функция ϕX (t) = EeitX , t ∈ R, i - мнимая единица.
Замечание. Исходя из определения математического ожидания и интеграла Лебега
характеристическую функцию случайной величины X можно переписать в таком
виде:
Z∞
ϕX (t) =
eitx dF (x),
−∞

где F (x) — функция распределения X.
Если случайная величина X имеет плотность f (x), то ее характеристическая
функция имеет вид
Z∞
ϕX (t) =
eitx f (x) dx.
−∞

В этом случае характеристическая функция является преобразованием Фурье
для функции плотности f (x).
Если случайная величина X дискретна, тогда ее характеристическая функция
имеет вид
∞
X
eitxk P(X = xk ).
ϕX (t) =
i=1

Пример. Вычислим характеристическую функцию пуассоновской случайной величины X с параметром λ (X ∼ Π(λ)).
itX

ϕX (t) = Ee

=

∞
X

itn

e P (x = n) =

i=1

= e−λ

∞
X
i=1

∞
X
i=1

it n

eitn

e−λ λn
n!

(λe )
it
it
= e−λ eλe = eλ(e −1) .
n!

77

it

Итак, функция ϕX (t) = eλ(e −1) является характеристической функцией пуассоновской случайной величины X с параметром λ.
Пример. Вычислим характеристическую функцию стандартной нормальной случайной величины X (X ∼ N (0, 1)). Учитывая тот факт, что
1
√
2π

Z∞

x2

sin tx e− 2 dx = 0,
−∞

мы можем переписать характеристическую функцию в следующем виде
1
ϕX (t) = √
2π

Z∞
eitx e

2
− x2

−∞

1
dx = √
2π

Z∞

x2

cos tx e− 2 dx
−∞

Продифференцируем характеристическую функцию по t

0
Z∞
Z∞
x2
x2
1
1
−
0
ϕX (t) =  √
cos tx e 2 dx = √
x sin tx e− 2 dx
2π
2π
−∞

1
=√
2π

Z∞
−∞

−∞

t

x2
1
sin tx de− 2 = −t √
2π

Z∞

x2

cos tx e− 2 dx.
−∞

Получили дифференциальное уравнение
ϕ0X (t) = −tϕX (t),
Решением которого является функция
t2

ϕX (t) = ce− 2 .
Вычисляя значение характеристической функции в нуле найдем, что c = 1. Итак
характеристической функцией стандартной нормальной случайной величины X явt2
ляется функция ϕX (t) = e− 2 .
Сформулируем без доказательства одно свойство математического ожидания и
теорему Лебега о мажорируемой сходимости, которые нам потребуются в дальнейшем при доказательстве свойств характеристических функций и теорем с ними связанных.
Теорема 9.1 (свойство математического ожидания). Пусть случайные величины таковы, что |X| ≤ Y (п.н) и EY < ∞. Тогда существует E|X| и E|X| < EY .
Теорема 9.2 (теорема Лебега о мажорируемой сходимости). Пусть случайп. н.
ные величины таковы, что |Xn | ≤ Y , EY < ∞ и Xn −−→ X. Тогда E|X| < ∞
и
EXn → EX,

n→∞

и
E|Xn − X| → 0,
78

n → ∞.

9.1.1

Свойства характеристических функций

1◦ . ϕX (0) = 1
Доказательство. Свойство проверяется тривиально
Z∞

Z∞
e0 dF (x) =

ϕX (0) =
−∞

dF (x) = 1.
−∞

2◦ . |ϕX (t)| ≤ 1
Доказательство. Очевидно имеем оценки
¯
¯ ∞
¯ Z∞
¯Z
Z∞
¯
¯
itx
itx
|e |dF (x) =
dF (x) = 1.
|ϕX (t)| = ¯¯ e dF (x)¯¯ 6
¯
¯
−∞

−∞

−∞

3◦ . ϕX (t) равномерно непрерывна на R
Доказательство. Свойство следует из оценцки
|ϕ(t + h) − ϕ(t)| = |Eeitx (eihx − 1)| ≤ E|eihx − 1|
и теоремы Лебега о мажорируемой сходимости, согласно которой E|eihx − 1| → 0 при
h → 0.
4◦ . ϕX (−t) = ϕX (t)
Доказательство. Свойство следует из цепочки равенств
ϕX (−t) = Eei(−t)x = Ee−itx = Eeitx .

5◦ . ϕaX+b (t) = eitb ϕX (at)
Доказательство. Проводя тривиальные выкладки, убеждаемся в справедливости
свойства:
ϕaX+b (t) = Eeit(ax+b) = Eeitax eitb = eitb ϕX (at).

6◦ . Если для некоторого n ≥ 1 E|X|n < ∞, то при всех r ≤ n существуют производные ϕ(n) (t) и
Z
(n)
ϕ (t) = (ix)r eitx dF (x),
(1)
R

ϕ(r) (0)
.
EX =
ir
r

79

(2)

Доказательство. Если E|X|n < ∞, то E|X|r < ∞ для всех r < n. Рассмотрим
отношение
¶
µ ihX
ϕ(t + h) − ϕ(t)
e
−1
itX
= Ee
.
h
h
Поскольку
¯ ihx
¯
¯e − 1¯
¯
¯
¯ h ¯ ≤ |x|
и E|X| < ∞, то по теореме Лебега о мажорируемой сходимости имеем
µ
itX

lim Ee

h→0

eihX − 1
h

¶

µ
= E lim e

itX

h→0

eihX − 1
h

¶

Z∞
= iE(X e

itX

x eitx dF (x).

)=i
−∞

Поэтому существует производная ϕ0 (t) и
Z∞
ϕ0 (t) = iE(X eitX ) = i

x eitx dF (x).

−∞

Существование ϕ(r) (t), 1 ≤ r ≤ n и справедливость формулы (1) доказывается по
индукции. Формула (2) следует непосредественно из (1).
7◦ . ϕX (t) является неотрицательно определенной функцией
Доказательство. Неотрицательная определенность функции f (t) означает, что
для ∀n, ∀t1 , . . . , tn ∈ R и ∀z1 , . . . , zn ∈ C выполнено
n
X

zk zl f (tk − tl ) ≥ 0.

k,l=1

Покажем, что характеристическая функция ϕX (t) является неотрицательно определенной.
n
X

zk zl ϕX (tk − tl ) =

k,l=1

=

n
X
k,l=1
n
X

zk zl Ee

i(tk −tl )x

=

n
X

k,l=1
n
X

Ezk eitk x zl eitl x = E

k,l=1

=E

Ezk zl eitk x e−itl x

n
X

zk eitk x zl eitl x

k,l=1

wk wl = E

k,l=1

n
X

wk

k=1

n
X
l=1

wl = E

n
X
k=1

wk

n
X

wk ≥ 0.

k=1

Где мы сделали замену wk = zk eitk x , wl = zl eitl x .
Сформулируем свойство, которое является ключевым при доказательстве предельных теорем для сумм независимых случайных величин методом характеристических функций.
80

8◦ . Пусть X1 , ..., Xn — независимые случайные величины, тогда
ϕX1 +...+Xn (t) =

n
Y

ϕXk (t).

k=1

Замечание. Обратное, вообще говоря, неверно!
Перейдем к доказательсву свойства.
Доказательство. Ранее было доказано, что если X1 , . . . , Xn - независимые случайные величины, и существуют EXk , где k = 1, n, то существует EX1 . . . Xn и
EX1 . . . Xn = EX1 . . . EXn .
По лемме о группировке, любые комбинации sin и cos от независымых случайных
величин X1 . . . Xn (например cos tX1 , sin tX2 , cos tX3 . . . cos tXn ) будут независимыми.
Учитывая это и форумулу Эйлера eiα = cos α + i sin α, получим
ϕX1 +...+Xn (t) = Eeit(X1 +...+Xn )
= E(cos tX1 + i sin tX1 ) . . . (cos tXn + i sin tXn )
= (E cos tX1 + iE sin tX1 ) . . . (E cos tXn + iE sin tXn ) =

n
Y

ϕXk (t).

k=1

Мы сформулировали некоторые необходимые условия, которым удовлетворяют
характеристические функции. Таким образом, если для некоторой функции не выполняется одно из первых условий, то это означает, что рассматриваема функция не
может быть характеристической.
Сложнее обстоит дело с проверкой того, является ли данная функция характеристической. Сформулируем теорему Бохнера-Хинчина, дающую ответ на этот вопрос.
Теорема 9.3 (Теорема Бохнера-Хинчина). Непрерывная функция ϕ(t), t ∈ R,
такая что ϕ(0) = 1, является характеристической функцией некоторой случайной
величины X, тогда и только тогда, когда она неотрицательно определена.
Доказательство. Необходимость нами доказана выше. Достаточность доказывается труднее, и мы примем ее без доказательства. Доказательство можно найти в
книге Б.В. Гнеденко "Курс теории вероятностей".

9.2

Формула обращения

Cформулируем теорему, показывающую, что функция распределения F = F (x)
случайной величины X однозначно восстанавливается по своей характеристической
функции ϕ(t), и дадим явное представление F (x) через ϕ(t).
Теорема 9.4 (формула обращения). Пусть F = F (x) — функция распределения
и
Z∞
eitx dF (x)

ϕ(t) =
−∞

81

— ее характеристическая функция. Тогда, для любых двух точек a, b(a < b), где
функция F (x) непрерывна,
Zc

1
F (b) − F (a) = lim
c→∞ 2π

e−ita − eitb
ϕ(t) dt.
it

−c

Если

R∞

|ϕ(t)| dt < ∞, то функция распределения F (x) имеет плотность f (x),

−∞

Zx
f (y) dy,

F (x) =
−∞

и
1
f (x) =
2π

Z∞
e−itx ϕ(t) dt.
−∞

Доказательство. Обозначим
1
Φc ≡
2π

Zc

e−ita − eitb
ϕ(t) dt.
it

−c

Преобразуем Φc следующим образом:
Zc

−ita


−ita

itb

Z∞



−e
e
−e 
1
ϕ(t) dt =
eitx F (x) dx dt
it
2π
it
−c
−c
−∞


∞
Z
Z∞ Zc −ita
− eitb itx 
1
 e
Ψc (x) dF (x),
=
e dt dF (x) =
2π
it

Φc =

1
2π

−∞

e

Zc

itb

−c

−∞

где мы положили
1
Ψc (x) =
2π

Zc

e−ita − eitb itx
e dt
it

−c

и воспользовались теоремой Фубини (см. замечание в конце теоремы), справедливость которой в данном случае следует из того, что
¯
¯
¯
¯ ¯ −ita
¯ ¯Zb
¯ −ita
itb ¯
itb
¯
¯
¯
¯
¯e
e
−
e
−
e
−itx
itx
¯=¯
¯ = ¯ e dx¯ ≤ b − a,
¯
e
¯
¯ ¯
¯ ¯
¯
it
it
¯
¯
a

Z∞
dF (x) = 1
−∞

82

и
Zc Z∞
(b − a) dF (x) dt ≤ 2c(b − a) ≤ ∞.
−c −∞

Далее,
1
Ψc (x) =
2π

Zc

sin t(x − a) − sin t(x − b)
dt
t

−c

1
=
2π

c(x−a)
Z

c(x−b)
Z

sin v
1
dv −
v
2π

−c(x−a)

sin v
dv
v

−c(x−b)

Функция
Zt
g(s, t) =

sin v
dv
v

s

равномерно непрерывна по s и t и
g(s, t) → π
при t ↑ ∞ и s ↓ −∞. Поэтому существует такая константа C, что для всех c и x
|Ψc (x)| < C < ∞. Отсюда следует, что
Ψc (x) → Ψ(x),

c → ∞,

где


если x < a или x > b;
0,
Ψ(x) = 1/2, если x = a или x = b;


1,
если a < x < b.
Тогда по теореме Лебега о мажорируемой сходимости возникает предел
Z∞

1
1
Ψ(x) dF (x) = Q(a, b) + Q(a) + Q(b) = Q(a(a; b]) = F (b) − F (a).
2
2

−∞

Последнее равенство справедливо только для a и b, являющихся точками непрерывности F (x).
Таким образом, доказана первая часть теоремы.
Вторая часть доказывается проще.
Обозначим
Z∞
1
e−itx ϕ(t) dt.
f (x) =
2π
−∞

83

Из теоремы о мажорируемой сходимости слудует, что эта функция непрерывна по x
и, значит, она интегрируема на [a, b]. Применяя теорему Фубини, получим


Zb
Zb Z∞
1
 e−itx ϕ(t) dt dx
f (x) dx =
2π
a
a
−∞
 b

 b

∞
Z
Z
Zc
Z
1
1
ϕ(t)  e−itx dx dt = lim
ϕ(t)  e−itx dx dt
=
c→∞ 2π
2π
−∞

a

Zc
= lim

c→∞

−c

a

1 e−ita − e−itb
ϕ(t) dt = F (b) − F (a)
2π
it

c

для всех точек a и b непрерывности функции F (x). Отсюда вытекает, что
Zx
f (y) dy,

F (x) =

x ∈ R,

−∞

а так как f (x) - непрерывная, а F (x) - неубывающая функции, то f (x) есть плотность
F (x).
Замечание. Теорема Фубини будет сформулирована и доказана в курсе функционального анализа, а пока мы ее принимаем на веру. Теорема нужна нам, чтобы
показать, что мы имеем право менять пределы интегрирования у интеграла.
Замечание. Формулы
Z∞
eitx f (x) dx,

ϕ(t) =
−∞

1
f (x) =
2π

Z∞
e−itx ϕ(t) dt
−∞

очень похожи. Первую из них, как отмечалось выше, обычно в анализе называют
преобразование Фурье функции f (x), вторую — обратным преобразованием Фурье.
Подробно с этой темой вы познакомитесь в курсах математического и функционального анализов.

84

Лекция 10

10.1

Слабая cходимость

Определение 10.1. Последовательность функций распределения
F1 (x), F2 (x), . . . , Fn (x), . . .
слабо сходится к функции F (x), если при n → ∞ она сходится к этой последней
в каждой ее точке непрерывности.
Замечание. Тот факт, что последовательность функций распределения {Fn (x)}
слабо сходится к функции F (x) будем обозначать Fn (x) ⇒ F (x).
Замечание. Рассмотрим X1 , X2 , . . . — последовательность одинаково распределенных случайных величин с P(Xi = 1) = p, P(Xi = 0) = q, p+q = 1. Используя понятие
сходимости по вероятности, запишем закон больших чисел в виде
Sn p
−
→ p,
n

n → ∞.

(1)

Обозначим
½

¾
Sn
6x ,
n

Fn (x) = P
(
1, x > p;
F (x) =
0, x < p.

Из (1) легко вывести, что Fn (x) → F (x) для всех точек x ∈ R, кроме точки
x = p, где функция F (x) терпит разрыв.
Отсюда следует, что слабая сходимость не влечет за собой поточечную сходимость Fn (x) к F (x).
Возникает вопрос, всегда ли будет предельная функция являться функцией распределения. Ответ на этот вопрос отрицательный. Приведем пример поясняющий
сказанное.
Пример. Рассмотрим последовательность функций распределения


при x 6 −n;
0,
Fn (x) = 1/2, при −n < x < n;


1,
при x > n.
Очевидно, чтобы предельная функция F (x) ≡ 1/2 — не является функцией распределения.
Следовательно, мы должны накладывать некоторые условия, чтобы предельная
функция была функцией распределения.
85

Замечание. Пусть X, X1 , X2 , . . . — случайные величины и FXn (x) ⇒ FX (x). В этом
случае говорят, что случайные величины X1 , X2 , . . . сходятся по распределению к
d
случайной величине X, и записывают Xn −
→ X. Эта запись наглядна и поэтому часто
в формулировках предельных теорем ее предпочитают записи FXn (x) ⇒ FX (x).
Утверждение 10.1. Пусть последовательность функций распределения {Fn (x)}
сходится к функции F (x) на всюду плотном множестве D. Тогда Fn (x) ⇒ F (x).
Доказательство. Пусть x — любая точка и x0 и x00 — какие-нибудь точки множества D, такие что x0 6 x 6 x00 . При этом также
Fn (x0 ) 6 Fn (x) 6 Fn (x00 ).
Следовательно,
lim Fn (x0 ) 6 lim Fn (x) 6 lim Fn (x) 6 lim Fn (x00 ).

n→∞

n→∞

n→∞

n→∞

А так как
lim Fn (x0 ) = F (x0 )

n→∞

lim Fn (x00 ) = F (x00 ),

и

n→∞

то и
F (x0 ) 6 lim Fn (x) 6 lim Fn (x) 6 F (x00 ).
n→∞

n→∞

Но средние члены в этих неравенствах не зависят от x0 и x00 , поэтому
F (x − 0) 6 lim Fn (x) 6 lim Fn (x) = F (x + 0).
n→∞

n→∞

Если функция F (x) в точке x непрерывна, то
F (x − 0) = F (x) = F (x + 0).
Следовательно, в точках непрерывности функции F (x)
lim Fn (x) = F (x).

n→∞

Далее нам понадобятся две теоремы, принадлежащие Хелли.
Теорема 10.1 (Первая теорема Хелли). Из любой последовательности {Fn (x)}
функций распределения можно выделить по крайней мере одну слабо сходящуюся
подпоследовательность.
Замечание. Идея доказательства теоремы очень похожа на ту, что использовалась
при доказательстве теоремы Арцела из курса математического анализа, заключающуюся в том, что из равностепенно непрерывной и равномерно ограниченной функциональной последовательности можно извлечь по крайней мере одну подпоследовательность, сходящуюся равномерно на некотором компакте. Так что при желании
читатель может провести доказательство самостоятельно.
86

Доказательство. Рассмотрим какое-нибудь всюду плотное множество D точек
x01 , . . . , x0n , . . .. Возьмем значения функций последовательности {Fn (x)} в точке x01
F1 (x01 ), F2 (x01 ), . . . , Fn (x01 ), . . . .
Так как множество этих значений ограничего, то по теореме Больцано-Вейерштрасса
из курса математического анализа, оно содержит по меньшей мере одну подпоследовательность
F11 (x01 ), F12 (x01 ), . . . , F1n (x01 ), . . . ,
сходящуюся к некоторому предельному значению G(x01 ). Рассмотрим теперь множество чисел
F11 (x02 ), F12 (x02 ), . . . , F1n (x02 ), . . . ,
Так как и это множество ограничено, то и в нем существует подпоследовательность,
сходящаяся к некоторому предельному значению G(x02 ). Таким образом из последовательности {F1n (x)} мы можем выделить подпоследовательность
F21 (x), F22 (x), . . . , F2n (x), . . .
такую, что одновременно lim F2n (x01 ) = G(x01 ) и lim F2n (x02 ) = G(x02 ). Продолжим
n→∞

n→∞

такое выделение подпоследовательностей {Fkn (x)}, для которых одновременно для
всех r 6 k выполнено lim Fkn (x0r ) = G(x0r ).
n→∞

Составим теперь диагональную ("канторовскую") последовательность {Fnn (x)},
сходящуюся по всем x0k к G(x). Так как все Fnn (x) неубывают и ограничены, то
G(x) будет неубывающей и ограниченой. В силу доказанного выше утверждения
Fnn (x) ⇒ G(x).
Теорема 10.2 (Вторая теорема Хелли). Пусть g(x) — непрерывная функция и
Fn (x) ⇒ F (x), при этом F (+∞) − F (−∞) = 1. Тогда
Z∞

Z∞
g(x) dFn (x) →

−∞

g(x) dF (x).
−∞

Доказательство. Сначала докажем, что для некоторого фиксированного A > 0
ZA

ZA
g(x) dFn (x) →

−A

g(x) dF (x).

(2)

−A

Фиксируем произвольное ε > 0. Разделим отрезок [−A, A] точками x0 , . . . , xN :
−A = x0 < x1 < . . . < xN = A, так что xi — точки непрерывности F (x) и
|g(x) − g(xi )| < ε для ∀x ∈ [xi−1 , xi ]. Последнее возможно, т.к. g(x) равномерно
непрерывна на [−A, A].
Определим ступенчатую функцию gε (x) на [−A, A]:
gε (x) = g(xi )

для x ∈ [xi−1 , xi ) i = 1, N
87

и

gε (−A) = gε (A).

Тогда, очевидно, что для ∀x ∈ [−A, A] |gε (x) − g(x)| < ε. Рассмотрим разность
интегралов 1:
¯ A
¯
¯Z
¯ ZA
ZA
¯
¯
¯ g(x) dFn (x) − g(x) dF (x)¯ 6
|g(x) − gε (x)| dFn (x)
¯
¯
¯
¯
−A
−A
−A
¯ A
¯
¯Z
¯ ZA
ZA
¯
¯
¯
+ ¯ gε (x) dFn (x) − g(x) dF (x)¯¯ + |g(x) − gε (x)| dF (x)
¯
¯
−A

−A

6 2ε + M

N
X

−A

(|Fn (xk ) − F (xk )| + |Fn (xk−1 ) − F (xk−1 )|),

k=1

где M = supk |g(x)|.
Так как Fn (x) ⇒ F (x), то при n → ∞ последнее слагаемое стремится к нулю,
следовательно (2) доказано.
Фиксируем ε > 0, тогда ∃A : F (−A) < ε/4, 1 − F (A) < ε/4. Не ограничивая
общности, считаем, что −A и A — точки непрерывности F . Тогда, т.к. Fn (−A) →
F (−A) и Fn (A) → F (A), то ∃n0 : n > n0 :
Fn (−A) < ε/2

и

1 − Fn (A) < ε/2.

Таким образом имеем:
¯ ∞
¯ ¯ A
¯
¯Z
¯ ¯Z
¯
Z∞
ZA
¯
¯ ¯
¯
¯
¯ 6 ¯ g(x) dFn (x) − g(x) dF (x)¯
g(x)
dF
(x)
−
g(x)
dF
(x)
n
¯
¯ ¯
¯
¯
¯ ¯
¯
−∞
−∞
−A
−A
¯
¯ ¯
¯ ¯
¯
¯ Z
¯ ¯ Z
¯ ¯ ZA
¯
ZA
¯
¯ ¯
¯ ¯
¯
¯
¯ ¯
¯ ¯
+¯
g(x) dFn (x)¯ + ¯
g(x) dFn (x)¯ 6 ¯ g(x) dFn (x) − g(x) dF (x)¯¯
¯
¯ ¯
¯ ¯
¯
¯
¯ ¯
¯
|x|>A

−A

|x|<A

−A

+M (Fn (−A) + (1 − Fn (A)) + F (−A) + (1 − F (A))
¯ A
¯
¯Z
¯
ZA
¯
¯
¯
6 ¯ g(x) dFn (x) − g(x) dF (x)¯¯ + M ε + M ε/2.
¯
¯
−A

−A

В силу (2) правая часть стремится к нулю. Таким образом теорема доказана.

10.2

Предельные теоремы
для характеристических функций

Из прошлой лекции мы знаем, что между функциями распределения и характеристическими функциями существует взаимно однозначное соответствие. Следующие
две предельные теоремы показывают, что соответствие не только взаимно однозначно, но и непрерывно.
Теорема 10.3 (Прямая предельная теорема). Если последовательность {Fn (x)}
функций распределения слабо сходится к функции распределения F (x), то соответсвующая последовательность {ϕn (t)} характеристических функций сходится
к характеристической функции ϕ(t).
88

Доказательство. Эта теорема является прямым следствием второй теоремы Хелли. Действительно, из Fn (x) ⇒ F (x) вытекает, что
Z∞

Z∞
eitx dFn (x) →

ϕn (t) =
−∞

eitx dF (x) = ϕ(t).
−∞

Теорема 10.4 (Обратная предельная теорема). Пусть {ϕn (t)} — последовательность характеристических функций, сходящаяся к непрерывной в нуле функции ϕ(t). Тогда последовательность {Fn (x)} функций распределения слабо сходится к некоторой функции распределения F (x), и ϕn (t) и ϕ(t) — характеристические
функции Fn (x) и F (x) соответсвенно.
Замечание. Возникает вопрос, всегда ли будет характеристической функцией предел ϕ(t) последовательности {ϕn (t)} характеристических функций.
Ответ на этот вопрос отрицательный. Рассмотрим пример, поясняющий сказанное.
Пример. Рассмотрим последовательность характеристических функций

0,
при t 6 −1/n;



n t + 1,
при −1/n < t 6 0;
ϕn (t) =

−n t + 1, при 0 < t < 1/n;



0,
при x > 1/n.
Очевидно, что предельная функция


0,
ϕ(t) = 1


0,

при t < 0;
при t = 0;
при t > 0

не будет характеристической, т.к. она не является непрерывной.
Доказательству теоремы предпошлем лемму
Лемма 10.1. Пусть X — случаяная величина. Тогда для ∀τ > 0 имеет место
неравенство
¯
¯
¯
¯
Zτ
¯ 1
¯
P(|X| 6 2/τ ) > 2 ¯¯
(3)
ϕ(t) dt¯¯ − 1.
¯ 2τ
¯
−τ

Доказательство.

¯
¯ ¯
¯
¯
¯ ¯
¯
Zτ
Zτ
¯ 1
¯ ¯ 1
¯
itX
¯
¯
¯
ϕ(t) dt¯ = ¯
Ee dt¯¯
¯ 2τ
¯
¯ ¯ 2τ
¯
−τ
−τ
¯
¯
¯
¯ ¯
¯
Zτ
¯ 1
¯ ¯ sin τ X ¡
¢¯
itX
¯
¯
¯
= ¯ E e dt¯ = ¯E
I|X|62/τ + I|X|>2/τ ¯¯
2τ
τ
X
¯
¯
−τ

6 P(|X| 6 2/τ ) +

1
(1 − P(|X| 6 2/τ )) .
2

89

Теперь мы обладаем всем, чтобы доказать обратную предельную теорему.
Доказательство. По первой теореме Хелли из последовательности Fn (x) можно
выделить подпоследовательность Fnn (x), слабо сходящуюся к некоторой функции
F (x).
Докажем, что функция F (x) является функцией распределения. Для этого достаточно доказать, что
F (+∞) − F (−∞) > 1.
А так как в силу первой теоремы Хелли F (x) неубывает и 0 6 F (−∞) 6 F (∞) 6 1,
то отсюда будет следовать, что F (x) — функция распределения. В силу леммы 2
¯
¯
¯
¯
Zτ
¯
¯ 1
¯
ϕnn (t) dt¯¯ − 1.
Fnn (2/τ ) − Fnn (−2/τ ) > 2 ¯
¯
¯ 2τ

(4)

−τ

В неравенстве (4) можно считать, что −2/τ, 2/τ — точки непрерывности функции F (x).
Устремив n → ∞ и применяя теорему Лебега о мажорируемой сходимости, получаем
¯
¯
¯
¯
Zτ
¯ 1
¯
¯
F (2/τ ) − F (−2/τ ) = lim Fnn (2/τ ) − Fnn (−2/τ ) > lim 2 ¯
ϕnn (t) dt¯¯ − 1
n→∞
n→∞
¯ 2τ
¯
−τ
¯
¯
¯
¯
Zτ
¯
¯ 1
¯
ϕ(t) dt¯¯ − 1.
= 2¯
¯
¯ 2τ
−τ

Тогда, так при τ → 0
1
2τ

Zτ
ϕ(t) dt → ϕ(0),
−τ

то
¯
¯
¯
¯
Zτ
¯ 1
¯
¯
F (+∞) − F (−∞) > lim 2 ¯
ϕ(t) dt¯¯ − 1 = 1.
τ →0
¯ 2τ
¯
−τ

Покажем теперь, что Fn (x) ⇒ F (x). Пусть это не так. Тогда существуют две под2
1
(x) слабо сходящиеся к F 1 (x) и F 2 (x). При этом
(x) и Fnn
последовательности Fnn
1
2
F (x) 6= F (x).
Пусть ϕ1nn (t) → ϕ1 (t), где ϕ1nn (t) и ϕ1 (t) — характеристические функции, отвечаю1
(x) и F 1 (x) соответственно. И ϕ2nn (t) → ϕ2 (t), где ϕ2nn (t) и ϕ2 (t) — характерищие Fnn
2
(x) и F 2 (x) соответственно. Т.к. F 1 (x) 6= F 2 (x),
стические функции, отвечающие Fnn
то по прямой теореме о непрерывном соответсвии ϕ1 (t) 6= ϕ2 (t). Но это противоречит
условиям теоремы. Следовательно Fn (x) ⇒ F (x).

90

Замечание. Покажем, что требование непрерывности в нуле предельной функции
ϕ(t) существенно.
Рассмотрим последовательность нормально распределенных с параметрами 0 и n
случайных величин Xn (Xn ∼ N (0, n)). Тогда Xn имеет характеристическую функ2
цию ϕn (t) = e−nt /2 . Очевидно, что
(
0, если t 6= 0,
lim ϕn (t) = ϕ(t), где ϕ(t) =
n→∞
1, если t = 0.
Таким образом предельная функция ϕ(t) разрывна при t = 0. Следовательно, теорема непрерывности не может иметь место. Это следует из соотношения
Fn (x) = P{Xn 6 x} = P{n−1/2 Xn 6 xn−1/2 }
1
= Φ(n−1/2 x) →
n → ∞.
2
Cледовательно, предел lim Fn (x) = F (x) существует для каждого x ∈ R, но функn→∞
1
ция F (x) = не является функцией распределения.
2

91

Лекция 11

11.1

Метод характеристических функций в доказательстве предельных теорем

Теперь мы обладаем хорошо развитым аппаратом характеристических функций и
можем доказать некоторые простые предельные теоремы.
Cформулируем и докажем закон больших чисел в форме Хинчина.
Теорема 11.1 (закон больших чисел). Пусть X1 , X2 , . . . — последовательность
независимых одинаково распределенных случайных величины c EX1 < ∞ и EX1 = m.
Sn p
Тогда
−
→ m, т.е
n
¯
½¯
¾
¯
¯ Sn
¯
¯
P ¯ − m¯ > ε → 0,
n → ∞,
n
где Sn = X1 + . . . + Xn .
Замечание. Напомним, что в законе больших чисел в форме Чебышева было требование существования ограниченных дисперсий. В усиленном законе больших чисел в
форме Колмогорова требовалась сходимость некоторого ряда даже в случае не всех
ограниченных дисперсий. У Хинчина же требуется только ограниченность первых
моментов.
Перед тем как перейти к доказательству ЗБЧ в форме Хинчина, выведем оценку
для характеристической функции.
Теорема 11.2. Пусть ϕX (t) — характеристическая функция некоторой случайной
величины X. Если E|X|n < ∞ , то
ϕX (t) = 1 + itEX + . . . +
где Rn (t) = o(tn ),

(it)n
EX n + Rn (t),
n!

(1)

t → 0.

Доказательство. Имеем
Z∞
eitx dF (x)

ϕX (t) =
−∞

Z µ

=

e

itx

(itx)n
− 1 − itx − . . . −
n!

¶

Z µ
dF (x) +

R

(itx)n
1 + ... +
n!

¶
dF (x). (2)

R

Из существования E|X|n < ∞ вытекает существование E|X|r < ∞ для ∀r 6 n.
Таким образом, мы можем переписать (2) в виде
(it)n
EX n + Rn (t).
ϕX (t) = 1 + itEX + . . . +
n!
92

Покажем, что
¯
¯
n¯
n+1
¯ iy
(iy)
¯e − 1 − iy − . . . −
¯ 6 |y|
.
¯
n! ¯ (n + 1)!

(3)

Для n = 1 имеем
¯ y
¯
¯ Z
¯ Z|y|
¯
¯
|eiy − 1| = ¯¯i eiu du¯¯ 6 1 du = |y|.
¯
¯
0

0

Воспользуемся индукцией и получим
¯ Zy µ
¯
¶
n−1
n¯
¯ iy
(iu)
(iy)
iu
¯e − 1 − iy − . . . −
¯6
e − 1 − ... −
du
¯
n! ¯
(n − 1)!
0

¯
Z|y| n
Z|y| ¯
n−1 ¯
¯ iu
(iu)
|u|
|y|n+1
¯ du 6
6 ¯¯e − 1 − . . . −
du
=
.
(n − 1)! ¯
n!
(n + 1)!
0

0

Выведем еще одну оценку:
¯
¯
¯
¯
n
n−1
¯ |y|n |y|n
¯ iy
(iy)
|y|n
(iy)
¯6
¯e − 1 − iy − . . . −
−
+
=
2
.
¯
(n − 1)! | {z
n! }¯¯
n!
n!
n!
¯|
{z
}
Перепишем Rn (t) в таком виде
¶
Z
Z µ
(itx)n
itx
dF (x) =
Rn (t) =
e − 1 − itx − . . . −
n!
R

(4)

Z
+

|X|6a

.

|X|>a

Оценим |Rn (t)| сверху используя (3) и (4)
Z
Z
|tx|n+1
|tx|n
|Rn (t)| 6
dF (x) +
2
dF (x)
(n + 1)!
n!
|X|6a
n+1 n+1

n

|t| a
t
6
+2
(n + 1)!
n!

Z

|X|>a
n

|x| dF (x) 6 |t|

tn
e +2
n!

Z

n+1 a

|X|>a

|x|n dF (x).
|X|>a

Выберем теперь a > 0 так, чтобы
Z
ε
2
|x|n dF (x) < .
n!
2
|X|>a

Затем выберем δ = δ(ε; a) так, чтобы
ε
|t|ea < .
2
Таким образом, мы получили вторую оценку.

93

Перейдем теперь к доказательству закона больших чисел.
Sn

Доказательство. Пусть Sn = X1 + . . . + Xn , ϕ(t) = EeitX1 и ϕ Sn (t) = Eeit n . Тогда
n
в силу независимости случайных величин и свойства 8 характеристических функций
·
¸n
t
ϕ Sn (t) = ϕ( ) .
n
n
Согласно (1) для n = 1
ϕ(t) = 1 + itm + o(t),

t → 0.

Значит, для всякого t ∈ R
t
t
1
ϕ( ) = 1 + i m + o( ),
n
n
n

n → ∞,

и поэтому
·

¸n
1
t
ϕ Sn (t) = 1 + i m + o( ) → eitm .
n
n
n
Функция ϕ(t) = eitm непрерывна в нуле и является характеристической функцией
вырожденного распределения вероятностей, сосредоточенного в точке m. Поэтому
Sn d
→
− m,
n
значит нам осталось доказать, что отсюда следует, что
Sn p
→
− m.
n
По обратной теореме F Sn (x) ⇒ Fm (x). Фиксируем произвольное ε > 0.
n
¯
µ¯
¶
¯ Sn
¯
P ¯¯ − m¯¯ < ε = F Sn (m + ε) − F Sn (m − ε) → Fm (m + ε) − Fm (m − ε) = 1.
n
n
| {z } | {z }
n
=1

=0

Что и требовалось доказать.

11.1.1

Центральная предельная теорема

Перейдем к центральной предельной теореме. Эта теорема примечательна уже тем,
что в ее названии содержится слово «центральная» , показывающее, что эта теорема
находится не на переферии теории вероятностей, а является центральной.
Предельная теорема Муавра-Лапласа может быть получена как следствие центральной предельной теоремы.
Перейдем к формулировке теоремы.
Теорема 11.3 (Центральная предельная теорема для независимых одинаково распределенных случайных величин). Пусть X1 , X2 , . . . — последовательность независимых одинаково распределенных (невырождненных) случайных
величин с EX12 < ∞ и Sn = X1 + . . . + Xn . Тогда при n → ∞ для ∀x ∈ R имеем
¾
½
Zx
z2
1
Sn − ESn
√
6 x → Φ(x) = √
(5)
e− 2 dz.
P
DSn
2π
−∞

94

Доказательство. Пусть EX1 = m, DX1 = σ 2 и
ϕ(t) = Eeit(X1 −m) .
Обозначим
ϕn (t) = Ee

n −ESn
it S√
DS
n

,

то получим, что
·

¸n
t
ϕn (t) = ϕ( √ ) .
σ n
В силу формулы (1) для n = 2
ϕ(t) = 1 −

σ 2 t2
+ o(t2 ),
2

t → 0.

Поэтому для любого t ∈ R и n → ∞
·
¸
t2
σ 2 t2
1
ϕn (t) = 1 − 2 + o( ) → e− 2 .
2σ n
n
t2

Функция e− 2 является характеристической функцией стандартного нормального
распределения ( N (0, 1) ). В силу теорем о непрерывном соответсвии между функциями распределения и характеристическими функциями центральная предельная
теорема доказана.
Замечание. Часто центральную предельную теорему записывают в следующем виде
Sn − ESn d
√
−
→ N (0, 1).
DSn
Так как в (5) функция Φ(x) непрерывна, то на самом деле сходимость равномерная и можно поставить вопрос о скорости сходимости.
Дадим ответ на этот вопрос сначала для случая разнораспределенных независимых случайных величин, а потом приведем соответствующий результат для случая
одинаково распределенных случайных величин.
Теорема 11.4 (центральная предельная теорема для разнораспределенных
слагаемых). Пусть X1 , X2 , . . . — последовательность независимых случайных величин, для которых существуют EXk = ak , DXk = b2k , ck = E|Xk − ak |3 . Обозначим
Sn = X1 + . . . + Xn ,
An = ESn = a1 + . . . + an ,
Bn2 = DSn = b21 + . . . + b2n ,
C n = c1 + . . . + cn ,
Sn − A n
Tn =
.
Bn
Тогда
sup |FTn (x) − Φ(x)| 6 α0
x∈R

где α0 — абсолютная константа.
95

Cn
,
Bn3

В случае независимых одинаково распределенных случайных величин ответ на
вопрос о скорости сходимости дает теорема (неравенство) Берри - Эссеена.
Теорема 11.5 (Берри-Эссеен). Пусть X1 , X2 , . . . — последовательность независимых одинаково распределенных случайных величин с EX13 < ∞. Тогда в обозначениях предыдущей теоремы имеем:
sup |FTn (x) − Φ(x)| 6 C
x∈R

E|X1 − EX1 |3
√
,
σ3 n

где C - универсальная константа, точное значение которой еще не известно, при1
водятся только неравенства: √ 6 C 6 0.7655.
2π
Рассмотрим вопрос применения центральной предельной теоремы.
Пример. При измерении некоторой величины a (длины доски в аудитории) мы
получаем приближенное значение X. Сделанная ошибка δ = X − a может быть
представлена в виде суммы двух ошибок
δ = (X − EX) + (EX − a),
первая из которых называется случайной ошибкой, а вторая систематической. Пусть
результаты измерений лишены систематической ошибки, т.е EX = a. Так бывает не
всегда, но для простоты допустим. Случайная ошибка δ имеет нулевое математическое ожидание Eδ = 0. Положим Dδ = σ 2 . Для уменьшения ошибки производят n
независимых измерений X1 , . . . , Xn . Они представляют собой независимые и одинаково распределенные случайные величины. В качестве приближенного значения a
принятно брать среднее арифметическое из результатов наблюдений
â =

X1 + . . . + Xn
.
n

В силу центральной предельной теоремы
√
ε n

¯
µ¯
√ ¶
Zσ
2
¯ X1 + . . . + Xn − na ¯ ε n
1
− z2
¯
¯
√
√
P(|â − a| < ε) = P ¯
<
∼
e
dz.
¯
σ
σ n
2π √
− ε σn

Если мы начнем увеличивать число измерений, наш результат√ будет становиться
ε n
√
Rσ − z2
1
ε n
e 2 dz = 0.997 и
все лучше и лучше. В частности, если взять σ = 3, то √
2π − ε√n
σ
следовательно
µ
¶
3σ
P |â − a| < √
≈ 0.997,
n
что уже является неплохой точностью.

96

Лекция 12

12.1
12.1.1

Условное математическое ожидание, условное
распределение случайной величины
Условное математическое ожидание, условное распределение в случае дискретных случайных величин

Определение 12.1. Условной вероятностью события A при уже произошедшем (при условии) B (обязательно P(B) > 0) называется величина
P(AB)
= P(A|B) — это её обозначение.
P(B)
Замечание. Пространство (Ω,F, P(·|B)) — также вероятностное пространство, на
котором P(A|B) как функция от события A есть вероятность.
Рассмотрим дискретные случайные величины X и Y такие, что
X принимает значения a1 , . . . , ak с вероятностями p1 , . . . , pk , а
Y принимает значения b1 , . . . , bm с вероятностями q1 , . . . , qm .
В качестве события B рассмотрим B = {Y = bi } (bi фиксировано), P (B) = qi > 0 ,
тогда можем определить математическое ожидание случайной величины X относительно меры P(·|B) как
E(X|B) = E(X|Y = bi ) =

k
X

aj P(X = aj |B)

j=1

Определение 12.2. Условным математическим ожиданием E(X|Y ) случайной величины X относительно случайной величины Y называется случайная
величина, которая принимает значения E(X|Y = bi ) с вероятностями P(Y = bi ),
и определяется как отображение следующего вида
∀ω ∈ Y −1 (bi ) ∈ F
данное отображение обозначим
g(Y (ω)) = E(X|Y = bi ).
Так как Y — случайная величина, то отображение g(Y ) также является случайной величиной.
Определение 12.3. Условным распределением случайной величины X относительно случайной величины Y называется случайная величина, которая для
∀A ∈ F является борелевской σ-алгеброй на прямой R и для любого ω ∈ Y −1 (bi )
принимает значение
P(x ∈ A|y = bi ) = E(Ix∈A |Y = bi )
97

12.1.2

Условное математическое ожидание, условное распределение в случае абсолютно непрерывных случайных
величин

Рассмотрим случай абсолютно непрерывной случайной величины Y , для нее (в силу
ее абсолютной непрерывности) следует, что P(Y = yi ) = 0, где yi — некоторое
фиксированное число. Очевидно, что в данном случае мы не можем воспользоваться
рассуждениями для дискретного случая.
Рассмотрим частный случай следующего вида — случайный вектор (X, Y ) имеет
плотность f (x, y), причем f (x, y) ∈ C. Предположим, что для произвольного достаточно малого ε > 0 выполнено
P(−ε < Y − y0 < ε) > 0

(A)

Таким образом, если fY (y) — плотность случайной величины Y , то
Z +∞
fY (y) =
f (x, y)dx,
−∞

и из формулы (A) следует, что fY (y0 ) > 0.
Рассмотрим ∀u ∈ R
P(X < u, Y ∈ (y0 − ε, y0 + ε))
P(y0 − ε < Y < y0 + ε)
R u R y0 +ε
Z u
f (x, y)dxdy
f (x, y0
−∞ y0 −ε
=
−−→
dx
R y0 +ε
ε→0
f (y)dy
−∞ fY (y0 )
y0 −ε Y

P(X < u|Y ∈ (y0 − ε, y0 + ε)) =

df

= P(X < u|Y = y0 )

Определение 12.4.
Z

u

P(X < u|Y = y0 ) =
−∞

f (x, y0 )
dx
fY (y0 )

Определение 12.5. Условной плотностью случайной величины X при условии
Y = y0 называется величина, равная

 f (x, y0 )
fY (y0 )

0

, если fY (y0 ) > 0;
, если fY (y0 ) = 0.

Замечание. Пусть случайная величина Y имеет равномерное распределение на отрезке [0; 1]. Обозначим
NY = {z ∈ R : fY (z) = 0}
тогда
Z
P(Y ∈ NY ) =

fY (z)dz = 0.
NY

98

Замечание. Так как f (z, y) и fY (y) — плотности, то
f (z, y0 )
> 0,
fY (y0 )
и

Z
R

f (z, y0 )
1
dz =
fY (y) )
fY (y0 )

Следовательно, условная плотность

Z
f (z, y0 )dz =
R

fY (y0 )
= 1.
fY (y0 )

f (z, y0 )
есть плотность.
fY (y0 )

Определение 12.6. Условным математическим ожиданием случайной величины X при фиксированном значении случайной величины Y называется величина, равная E(X|Y = y0 ) =

+∞

 R xf (x, y0 ) dx , если f (y ) > 0;
Y
0
−∞ fY (y0 )

0
, если fY (y0 ) = 0.
Определение 12.7. Условным математическим ожиданием случайной величины X относительно случайной величины Y называется случайная величина
g(Y ) :
g(Y )(ω) = g(Y (ω)) = E(X|Y (ω)).

(B)

Утверждение 12.1. Для любой ограниченной борелевской функции h(y)
Eh(Y )X = Eh(Y )g(Y )

(C)

где g(Y ) из формулы (B)
Доказательство. Распишем правую часть:
Z +∞
Z +∞
Z +∞
xf (x, y0 )
h(y)fY (y)dy
h(y)g(y)fY (y)dy =
Eh(Y )g(Y ) =
dx
fY ()y0
−∞
−∞
−∞
Z +∞ Z +∞
=
h(y)x
f (x, y) dxdy
| {z }
| {z }
−∞
−∞
ф-ия сл. в. плотность сл. в.

= Eh(Y )X.
Можно показать, что равенство (C) однозначно определяет g(Y ), то есть если (C)
выполнено для всех ограниченных борелевских функций h(y) при функциях g1 (y)
и g2 (y)(где g1 (y) и g2 (y) считаются измеримыми отностиельно BY — борелевской
σ-алгебры на прямой, порожденной случайной величиной Y ), то
g1 (y) = g2 (y) с вероятностью 1.
Таким образом формулу (C) можно считать определением условного математического ожидания.
Замечание. Функция g1 (y) называется измеримой относительно BY , если
{z : g(z) < a} ∈ BY ∀a ∈ R.
Замечание. Мы не всегда можем взять в качестве g(Y ) случайную величину X,
так как она может не быть измеримой относительно BY .
99

12.2

Свойства условного математического ожидания

Пусть X и Y — случайные величины, тогда имеют место свойства:
1◦ . E(cX|Y ) = cE(X|Y );
2◦ . E(X + Z|Y ) = E(X|Y ) + E(Z|Y );
3◦ . E(X|X) = X (так как E(X|X = al ) = al );
4◦ . Если X и Y — независимые случайные величины, то
j=k
X

j=k

P(X = aj , Y = bi ) X
P(Y = bi )
E(X|Y ) =
aj
=
aj P(X = aj )
= EX,
P(Y
=
b)i)
P(Y
=
b
)
i
j=1
j=1
то есть равно константе.
5◦ . EX = E(E(X|Y ))

100

Лекция 13

13.1

Введение в математическую статистику

Математическая статистика — это математическая дисциплина, родственная теории вероятностей. Она базируется на методах теории вероятностей, но решает свои
задачи своими методами.
Математические модели случайных величин в теории вероятностей основываются на понятии вероятностного пространства (Ω, A, P). Где Ω — непустое множество,
называемое пространством элементраных исходов, A — класс событий из Ω. Как
известно, чтобы A стал σ - алгеброй надо наложить некоторые требования. P —
вероятность, заданная на событиях из A. В теории вероятностей P считается заданной, и задачей теории вероятностей считается разработка методов определения
вероятностей более сложных событий.
На практике при изучении некоторого эксперимента редко бывает, что P полностью известна. Часто можно лишь утверждать, что P является элементом некоторого
класса P. Этот класс может включать все вероятности, которые можно задать на
A, а может представлять собой более узкое семейство вероятностей. В любом случае P — это совокупность допустимых вероятностей P. Таким образом, мы пришли
к понятию вероятносто-статической модели (или просто к статистической модели),
понимая под этим набор (Ω, A, P).
Пример. Рассмотрим эксперимент, состоящий из n независимых испытаний, в каждом из которых наблюдается 1 в случае успеха и 0 в случае неудачи с вероятностями соответственно p и q = 1 − p. Исход эксперимента можно представить вектором
ω = (x1 , . . . , xn ), где xi = 0, 1. Если вероятность p успеха известна, то вероятностной
моделью является набор (Ω, A, P), где Ω = {ω : ω = (x1 , . . . , xn ), xi = 0, 1}, A —
совокупность всех подмножеств Ω и вероятностью P:
P

P(w) = p

P
xi n− xi

q

.

Предположим теперь, что вероятность успеха не известна. Обозначим ее за θ, и мы
можем только сказать, что θ ∈ [0, 1]. Таким P
образом семейсво
допустимых вероятP
xi
n− xi
ностей имеет вид P = {Pθ , θ ∈ Θ}, где Pθ = θ
(1 − θ)
.
Нашей задачей будет сузить класс P.
Исходные статистические данные — результат наблюдения конечной совокупности случайных величин X = (X1 , . . . , Xn ). При этом говорят, что эксперимент
состоит в проведении n испытаний, в которых результат i - го испытания описывается случайной величиной Xi . Совокупность X = (X1 , . . . , Xn ) называют выборкой,
величины Xi — элементами выборки, а их число n — объемом выборки.
Реализации выборки X будем обозначать x = (x1 , . . . , xn ).
Пусть X = {x} — множество не котором задано распределение случайного вектора X, т.е. множество всех возможных значений выборки X. F - класс допустимых
распределений случайной величины X, заданных на X . Таким образом под статистической моделью эксперимента будем понимать набор (X , F).
101

Следовательно, с каждой выборкой X свяжем ее функцию распределения FX (x):
FX (x1 , . . . , xn ) = P(X1 < x1 , . . . , Xn < xn ).
Мы будем рассматривать случай, когда все компоненты выборки независимы
и распределены так же, как и некоторая случайная величина ξ. Такую выборку
мы будем называть повторной. Этот случай соответствует эксперименту, в котором
проводятся повторные независимые наблюдения над случайной величиной ξ. Тогда
FX (x) = Fξ (x1 ) . . . Fξ (xn ). И говорят, что X = (X1 , . . . , Xn ) — выборка из распределения случайной величины ξ. Иногда множество возможностых значений ξ называют
генеральной совокупностью, а величину X — выборкой из этой совокупности.
Если функции распределения из класс F заданы с точностью до значений некоторого параметра θ c множеством допустимых значений Θ, то такая модель F =
{F (x, θ), θ ∈ Θ} называется параметрической. В этом случае известен тип распределения, но не известен параметр, от которого зависит распределение.

13.2

Эмпирическая функция распределения

Далее нам потребуется понятие эмпирической функции распределения.
Определение 13.1. Эмпирической функцией распределения, построенной по случайной выборке (X1 , . . . , Xn ), называется случайная функция
n

1X
Fn (x) =
I(Xi < x).
n i=1
Для конкретной реализации x выборки X и фиксированного числа x величина
Fn (x) равна доле тех значений xi , которые меньше x.
Cледующая теорема показывает, что функция Fn (x) является хорошей оценкой
для теоретической функции распределения F (x).
Теорема 13.1. Пусть (X1 , . . . , Xn ) — повторная выборка значений случаной величины X, имеющей функцию распределения F (x). Тогда для любого x ∈ R
P ( lim Fn (x) = F (x)) = 1.
n→∞

Доказательство. Обозначим Yi = I(Xi < x). Случайные величины Y1 , . . . , Yn —
независимые и одинаково распределенные.
Из определения Yi следует, что EYi = P(Xi < x) = F (x) и DYi = EYi2 − (EYi )2 =
F (x)(1 − F (x)) < ∞. Следовательно применим усиленный закон больших чисел и
Fn (x) =

Y1 + . . . + Yn п. н.
−−→ F (y).
n

Весьма замечательно, что имеет место более сильный результат о том, что сходимость в теореме равномерна по x.
Теорема 13.2. Пусть выполняются условия предыдущей теоремы. Тогда
P ( lim sup |Fn (x) − F (x)| = 0) = 1.
n→∞ x∈R

Доказательство этого результата приведено например в книге А.Н. Ширяева "Вероятность - 1".
102

13.3

Эмпирические или выборочные моменты

Пусть (X1 , . . . , Xn ) — выборка из распределения L(X) и F (x) и Fn (x) - соответсвенно теоретическая и эмпирическая функции распределения. Точно так же, как F (x)
ставится в соответсвие Fn (x), любой теоретической характеристике можно поставить
в соответствие эмпирическую характеристику.
Дадим определение эмпирического момента.
Определение 13.2. Эмпирическим (выборочным) моментом называется момент
случайной величины, имеющей эмпирическую функцию распределения в качестве
функции распределения.
Обозначим выборочный момент X. Из выше сказанного заключаем, что
Z
n
1X
X = x dFn (x) =
Xi .
n i=1
R

Вообще, если g =

R

g(x) dF (x) - некоторая теоретическая характеристика распре-

R

деления F (x), то ей можно поставить в соответствие эмпирическую характеристику
по формуле
Z
n
1X
G = g(x) dFn (x) =
g(Xi ).
n i=1
R

Если g(x) = xk , то G — выборочный момент k-го порядка и он равен
n

1X k
X .
Ak = Ak (X) =
n i=1 i
Выборочным центральным моментом k-го порядка называют случайную величину

n

1X
Mk = Mk (X) =
(Xi − X)k .
n i=1

При k = 2 величину Mk называют выборочной дисперсией и обозначают символом
S 2 = S 2 (X):
n
1X
2
S =
(Xi − X)2 .
n i=1
Между эмпирическими моментами сохраняются те же соотношения, что и между
соответсвующими теоретическими моментами.
Так как эмпирическая характеристика G является с свою очередь случайной
величиной, то мы можем говорить о ее распределении и различных характеристиках.
Вычислим математическое ожидание и дисперсию выборочного среднего и выборочной дисперсии. Так как все Xi независимы и распределены так же как и наблюдаемая случайная величина X, то для выборочного среднего имеем
n

EX =
DX =

1X
EXi = EX,
n i=1

DX1 + . . . + DXn
DX
=
.
2
n
n
103

Вычислим теперь математическое ожидание выборочной дисперсии. Заметим,
что выборочная дисперсия инварианта относительно сдвига. Действительно
¶2
n µ
1X
(X1 + c) + . . . + (Xn + c)
2
S (X1 + c, . . . , Xn + c) =
Xi + c −
n i=1
n
n

1X
=
(Xi − X)2 = S 2 (X).
n i=1
Пусть EX1 = m, DX1 = σ 2 . Положим, Yi = Xi − m. В силу инвариантности
относительно сдвига имеем S 2 (X) = S 2 (Y) и
n

n

1X
1X 2
2
(Yi − Y )2 =
(Yi − 2Y Yi + Y )
S =
n i=1
n i=1
2

n

=

n

1 X 2 2n 2 n 2
1X 2
2
Yi − Yi + Yi =
Yi − Yi .
n i=1
n
n
n i=1

(1)

Используя тот факт, что EYi = 0, и то, что математическое ожидание произведения независимых случайных величин равно произведению математических ожиданий, получим
Ã n
!2
Ã n
!
X
X
X
1
1
Yi
= 2 E
Yi2 + 2
Yi Yj
EY = 2 E
n
n
i=1
i=1
i<j
Ã n
!
n
X
1 X
1 X
σ2
2
= 2
EYi + 2
EYi EYj = 2
EYi2 = .
n
n i=1
n
i=1
i<j
2

Теперь, применяя (1), получим
ES 2 (X) = ES 2 (Y)
n
1X
σ2
n−1 2
2
2
2
=
EYi − EY = σ −
=
σ .
n i=1
n
n
Замечание. Часто используют другое определение выборочной дисперсии:
n

S 2 (X) =

1 X
(X − X)2 .
n − 1 i=1

Оно лучше тем, что ES 2 (X) = σ 2 . Чтобы отличать от выборочной дисперсии введен2
2
(X) и называть
= Sre
ной ранее, такую выборочную дисперсию будем обозначать Sre
исправленной выборочной дисперсией.
Введем еще одно определение, которое нам понадобится в будущем.
Определение 13.3. Последовательно случайных величин {Yn } — асимпототически нормальна с параметрами (an , bn ), если для любого z
½
P

Yn − an
<z
bn

¾

1
→ Φ(z) = √
2π

104

Zz

u2

e− 2 du,
−∞

n → ∞.

Теорема 13.3. Последовательность X n — асимптотически нормальна.
σ
Доказательство. Возьмем an = a, bn = √ . Тогда в силу центральной предельn
ной теоремы
Xn − a
X1 + . . . + Xn − na d
√
→
− N (0, 1).
=
bn
σ n
Замечание. Теорема остается справедливой для выборочных моментов любого порядка k.

13.4

Порядковые статистики и вариационные ряды

Каждой реализации x выборки X можно поставить в соответствие упорядоченную
последовательность:
x(1) 6 x(2) 6 . . . 6 x(n) .
Обозначим через X(k) случайную величину, которая для каждой реализации x выборки X принимает значение x(k) . Таким образом мы по выборке X = (X1 , . . . , Xn )
определили новую последовательность случайных величин X(1) , . . . , X(n) , называемых порядковыми статистиками. X(k) — k-ая порядковая статистика. X(1) , X(n) —
экстремальные значения выборки.
Очевидно, что порядковые статистики удовлетворяют неравенствам
X(1) 6 X(2) 6 . . . 6 X(n) .

(2)

Последовательность (2) называется вариационным рядом.
Интересно поставить вопрос о распределение X(k) .
Для X(n) и X(1) имеем
Ãn
!
n
\
Y
P(X(n) < z) = P
{Xi < z} =
P(Xi < z) = F n (z).
i=1

Ã

P(X(1) < z) = 1 − P((X(1) > z) = 1 − P

i=1
n
\

!

{Xi > z}

= 1 − (1 − F (z))n .

i=1

Лемма 13.1.
P(X(k) < z) =

n
X

Cni F i (z)(1 − F (z))n−i .

i=k

Доказательство. Обозначим через µn (z) — число событий {j : Xj < z}. Если
вспомнить определение эмпирической функции распределения, то
Fn (z) =

µn (z)
.
n

Из равенства {Xk < z} = {µn (z) > k}, доказательство справедливости которого мы
предоставляем читателю, вытекает, что
Ãn
!
\
P(X(k) < z) = P(µn (z) > k) = P
(µn (z) = i) .
i=k

105

События {µn (z) = i} несовместы, и µn (z) = i означает, что из n случайных величин
ровно i меньше z, а остальные не меньше z. Следовательно
P(X(k) < z) =

n
X

P(µn (z) = i).

i=k

Так как µn (z) имеет биноминальное распределение с параметрам n и p = P(X <
z) = F (z), то доказательство леммы окончено.

13.5

Статистические оценки

С этим понятием мы уже сталкивались выше, когда говорили, что эмпирическая
функция распределения являетя оценкой для теоретической функции распределения или выборочная характеристика является оценкой теоретической характеристики. При этом использование понятия "оценка"основалось на том, что при достаточно большом объеме выборки, большие отклонения эмпирической характерестики от
теоретической маловероятны.
При применение статистической теории на практике, часто приходится строить
оценки теоретических характеристик при ограниченных объемах выборки. Мы изложим некоторые общие методы решения подобных задач.
Пусть у нас есть параметрическая статистическая модель F = {F (x, θ), θ ∈ Θ}
и выборка X = (X1 , . . . , Xn ) из распределения L(X) ∈ F.
Априорная информация о наблюдаемой случайной величине X состоит в том,
что ее функция распределения F (x) принадлежит некоторому заданному параметрическому семейству F, т.е. имеет известную функциональную форму, но зависит
от некоторого неизвестного параметра θ, который принадлежит параметрическому
множеству Θ. Таким образом имеем задачу: по выборке X сделать статистические
выводы об истинном значении неизвестного параметра θ.
Определение 13.4. Статистикой называется любая случайная величина, являющаяся функцией лишь от выборки X.
При точечном оценивании ищут статистику T = T (X), которую при заданной
реализации x выборки X принимают за приближенное значение параметра θ.
Для оценивания θ можно использовать различные оценки. Но чтобы выбрать
лучшую из них нужно иметь критерии качества оценок. В разных случаях меры
качества различны.
Введем понятие несмещенной и состоятельной оценки.
Определение 13.5. Оценка T = T (X) является несмещенной оценкой неизвестного параметра θ, если
ET = θ.
Замечание. Иногда требуется найти несмещенную оценку не самого неизвестного
параметра θ, а некоторой функции τ (θ) от него. В этом случае оценка T = T (X)
является несмещенной оценкой τ (θ), если
ET = τ (θ).
Определение 13.6. Оценка T = T (X) является состоятельной оценкой неизвестного параметра θ, если при неограниченном увеличении объема выборки
p

T −
→θ
106

13.5.1

Свойства несмещенных оценок

1◦ . Несмещенные оценки не единственны.
К примеру в качестве несмещенной оценки для математического ожидания EX
могут выступать EX1 или EX.
2◦ . Несмещенные оценки могут не существовать.
Пример. Пусть L(X) — пуассоновское распределение с параметром θ. Производится
одно наблюдение X над пуассоновской случайной величиной. Требуется оценить
1
параметрическую функцию τ (θ) = . Пусть T (X) — несмещенная оценка для τ (θ),
θ
т.е.
∞
X

T (x)e−θ

x=0
∞
X
x=0

−θ θ

T (x)e

θx
1
= ,
x!
θ

x+1

x!

θ

=e =

или
∞
X
θr
r=0

r!

.

Очевидно, что не существует функции T (X), удовлетворяющей этому соотношению
и не зависящей от θ.
3◦ . Несмещенные оценки могут существовать, но быть бессмысленными.
Пример. Пусть L(X) — отрицательное биномиальное распределение с параметрами
1 и θ. Производится одно наблюдение X. Требуется оценить параметр θ . Пусть T (X)
— несмещенная оценка для θ, т.е.
∞
X

∞

X
θ
T (x)θ =
=
θr ,
1−θ
x=0
r=1
x

∀θ ∈ (0, 1).

Приравнивая коэффициенты при одинаковых степенях θ, получаем, что единственной несмещенной оценкой является статистика
(
0, при X = 0,
T (X) =
1, при X > 1.
Но значения этой статистики не принадлежат параметрическому множеству Θ =
(0, 1). Поэтому такая оценка бессмыслена.
4◦ . Из того, что ET (X) = θ, вообще говоря, не следует, что Ef (T (X)) = f (θ).

13.5.2

Свойства cостоятельных оценок

1◦ . Состоятельные оценки не единственны.
2
Sre

Действительно, выборочная дисперсия S 2 и исправленная выборочная дисперсия
являются состоятельными оценками теоретической дисперсии.

2◦ . Состоятельные оценки могут быть смещенными.
Действительно, как было показано ранее выборочная дисперсия является состоятельной, но смещенной оценкой теоретической дисперсии.
107

Лекция 14

14.1

Оптимальные оценки

Пусть нам требуется оценить заданную параметрическую функцию τ (θ) в модели
F = {F (x, θ), θ ∈ Θ} по выборке X = (X1 , . . . , Xn ) из распределения L(X) ∈ F.
Пусть статистики T = T (X) являются несмещенными оценками заданной параметрической функции. Обозначим через Tτ семейство всех несмещнных оценок. Предположим, что дисперсии всех оценок из Tτ конечны, т.е. Dθ T = Eθ (T − τ (θ))2 < ∞
для ∀θ ∈ Θ.
Рассмотрим теперь две статистики T1 , T2 ∈ Tτ . ET1 = ET2 . Возникает вопрос,
какую из оценок выбрать. Рассмотрим дисперсии оценок. Если Dθ T1 < Dθ T2 , то
берем T1 , поскольку чем меньше дисперсия, тем меньше разброс среднего. Но оценка
должна выполняться для ∀θ ∈ Θ.
Таким образом мы пришли к определению оптимальной оценики.
Определение 14.1. Пусть Tτ семейство несмещенных оценок параметрической
функции τ (θ). Оценка T = T (X) называется оптимальной, если Dθ T < Dθ T1 , для
любого θ ∈ Θ и T1 ∈ Tτ .
Имеет место следующий результат, показывающий, что если оптимальная оценка
существует, то она единственна с точность до меры нуль.
Теорема 14.1. Пусть статистики T1 , T2 ∈ Tτ . Если T1 и T2 — оптимальны, то
T1 = T2 с вероятностью 1.
Доказательство. Так как T1 и T2 — оптимальные оценки, то DT1 = DT2 . ПоT1 + T2
ложим DT1 = DT2 = σ 2 . Определим новую оценку: T3 =
∈ Tτ . Вычислим
2
дисперсию новой оценки.
2T3 = T1 + T2 ;
D(2T3 ) = D(T1 + T2 ) = DT1 + DT2 + 2cov(T1 , T 2) = 2σ 2 + 2cov(T1 , T 2).
2
2
2
Так
√ σ — наименьшая дисперсия, то DT3 > σ . Cледовательно cov(T1 , T2 ) > σ =
√ как
DT1 DT2 . И для коэффициента кореляции имеем

cov(T1 , T2 )
√
ρ= √
> 1.
DT1 DT2
Но, как известно, коэффициент кореляции |ρ| 6 1. Следовательно ρ = 1.
Из свойств коэффициента кореляции известно, что, если он равен 1, то случайные величины линейны зависимы c вероятностью 1. Таким образом T1 = aT2 + b
с вероятностью 1. Так как T1 и T2 несмещенные оценки, то ET1 = ET2 = θ. И мы
получили, что θ = aθ + b или θ(1 − a) = b. Следовательно
cov(T1 , T2 ) = E(T1 − θ)(T2 − θ) = E(aT2 + b − θ)(T2 − θ) = aE(T2 − θ)2 = aσ 2 .
Так как ρ = 1, то отсюда находим, что a = 1, b = 0, т.е. T1 = T2 .
108

14.2
14.2.1

Неравенство Рао - Крамера
Функция правдоподобия

Пусть X = (X1 , . . . , Xn ) — выборка из L(X) ∈ F . x = (x1 , . . . , xn ) — реализация
выборки X.
Если X имеет дискретное распределение, то определим функцию Ln = Ln (x, θ)
cледующим образом
Ln =

n
Y

P(Xi = xi ),

i=1

если имеет абсолютно непрерывно распределение, то
Ln =

n
Y

f (xi , θ),

i=1

где f (x, θ) - плотность распределения наблюдаемой слуайной величины X.
Функция Ln (x, θ) называется функцией правдоподобия. В дискретном случае
функция правдоподобия является вероятностью того, что выборка X примет значение (x1 , . . . xn ). В непрерывном случае функция правдоподобия является совместной
плотностью распределения выборки X.
Прежде чем сформулировать и доказать неравенство Рао - Крамера докажем
вспомогательную лемму.
∂Ln ∂ 2 Ln
Лемма 14.1. Предположим, что для ∀θ ∈ Θ ⊂ R cуществуют
,
, и
∂θ ∂θ2
¯ 2
¯
µ
¶2
¯∂
¯
∂
cуществуют конечные E ¯¯ 2 ln Ln ¯¯ и E
ln Ln . Тогда
∂θ
∂θ
¶
µ
∂ ln Ln
= 0,
(1)
E
∂θ
µ
¶2
∂ ln Ln
∂2
E
= −E 2 ln Ln .
(2)
∂θ
∂θ
Доказательство. Доказательство проведем для абсолютно непрерывного случая.
Для дискретного случае доказательство предлагается провести читателю самостоятельно.
Как отмечалось выше, в абсолютно непрерывнос случае функция Ln (x, θ) является совместной плотностью выборки X, следовательно
Z
1=

Ln (y, θ) dy,

y = (x1 , . . . , xn ).

Rn

Продифференцируем это тождество по θ (это мы можем сделать по условию) и получим
Z
Z
∂ ln Ln
∂
∂Ln
dy =
Ln dy = E ln Ln (x, θ).
0=
∂θ
∂θ
∂θ
Rn

Rn

109

Тем самым (1) доказано. Следующие выкладки доказывают (2)
Z 2
∂ ln Ln
∂2
E 2 ln Ln (x, θ) =
Ln dy
∂θ
∂θ2
Rn
µ
¶2
∂ 2 Ln
∂Ln
Z Ln
−
∂θ2
∂θ
=
Ln dy
2
Ln
Rn
¶2
µ
¶2
Z µ
∂
∂
=−
ln Ln Ln dy = −E
ln Ln (x, θ) .
∂θ
∂θ
Rn

Определение 14.2. Количеством информации по Фишеру, содержащейся в выборке X = (X1 , . . . , Xn ), называется величина
µ
In (θ) = E

∂ ln Ln (x, θ)
∂θ

¶2
.

Из только что доказанной леммы следует, что
µ
E

∂ ln Ln (x, θ)
∂θ

¶2

n
∂2
∂2 X
= −E 2 ln Ln (x, θ) = −E 2
ln f (xi , θ)
∂θ
∂θ i=1

= −nE

∂2
ln f (x1 , θ) = nI1 (θ).
∂θ2

Теорема 14.2 (неравенство Рао - Крамера). Пусть выполнены все условия
предыдущей леммы и τ (θ) дифференцируемая функция от θ ∈ Θ, для которой существует несмещенная оценка T = T (X) и

DT (X) < ∞,

¯
Z ¯
¯ ∂Ln ¯
¯
¯
¯ ∂θ ¯ dy < ∞ для ∀θ ∈ Θ

Rn

Тогда
DT (X) >

(τ 0 (θ)2
.
In (θ)

(3)

При этом равенство имеет место тогда и только тогда, когда
∂
ln Ln (x, θ) = c(θ)(T (x) − τ (θ)),
∂θ
с некоторой функцией c(θ) или, что эквивалентно
Ln (x, θ) = exp{ψ1 (θ) + ψ2 (θ) + f (x)}.

110

(4)

Доказательство. Так как T (X) — несмещенная оценка, то
Z
T (y) Ln (y, θ) dy = τ (θ).
Rn

Продифференцируем это равенство по θ ( это мы можем сделать в силу условия
теоремы) и, применяя неравенство Коши - Буняковского - Шварца, получим
¯
¯ ¯
¯
¯ ¯Z
¯
¯Z
¯
¯ ¯
¯
∂L
∂
ln
L
n
n
0
|τ (θ)| = ¯¯ T (y)
dy ¯¯ = ¯¯ T (y)
Ln dy ¯¯
∂θ ¯ ¯
∂θ
¯
¯ n
Rn
¯R µ
µ
¶¯ ¯
¶¯
¯
¯ ¯
¯
∂
ln
L
(x,
θ)
∂
ln
L
(x,
θ)
n
n
¯ = ¯E (T (X) − τ (θ))
¯
= ¯¯E T (X)
−
0
¯ ¯
¯
∂θ
∂θ
¶1/2
µ
∂ ln Ln
= (DT (X) · In (θ))1/2 .
6 DT (X) · D
∂θ
Что и доказывает нашу теорему.
Следствие 14.1. Если τ (θ) = θ, то
DT (X) >

1
.
nIn (θ)

Замечание. Многие часто встречающиеся модели удовлетворяют условию (4). Например модели, в которых закон распределения представляет собой
• нормальное распределение N (θ, σ 2 ),
• нормальное распределение N (a, θ),
• пуасоновское распределение Π(θ),
• биномиальное распределение Bi(n, θ),
• гамма - распределение Γ(θ, λ),
где θ - неизвестный параметр.
Пример. Пусть имеется выборка X = (X1 , . . . , Xn ) из биномиального распределения с параметрами 1 и θ (L(X) ∼ Bi(1, θ)). Требуется найти оптимальную оценку
параметра θ.
Здесь Eθ Xi = θ, поэтому T (X) = X является несмещенной оценкой параметра θ.
Покажем, что T (X) является оптимальной оценкой.
Вычислим дисперсию T (X)
DT (X) =

n
θ(1 − θ)
1 X
DXi =
.
2
n i=1
n

Вычислим теперь информацию по Фишеру
µ
I1 (θ) = E

∂ ln L1
∂θ

¶2

111

= −E

∂ 2 ln L1
.
∂θ2

Так как для n = 1 функция правдоподобия имеет вид L1 = θx1 (1 − θ)1−x1 , то
ln L1 = x1 ln θ + (1 − x1 ) ln(1 − θ),
∂ ln L1
x1 (1 − x1 )
x1 − θ
=
−
=
,
∂θ
θ
1−θ
θ(1 − θ)
µ
¶2
x1 − θ
1
θ(1 − θ)
E
=
.
= 2
2
θ(1 − θ)
θ (1 − θ)
θ(1 − θ)
1
, т.е. оценка T (X) = X имеет наименьшую дисnI1 (θ)
персию для любого θ. Следовательно является оптимальной.
Таким образом DT (X) =

Сформулируем теперь этот результат в виде теоремы.
Теорема 14.3. Относительная частота произвольного события в n независимых
испытаниях является оптимальной оценкой для вероятности этого события.
Следствие 14.2. Для любой фиксированной выборки эмпирическая функция распределения является оптимальной оценкой теоретической функции распределения.
Определение 14.3. Эффективностью оценки T = T (X), которая является несмещенной оценкой параметрической функции τ (θ), называется величина
e(T ) =

(τ 0 (θ))2
.
DT · In (θ)

Замечание. Из определения и неравенства Рао - Крамера следует, что 0 6 e(T ) 6 1.
Определение 14.4. Несмещенная оценка T = T (X) называется эффективной, если
ее эффективность равна 1.
Замечание. Можно сформулировать это определение иначе: оценка T = T (X) называется эффективной, если в неравенстве Рао - Крамера достигается равенство.

14.3

Метод моментов

Рассмотрим статистическую модель F = {F (x, θ), θ ∈ Θ}, где θ = (θ1 , . . . , θk ). Пусть
X = (X1 , . . . , Xn ) выборка из распределения L(X) ∈ F . Предположим, что существует математическое ожидание EX k = ak , тогда существуют все моменты низших
порядков. По выборке X построим эмпирические моменты
mi =

1 i
(X + . . . + Xni ) = ai = fi (θ1 , . . . , θk ).
n 1

Таким образом мы получаем систему из k уравнений с k неизвестными, которую
иногда можно разрешить относительно неизвестных параметров θi :


 m1 = a1 = f1 (θ1 , . . . , θk )
...
(5)

 m = a = f (θ , . . . , θ ).
k
k
k 1
k
Определение 14.5. Оценками по методу моментов называется решение θ1∗ , . . . , θk∗
системы (5) .
112

Пример. Пусть (X1 , . . . , Xn ) — выборка из биномиального распределения Bi(k, θ),
где k, θ — неизвестные параметры. Найдем их оценки по методу моментов.
Прежде всего нам необходимо найти два момента нашего распределения:
a1 = EX = k θ,
a2 = EX = DX + (EX)2 = k θ (1 − θ) + (k θ)2 .
2

Таким образом система (5) запишется следующим образом
(

a 1 = k θ = m1
a2 = k θ(1 − θ) + (k θ)2 = m2

Решая его, найдем оценки
m21 + m1 − m2
,
m1
m21
.
k∗ = 2
m1 + m1 − m2
θ∗ =

Часто оценки по методу моментов являются состоятельными. Так что имеет место следующая теорема
p

Теорема 14.4. Пусть h(x) — непрерывная функция и Yn −
→ 0. Тогда
p

h(Yn + a) −
→ h(a).
Доказательство. Из непрерывности функции h(x) следует, что для ∀ε > 0 ∃δ >
0 : |y| < δ:
|h(a + y) − h(a)| < ε.
Фиксируем ε > 0, тогда
P(|h(a + Yn ) − h(a)| > ε) = P(A ∩ |Yn | < δ ) + P(A ∩ |Yn | > δ| 6 P(|Yn | > δ) → 0.
|
{z
}
|
{z
}
A

∅

Если оценки, найденные по методу моментов, окажутся непрерывными функциями, то с помощью обобщения теоремы на случай многих переменных, докажем, что
они являются состоятельными оценками.

14.4

Достаточные статистики

Определение 14.6. Статистика T = T (X) называется достаточной для модели
F = {F (x, θ), θ ∈ Θ}, если распределение выборки X = (X1 , . . . , Xn ) не зависит от
θ при условии, что T (X) = t.
Это свойство статистики означает, что она содержит всю информацию о параметре θ, имеющуюся в выборке.

113

Пример. Пусть L(X) = Bi(1, θ). Покажем, что статистика T (X) =
достаточной.

P

Xi будет

P(X = x, T (X) = t)
P(T (X) = t)
P
P
θ Xi (1 − θ)n− Xi
1
=
= P Xi .
t
t
n−t
Cn θ (1 − θ)
Cn

P(X1 = x1 , . . . , Xn = xn |T (X) = t) =

Приведем следующий результат, называемый критерием факторизации, позволяющий определить, существует ли достаточная статистика и установить ее вид.
Теорема 14.5 (Критерий факторизации). T (X) достаточная статистика тогда и только тогда, когда функция правдоподобия может быть представлена в
виде
Ln (x, θ) = g(T (x, θ)h(x).
Доказательство. Приведем доказательство для дискретного случая. Для абсолютно непрерывного доказательство предлагается провести читателю самостоятельно.
Пусть T (X) достаточная статистика. Если T (X) = t, то событие {X = x} ⊆
{T (X) = t}. Поэтому
L(x, θ) = Pθ (X = x) = Pθ (X = x|T (X) = t)
= Pθ (T (X) = t) Pθ (X = x|T (X) = t) .
{z
}|
{z
}
|
g(T (x),θ)

h(x,t)

Пусть теперь функция правдоподобия имеет вид Ln (x, θ) = g(T (x, θ)h(x). Тогда,
если x таково, что T (x) = t, то
P(X = x, T (X) = t)
P(T (X) = t)
P(X = x)
P
=
=
P(X = x0 )

P(X = x|T (X) = t) =

x0 :T (x0 )=t

g(t, θ)h(x)
P
=
g(t, θ)h(x0 )
x0 :T (x0 )=t

h(x)
P
.
h(x0 )
x0 :T (x0 )=t

Что и требовалось доказать.
Пример. Рассмотрим общую нормальную модель N (θ1 , θ22 ), где оба параметра неизвестны. В этом примере функция правдоподобия будет зависеть от векторного параметра θ = (θ1 , θ22 ). Найдем функцию правдоподобия
Ln (x, θ) =

n
Y
i=1

√

1
2πθ

(xi − θ1 )2
2θ22
e
−

1
= √
exp
( 2πθ)n

Ã

n
1 X
n(x − θ1 )2
2
(x
−
x)
−
i
2θ22 i=1
2θ22

!
= g(T (x), θ)h(x).

В качестве достаточной статистики можно взять векторную функцию
T (X) = (x,

n
X

(xi − x)2 ).

i=1

Это не единственный, но классический выбор достаточной статистики.
114

Пример. Пусть X = (X1 , . . . , Xn ) — выборка из равномерного распределения на
[0, θ], θ > 0. Тогда функция правдоподобия будет иметь вид
Ln (x, θ) =

1
I{x >0} I{x(n) <θ} .
θn | (1)
{z }
h(x)

Таким образом T (X) = X(n) достаточная статистика.

115

Лекция 15

15.1

Достаточные и полные статистики

Роль достаточных статистик в теории оценивания раскрывает следующая теорема.
Теорема 15.1 (теорема Рао - Блекуэлла - Колмогорова). Если оптимальная
оценка существует, то она является функцией от достаточной статистики.
Доказательство. При доказательстве нам потребуются два свойства условного
математического ожидания:
Ef (x, z) = E(E(f (x, z)|z)),
E(g(z)|z) = g(z).

(1)
(2)

Эти свойства были доказаны ранее, поэтому мы не будем останавливаться на их
доказательстве.
Пусть теперь T (X) — достаточная статистика, и пусть T1 (X) — несмещенная
оценка для τ (θ), т.е.
ET1 (X) = τ (θ).
Рассмотрим функцию H(T ) = E(T1 |T ). Тогда из (1) слудует, что
EH(T ) = E(E(T1 |T )) = ET1 = τ (θ),
т.е. H(T ) является несмещенной оценкой для τ (θ).
Используя равенства (1) и (2) получим
E((T1 − H(T ))(H(T ) − τ (θ)) = E(E((T1 − H(T ))(H(T ) − τ (θ))|T ))
= E((H(T ) − H(T ))(H(T ) − τ (θ))) = 0.
Тогда
D(T1 ) = E(T1 − τ (θ))2 = E(T1 − H(T ) + H(T ) − τ (θ))2
= E(T1 − H(T ))2 + D(H(T )) > D(H(T )).
Таким образом H(T ) — оптимальная оценка.
При отыскании явного вида оптимальных оценок важную роль играет свойство
полноты достаточной статистики.
Определение 15.1. Достаточная статистика T (X) называется полной, если для
любой функции ϕ(z) из равенства Eθ ϕ(T ) = 0, ∀θ ∈ Θ cледует, что ϕ(T ) = 0 с
вероятностью 1.
116

Замечание. В определении полноты утверждается, что
Pθ (x : ϕ(T (x) 6= 0)) = 0,
где Pθ — распределение, порождаемое вектором (x1 , . . . , xn ) на Rk .
Пример. Пусть X = (X1 , . . . , Xn ) — выборка из равномерного распределения на
[0, θ], θ > 0. На прошлой лекции мы показали, что статистика T (X) = X(n) является
достаточной. Проверии ее полноту. Выпишем плотность распределения X(n) :
 n−1
 z
n n , z ∈ [0, θ],
h(z) =
θ
0,
иначе.
Тогда
Z
Eϕ(T ) =

n
ϕ(z)h(z) dz = n
θ

Zθ
ϕ(z)z n−1 dz = 0.
0

R

Из определения интеграла Лебега сразу следует, что ϕ(z) = 0 с вероятностью 1.
Таким образом достаточная статистика T (X) = X(n) является полной.
Теорема 15.2. Если T (X) — полная достаточная статистика, то она является
оптимальной оценкой своего математического ожидания.
Доказательство. Докажем, что T (X) является единственной несмещенной оценкой для ET (X). Тогда T (X) будет оптимальной оценкой.
Предположим, что T1 (X) — оптимальная оценка для ET . Из теоремы Рао - Блекуэлла - Колмогорова получаем, что T1 = H(T ) и ET1 = ET . Тогда
E (T (X) − H(T (X))) = 0,
|
{z
}
ϕ(T )

и из условия полноты T (X) следует, что ϕ(T ) = 0 с вероятностью 1, т.е. T = H(T ) с
вероятностью 1.

15.2

Оценки максимального правдоподобия

Одним из наиболее универсальных методов оценивания параметров распределения
является метод максимального правдоподобия. Оценку параметра, получаемую с
помощью этого метода, будем обозначать θ̂ = θ̂(X).
Пусть X = (X1 , . . . , Xn ) — выборка из распределения L(X) ∈ F = {F (x, θ), θ ∈
Θ} и Ln (x, θ) — функция правдоподобия.
Определение 15.2. Оценкой максимального правдоподобия θ̂ параметра θ называется такая точка параметрического множества Θ, в которой функция правдоподобия Ln (x, θ) при заданном x достигает максимума, т.е.
Ln (x, θ̂) = sup Ln (x, θ).
θ∈Θ

117

Пример. Чтобы пояснить сказанное рассмотрим пример. Пусть X = (X1 , X2 ) —
выборка из биномиального распределения Bi(1, θ). В нашем случае функция правдоподобия будет иметь вид
L(x, θ) = θx1 +x2 (1 − θ)2−x1 +x2
½

¾
1
999
Пусть параметрическое семейство Θ состоит из двух точек: Θ =
,
. Про100 1000
водится эксперимент и наблюдается реализация (1, 1) выборки X. Функция правдоподобия примет вид
L(1, 1, θ) = θ2 .
¾
½
999
.
Тогда в качестве неизвестного параметра следует, очевидно, взять точку
1000
Читатель может сам без труда выяснить, какую точку надо взять из множества
Θ, если наблюдаются реализации (0 , 0) , (1, 0) или (0,1) выборки X.
Если для каждого x максимум функции правдоподобия достигается во внутренней точке Θ, и Ln (x, θ) дифференцируема по θ, то оценка максимального правдоподобия (о.м.п.) θ̂ удовлетворяет уравнению
∂lnLn (x, θ)
= 0.
∂θ
Если θ векторный параметр: θ = (θ1 , . . . , θn ), то это уравнение заменяется системой
уравнение
∂lnLn (x, θ)
= 0,
i = 1, . . . , n.
∂θi
Эти уравнения называются уравнениями правдоподобия.
Утверждение 15.1. Если существует эффективная оценка T = T (X) скалярного
параметра θ, то она совпадает с оценкой максимального правдоподобия.
Доказательство. На прошлых лекциях мы отмечали, что если оценка T = T (X)
скалярного параметра θ эффективна, то в неравенстве Рао - Крамера достигается
равенство, т.е. имеет место представление
∂lnLn (x, θ)
= c(θ)(T (x) − θ).
∂θ
Что и доказывает наше утверждение.
Утверждение 15.2. Если T = T (X) достаточная статистика, а оценка максимального правдоподобия θ̂ существует и единственна, то она является функцией
от T .
Доказательство. Из критерия факторизации следует, что если T = T (X) достаточная статистика, то имеет место представление
Ln (x, θ) = g(T (x), θ)h(x).
Таким образом, максимизации Ln (x, θ) сводится к максимизации g(T (x), θ) по θ.
Следовательно θ̂ есть функция от T .

118

Пример. Пусть X = (X1 , . . . , Xn ) — выборка из равномерного распределения на
[θ, θ + 1]. Функция правдоподобия имеет вид
Ln (x, θ) = I{x(1) >θ} I{x(n) <θ+1} .
Отсюда следует, что любое θ ∈ [x(n) −1, x(1) ] максимизирует функцию правдоподобия.
Таким образом о.м.п. не единственна. В качестве решения можно выбрать, например,
θ̂ = (X(1) + X(n) − 1)/2.
Пример. Рассмотрим так называемую общую нормальную модель N (θ1 , θ22 ). Максимизация функции правдободобия в этом случае эквивалентна минимизации по θ
функции
µ
¶
(x − θ1 )2 1 S 2
S
ψ(x, θ) =
+
− 1 − ln .
2
2
2θ2
2 θ2
θ2
Заметим, что функция
1
f (x) = (x2 − 1) − ln x
2
достигает минимума при x = 1 и
f (1) = 0,
f (x) < 0 для всех x ∈ (0, 1),
f 0 (x) > 0 для всех x > 1.
0

Поэтому
1 2
(x − 1) > ln x ∀x > 0.
2
Таким образом получили, что θ̂ = (X, S) является о.м.п.
Утверждение 15.3 (Принцип инвариантности для оценок максимального
правдоподобия). Пусть f : Θ → F — взаимнооднозначое отображение из Θ в F.
Тогда, если θ̂ есть о.м.п. для θ, то f (θ̂) есть оценка для f (θ).
Доказательство. Так как sup Ln (x, θ) = sup Ln (x, f −1 (z)), то, если sup левой чаz∈F

θ∈Θ

сти достигается при θ = θ̂, то в правой части при некотором значении ẑ, которое
удовлетворяет равенству f −1 (ẑ) = θ̂, т.е. ẑ = f (θ̂).
Замечание. В заключении отметим, что оценки максимального правдоподобия часто состоятельны, асимпотически несмещенные и асимпотически нормальные.

119

Лекция 16

16.1

Доверительные интервалы и трактовка коэффициента доверия

Пусть есть выборка X1 , . . . , Xn из L(X) ∼ N (θ, 1), тогда в качестве несмещенной
оптимальной оценки возьмем
θ∗ = X.
(Понятно, что x0 и x00 ) — это разные вещи.
Пример. Вспомним первую лекцию. Пусть даны цены Pt в моменты времени t,
тогда относительная доходность в момент времени t равна
Xt =

Pt+1 − Pt
.
Pt

Для ряда финансовых инструментов поведение Xt близко к нормальному, то есть
X1 , X2 , . . . , Xn из L(X) ∼ N (θ1 , θ22 );
Естественно, что параметры θ1 , θ22 неизвестны, хотим найти для них оценки. В качестве оценки берем
θ1∗ = X.
Очевидно, что полученные значения в январе и в феврале не обязаны совпадать, положим, что в январе θ1∗ = a, интересуемся какова вероятность того, что и в февралее
получим ту же величину. Понятно, что
P(θ1∗ = a) = 0 в феврале.
Поскольку вероятность получить конкретное значение равна нулю, будем искать
вероятность попадания в небольшой отрезок.
Обозначим γ — уровень доверия,или коэффициент доверия, или надежность;
γ ∼ 1.
Определение 16.1. Пусть Y = (X1 , . . . , Xn ) — выборка из L(X). Интервальной
оценкой для θ (доверительным интервалом) с коэффициентом доверия
γ называется интервал (T1 (Y ), T2 (Y )) такой, что
P(T1 (Y ) < θ < T2 (Y )) > γ.
(T1 (Y ), T2 (Y ) — случайные величины.)
120

Рассмотрим, как это реализовать на практике.
Пусть X1 , . . . , Xn из L(X) ∼ N (θ, 1).
Тогда
n

1X
1
θ =X=
Xi ∼ N (θ, ).
n i=1
n
∗

Тогда
√
(X − θ) n ∼ N (0, 1)
И уже для такой величины, имеющей стандартное нормальное распределение, строим интервальную оценку: то есть находим такое tγ/2 , что
√
P(|(X − θ) n| < tγ/2 ) = γ.
Решаем его относительно θ и получаем
¶
µ
tγ/2
tγ/2
=γ
P X− √ <θ<X+ √
n
n
Возникают два замечания:
Замечание. Почему был взят интервал, симметричный относительно 0? Более информативен, вообще говоря, меньший интервал. То есть наша цель — построить
интервал наименьшей длины такой, что площадь под графиком плотности на этом
интервале равна γ. Ясно, что в случае стандартного нормального распределения
симметрия графика функции отностиельно оси Oy играет на нас.
Замечание. В конечном итоге получили доверительный интервал
tγ/2
tγ/2
(X − √ , X + √ )
n
n
В этом случае tγ/2 находится по γ единственным образом, что, вообще говоря, происходит не всегда.
Пример. Вспомним пример с данными о ценах за январь 2006 года. Размер выборки
n = 2000, и нами получен доверительный интервал (0, 5%, 1, 2%) с коэффициентом
доверия γ = 0, 99. Как трактовать такой результат?
θ — средняя относительная доходность, это конкретное число, а не случайная величина, то есть вероятности ее нахождения никакой нет: либо параметр θ попал в
построенный интервал, либо нет, но и интервал, и параметр уже найдены.
Возьмем N выборок и для каждой выборки посчитаем доверительный интервал.
N+ — число доверительны интервалов из N построенных, которые действительно
содержат θ. Тогда
N+
∼ γ по построению доверительного интервала.
N

121

Лекция 17

17.1
17.1.1

Методы построения интервальных оценок
Метод, основанный на точечных оценках

Пусть X1 , . . . , Xn из L(X), θ ∈ Θ
Y = (X1 , . . . , Xn ), T (Y ) — точечная оценка для параметра θ с функцией распределения G(T, θ). Предположим, что G(T, θ) монотонна как функция θ.
Пример. Имеем распределение N (θ, 1) и T (Y ) = X
√
√
P(θ∗ < t) = P((θ∗ − θ) n < (t − θ) n)
√
= Φ((t − θ) n),
где Φ(z) — функция стандартного нормального распределения.
⇓
√
1
G(t, θ) = Φ((t − θ) n), Φ(z) = √
2π

Zz
2 /2

e−u

du.

−∞

Следовательно, G(t, θ) монотонна.
Пусть ε : 1/2 < ε < 1;
для определенности предположим, что G(t, θ) монотонна по θ.
Рассмотрим уравнения
(
G(T (Y ), θ) = ε,
(1)
G(T (Y ), θ) = 1 − ε. (2)
Пусть θ1∗ (Y ) и θ2∗ (Y ) — решения первого и второго уравнений соответственно.
Предположим, что (θ1∗ , θ2∗ ) ( или (θ2∗ , θ1∗ )) — интервал такой, что
P(θ1∗ < θ < θ2∗ ) = γ
(P(θ1∗ < θ < θ2∗ ) = γ),
где γ = 2ε − 1.
Пример.
L(X) ∼ N (θ, 1);
1
T (Y ) = X ∼ N (θ, );
n
√

1
FX (t) = Φ( n(t − θ)), где Φ(t) = √
2π

122

Zt
2 /2

e−u
−∞

du.

√
Φ( n(t − θ)) монотонно убывает по θ.
Найдем решения (1) и (2) :
Φ(z) = ε;
Φ(z) строго возрастает ⇒ zε = Φ−1 (ε),
Φ(z) = 1 − ε;
⇒ z1−ε = Φ−1 (1 − ε).
Принимая во внимание вид графика функции стандартного нормального распределения, имеем zε = −z1−ε . Учтем это:
Φ(zε ) − Φ(z1−ε ) = ε − (1 − ε) = 2ε − 1,
при этом
zε =
z1−ε =

√
√

n(T (Y ) − θ1∗ ),
n(T (Y ) − θ2∗ ).

Отсюда находим:

zε
θ1∗ = T (Y ) − √ ,
n
z
ε
θ2∗ = T (Y ) + √
n
и получаем доверительный интервал
¶
µ
zε
zε
.
X − √ ,X + √
n
n
Замечание. Наличие решения зависело от монотонности функции(в случае монотонной функции легко получаем обратную), если же функция плотности ступенчатая, однозначно найти ε не удастся и в результате получим интервал удовлетворяющий неравенству P(θ1∗ < θ < θ2∗ ) > γ.
Замечание. Если случайная величина X имеет функцию распределения FX (y), то
FX (X) — такая случайная величина, что при определенных дополнительных условиях, она равномерно распределена на [0; 1].
(В частности, если случайная величина X имеет нормальное распределение, то случайная величина FX (X) ∼ U [0; 1]).

17.1.2

Метод, основанный на центральной статистике

Пусть Y = (X1 , . . . , Xn ) — выборка из распределения L(X).
Определение 17.1. Центральная статистика — это случайная величина
V (Y, θ), удовлетворяющая двум условиям:
1. Распределение V не зависит от θ;
2. V (Y, θ) монотонна как функция θ.
Если смогли найти такую функцию, то
Пусть v1 и v2 :
P(v1 < V (Y, θ) < v2 ) = γ, (3)
так как V (Y, θ) монотонна по θ (для определенности считаем, что монотонно возрастает), то получаем θ1∗ и θ2∗ — решения уравнений
V (Y, θi∗ ) = vi .
123

Тогда (3) эквивалентно
P(θ1∗ < θ < θ2∗ ) = γ.
Проиллюстрируем метод:
Рассмотрим выборку из распределения L(X) ∼ N (µ, θ2 ) при условии, что µ известно,
а θ2 — нет, и построим доверительный интервал для θ2 .
Рассмотрим следующую случайную величину — кандидата на звание центральной
статистики:
¶2
n µ
n
X
Xi − µ
1 X
2
V (Y, θ ) =
= 2
(Xi − µ)2 .
θ
θ
i=1
i=1
Проверяем условия:
1. Распределение V (Y, θ), очевидно, не зависит от θ (как сумма стандартно нормально распределенных случайных величин).
2. V (Y, θ) монотонно убывает как функция θ2 .
Следовательно, таким образом заданная функция V (Y, θ) является центрально статистикой.
Определение 17.2. Случайная величина с распределением, совпадающим с распределением
Z12 + . . . + Zn2 ,
где Zi — независимые случайные величины со стандартным нормальным распределением, называется случайной величиной с χ2 -распределением с n степенями свободы с плотностью

1

y n/2−1 e−y/2 , при y > 0
n/2
pn (y) = 2 Γ(n/2)

0,
иначе.
Обозначение — χ2n .
Замечание. Заметим, что при
n = 1 функция плотности не ограничена в нуле;

1
n = 2 имеем показательное распределение с параметром ;
2
n = 3 функция плотности на левой полуоси равна нулю, далее она возрастает, достигает максимуму и экспоненциально убывает. Найдем такие v1 , v2 , что площадь
фигуры, ограниченной графиком плотности, двумя прямыми x = v1 и x = v2 и осью
абсцисс, в точности равна γ. Естественно, что v1 , v2 находятся не единственным образом. Для определенности поместим на "хвосты"по половине остаточной массы, т.
е. по (1 − γ)/2. Для нахождения v1 и v2 решаем следующие уравнения
P(χ2n < v1 ) = (1 − γ)/2;
P(χ2n > v2 ) = (1 − γ)/2;
Из них v1 и v2 находятся однозначно(с помощью таблиц, пакетов).
В результате получаем:
P(v1 < χ2n < v2 ) = γ,
где χ2n — центральная статистика, монотонно убывающая по θ2 . Тогда предыдущее
равенство эквивалентно
124



n
P

2

 i=1(Xi − µ)
P
< θ2 <

v2

n
P


2

(Xi − µ) 
 = γ.

v1

i=1

Определение 17.3. Центральным доверительным интервалом называется доверительный интервал, при котором на "хвостах"лежит одинаковая масса.
Замечание. Критерием того, насколько хорошо выбран доверительный интервал,
1
1
−
с коявляется его длина. В данном случае она пропорциональна разности
v1
v2
n
P
эффициентом пропорциональности
(Xi − µ)2 . Таким образом, перед нами встает
i=1

задача минимизации указанной выше разности при условии, что

Rv2

pn (y)dy = γ. В яв-

v1

ном виде решения получить, вообще говоря, нельзя из-за вида функции плотности,
так что для минимизации длины используются таблицы хи-квадрат распределения.

17.1.3

Метод, основанный на центральной предельной теореме

Пусть X1 , . . . , Xn из L(X), θ ∈ Θ, и считаем, что все нужные для дальнейшего рассмотрения производные и мат. ожидания существуют. Функция правдоподобия в
данном случае имеет вид:
pn (y, θ) =

n
Y

p(xi , θ),

i=1

где p — плотность случайной величины X. Так как случайные величины X1 , . . . , Xn
независимы и одинаково распределены, то, рассмотрев производную по θ натурального логарифма функции правдоподобия, имеем
n

n

X ∂
X
∂
(ln pn (Y, θ)) =
(ln p(Xi , θ)) =
Zi ,
∂θ
∂θ
i=1
i=1
где случайные величины Z1 , . . . , Zn — независимы и одинаково распределены.
По ЦПТ ∀c, d, c 6 d имеем:
µ
¶
Z1 + . . . + Zn − a
n→∞
√
P c6
6 d −−−→ Φ(d) − Φ(c), (4)
σ n
где Φ(z) — функция стандартного нормального распределения, a = EZ1 , σ 2 = DZ1 .
Ранее было доказано, что
µ
¶
∂ ln p(X1 , θ)
E
= 0; (т. е. a = 0)
∂θ
µ
µ 2
¶
¶2
∂ ln p
∂ ln p
2
σ = DZ1 = E
= −E
.
∂θ
∂θ2

125

Рассмотрим фукнцию
n ∂ ln p(X , θ)
P
i
∂θ
Vn (θ) = Ã µi=1
¶2 !1/2 .
∂ ln p(Xi , θ)
E
∂θ

По ЦПТ распределение Vn (θ) → N (0, 1), т. е. если нам нужно найти zγ — решение
следующего уравнения
P(|Vn (θ)| < zγ ) = γ, (5)
то заменяем уравнение (5) на предельное
Φ(zj ) − Φ(−zj ) = γ, (6)
затем по таблицам или из пакетов программ находим из (6) zγ по заданному γ.
Предположим, что неравенство
|Vn (θ)| < zγ (7)
разрешается относительно θ в виде интервала θ1∗ < θ < θ2∗ , тогда (θ1∗ , θ2∗ ) — доверительный интервал с надежностью γ. Стоит заметить, что неравенство (7), вообще
говоря, не является однозначно разрешимым или разрешимым относительно θ.
Пример. Рассмотрим выборку из Пуассоновского распределения:
θk
L(X) ∼ P ois(θ), θ > 0, P(X = k) = e−θ .
k!
В данном случае
n
P

pn (y, θ) = θ

i=1

xi

−nθ

e

n
n
Y
Y
1
1
nX −nθ
=θ e
x!
x!
i=1 i
i=1 i

⇒
¢
∂ ln pn
1
n¡
= nX − n =
X −θ
∂θ
θ
θ
тогда
• В силу неравенства Рао-Крамера X — эффективная оценка для θ.
• Для нахождения оценок максимального правдоподобия нужно решить уравнение правдоподобия:
∂
ln pn (Y, θ) = 0, откуда
∂θ
θ∗ = X,

126

т. е. X — оценка максимального правдоподобия.
Имеем
µ 2
¶
µ
¶
µ ¶
∂ ln pn
nX
X
n
DZ1 = E
=
E
=
nE
=
∂θ2
θ2
θ2
θ
⇒
r
¢
n¡
Vn (Y, θ) =
X −θ ,
θ
Решаем неравенство (7) в виде интервала относительно θ и, введя обозначение
s
zγ2
X
B(γ, n) = zγ
+ 2,
n
4n
получаем, что доверительный интервал имеет вид
X+

17.2
17.2.1

zγ
zγ
− B(γ, n) < θ < X +
+ B(γ, n).
2n
2n

Проверка статистических гипотез
Общая постановка проверки статистических гипотез

Пусть X1 , . . . , Xn из L(X) ∈ P,
т. е. есть некоторая статистическая структура (X, A, P), где
X — совокупность всех возможных значений выборки,
A — σ -алгебра,
P — семейство вероятностных распределений.
Основная задача — максимально сузить P, т. е. найти распределение, наиболее
соответствующее выборке.
Определение 17.4. Статистической гипотезой называется любое предположение о распределении случайной величины X.
Определение 17.5. Статистическая гипотеза называется простой, если предполагаемое семейство вероятностных распределений состоит в точности из одного распределения.
Пример. Предположим, что имеется набор значений цен Pt в момент времени t, тоPt+1 − Pt
гда Xt =
— выборка относительных доходностей. Допустим, что известно,
Pt
что Xt ∼ N (θ1 , θ22 ), тогда как только мы фиксируем оба параметра, то получаем простую гипотезу, например, Xt ∼ N (0.1, 0.001).
Пусть нулевое предположение H0 : L(X) ∈ P0 , альтернатива H1 : L(X) ∈ P1 ,
где P0 , P1 могут состоять как из одного, так и из больше числа распределений, и P0
и P1 не пересекаются.

17.2.2

Типы гипотез

• Гипотезы о виде распределения (например, X ∼ N (0, 0.001))
• Гипотезы о проверке однородности выборки
127

Пример. Предположим, что имеется несколько выборок:
x11 , . . . , x1n1 ∼ L(X),
x21 , . . . , x2n2 ∼ L(Y )
тогда H0 : L(X) = L(Y ) (гипотеза об однородности)
H1 : L(X) 6= L(Y ).
В качестве содержательного примера можно рассмотреть следующий: имеются
два метода лечения, старый и новый. Есть два набора результатов, количество
которых n1 и n2 для старого и нового методов соответственно. Тогда в качестве
H0 можно взять гипотезу о том, что новый метод не лучше старого.
• Гипотезы о независимости признаков
Пусть имеется выборка (набор двумерных векторов), полученная из случайного вектора (X, Y )
(x1 , y1 ), . . . , (xn , yn ) ∼ L(X, Y ).
H0 : X, Y независимы,
H1 : X, Y зависимы.
Определение 17.6. Статистическим критерием (критерием) называется
правило, согласно которому гипотеза H0 принимается или отвергается.
Пример. Допустим, что семейство вероятностных распределений состоит из двух
распределений P : N (0, 1), N (2, 1),
H0 : L(X) ∼ N (0, 1),
H1 : L(X) ∼ N (2, 1),
и имеется всего лишь одно наблюдение x1 . Ясно, что графики функций плотностей,
соответствующих кждому из распределений пересекаются в точке x = 1 и при x < 1
график функции плотности, соответствующей распределению N (0, 1), лежит выше.
Аналогично при x > 1 выше лежит график функции плотности, соответствующей
N (2, 1). В данном случае вполне логично рассмотреть следующий критерий:
Если x1 < 1, то принимается гипотеза H0 .
Естественно, что при проверке гипотез возможны ошибки.
Определение 17.7. Ошибка первого рода — отвергается гипотеза H0 , при
условии, что она верна.
Обозначение — H1 |H0 .
Определение 17.8. Ошибка второго рода — считаем, что гипотеза H0 не
противоречит наблюдаемым данным, при условии, что она не верна.
Обозначение — H0 |H1 .
Определение 17.9. α = P(H1 |H0 ) — уровень значимости критерия.
Определение 17.10. 1 − P(H0 |H1 ) = P(H1 |H1 ) — мощность критерия.
Пример. Рассмотрим предыдущий пример, в котором критерием выбора гипотезы
было сравнение значения x1 с xкрит. = 1. Тогда при xкрит. = 1 получим
α = P(X1 > xкрит. |H0 ) = 1 − Φ(1) ≈ 0.17,
β = P(H0 |H1 ) = P(X1 < xкрит. |H1 ) = Φ(−1) = 1 − Φ(1) ≈ 0.17.
Ясно, что с ростом xкрит. α также растет, а β убывает; при уменьшении же xкрит. α
уменьшается, зато наблюдается рост β.То есть не возможно одновременно сделать
128

ошибки обоих родов сколь угодно малыми (при фиксированном объеме выборки).
Обычно для фиксированного n (объема выборки) фиксируют α и среди всех возможных критериев с заданным уровнем значимости α выбирают наиболее мощный.
Предположим, что есть выборка X1 , . . . , Xn из L(X), с параметром θ ∈ Θ.
H0 : θ ∈ Θ0 , H1 : θ ∈ Θ1 . Θ0 ∩ Θ1 = ∅.
Определение 17.11. Пусть X — совокупность всех возможных значений (X1 , . . . , Xn ),
S ⊂ X — некоторая область, называемая критической область.
Тогда критерий, при котором при условии (x1 , . . . , xn ) ∈ S гипотеза H0 отвергается, называется S-критерием.
В рассмотренном ранее примере S = [1; +∞).
Определение 17.12. Пусть pn (y, θ) — функция правдоподобия, тогда функция
Z
W (S, θ) = pn (y, θ)dy
S

называется функцией мощности.
Содержательный смысл функции мощности:
Если Θ0 = θ0 , Θ1 = θ1 , т. е. H0 , H1 — простые, тогда
Z
W (S, θ0 ) = pn (y, θ0 )dy = P(Y ∈ S|H0 ) = α,
S
Z

W (S, θ1 ) =

pn (y, θ1 )dy = P(Y ∈ S|H1 ) − мощность критерия.
S

Определение 17.13. S-критерий S∗ называется оптимальным критерием с
заданным уровнем значимости α, если
W (S ∗ , θ0 ) = α,
W (S ∗ , θ1 ) > W (S, θ1 ), (8)
для любого S-критерия: W (S, θ0 ) = α.
Если мощность #Θ1 > 1, то (8) выполняется для всех θ1 ∈ Θ1 , но в дальнейшем
будут рассматриваться простые гипотезы.
Определение 17.14. Пусть X — совокупность всех возможных значений (X1 , . . . , Xn ),
и введена функция ϕ : X → [0; 1], тогда, отвергая H0 с вероятностью ϕ(x1 , . . . , xn ),
получаем рандомизированный, или ϕ-критерий.
Оптимальный критерий с заданным уровнем значимости α существует не всегда.
Если ϕ(x1 , . . . , xn ) = 1S (x1 , . . . , xn ), то получаем S-критерий.
Определение 17.15. Функция
Z
W (ϕ, θ) = ϕ(y)pn (y, θ)dy, y = (x1 , . . . , xn )
Rn

называется функцией плотности для рандомизированного критерия.
129

Аналогично
W (ϕ, θ0 ) − уровень значимости,
W (ϕ, θ1 ) − мощность критерия.
Определение 17.16. ϕ∗ — оптимальный рандомизированнй критерий с
уровнем значимости α, если
W (ϕ∗ , θ0 ) = α,
W (ϕ∗ , θ1 ) > W (ϕ, θ1 ),
для любого ϕ: W (ϕ, θ0 ) = α.
Оптимальный рандомизированный критерий существует всегда.

130

Лекция 18

18.1

Лемма Неймана-Пирсона

Пусть X1 , . . . , Xn — повторная выборка из L(X), θ ∈ Θ;
и относительно значений параметра имеем две простые гипотезы:
H0 : θ = θ 0 ;
H1 : θ = θ 1 ;
pn (y, θ) — функция правдоподобия,
p1 (y) = pn (y, θ1 ), p0 (y) = pn (y, θ0 );
Тогда отношением правдоподобия называется величина

p1 (y)
.
p0 (y)

Определение 18.1. Критерии отношения правдоподобия — это критерии,
p1 (y)
основанные на отношении
.
p0 (y)
Лемма 18.1. Для ∀α ∈ [0; 1] ∃ постоянные c > 0 и ε ∈ [0; 1] такие, что ϕ – критерий


 1, p1 (y) > cp0 (y),
∗
ϕ (y) = ε, p1 (y) = cp0 (y),

 0, p (y) < cp (y)
1
0
является оптимальным критерием, т. е. наиболее мощным среди всех
ϕ – критериев с уровнем значимости α.
Замечание. Если рассмотреть пример из прошлой лекции, где X1 из L(X) ∼
N (θ, 1), H0 : θ = 0, H1 : θ = 2, то критерий отношения правдоподобия в данном случае естественен, т. к. берется та гипотеза, при которой график функции
плотности располагается выше. Стоит заметить, что, вообще говоря, нельзя положить c равным 1, так как при выборе c нужно отталкиваться от заданного уровня
значимости α.
Замечание. ϕ∗ – критерий воспринимаем следующим образом:
ϕ(y) = 1 ⇒ H0 отвергаем,
ϕ(y) = 0 ⇒ H0 принимаем,
ϕ(y) = 1 ⇒ H0 отвергается с вероятностью ε.
Рассмотрим крайние случаи для α:
α = 0 = P(H1 H0 ) (т. е. мы никогда не допускаем ошибку 1-го рода), тогда
(
1, p1 (y) = 0, (но сюда мы никогда не попадем)
ϕ∗ (y) =
0, p0 (y) > 0, (здесь гипотеза H0 не отрицается)
131

α = 1 (всегда имеет место ошибка 1-го рода), H0 всегда отвергается, т. е.
ϕ∗ (y) = 1.
Доказательство. Доказательство будет состоять из двух частей: в 1-ой мы конструктивно укажем, как по заданному α найти c и ε, во 2-ой части будет доказана
оптимальность и то, что данный критерий обладает заданным уровнем значимости.
1. Определим функцию g(c) = P(p1 (Y ) > cp0 (Y )) | H0 ) (т. е. случайный вектор Y
имеет распределение, соответсвующее нулевой гипотезе). Тогда
1 − g(c) = P(p1 (Y ) < cp0 (Y ) | H0 ) = P(p1 (Y ) < cp0 (Y )1({p0 (Y )>0}) | H0 )
p1 (Y )
= P(
< c | H0 )
p0 (Y )1({p0 (Y )>0})
= ф-ия распределения сл. в. z как ф-ия от c.
Тогда можно выделить следующие свойства функции g(c) :
1. g(c) не возрастает;
2. g(c) непрерывна слева;
3. g(0) = 1; g(+∞) = 0;
Далее по заданному α определим cα следующим образом:
g(cα + 0) = lim g(c) < α 6 g(cα ),
c→cα +0

если cα — точка разрыва функции g(c), в противном случае
cα : α = g(cα ).
Для функции g(c) рассмотрим три возможных случая:
1. Функция g(c) терпит разрыв так, что ее график не пересекается с графиком
функции y = α. Т. е. в некоторой точке c0 g(c) разрывна и
g(c0 ) > α, g(c0 − 0) < α. Тогда cα = c0 .
2. Функция g(c) непрерывна и значение, равное α, достигается в единственной
точке c0 . Тогда, аналогично, cα = c0 .
3. Функция g(c) непрервына и значение, равное α, достигается на отрезке [c1 ; c2 ].
Тогда в качестве cα берем произвольную точку из отрезка [c1 ; c2 ].
Таким образом определенное cα и есть искомое c из определения функции ϕ∗ (y). ε
же определяется следующим образом:
во 2-ом и 3-ьем случаях (когда решение существует) ε = 0,
α − g(cα + 0)
.
в 1-ом случае положим ε =
g(cα ) − g(cα + 0)

132

2. Уровень значимости
Z
W (ϕ, θ0 ) = ϕ∗ (y)p0 (y)dy =

Z

Rn

p1 (y)>cα p0 (y)

Z
p0 (y)dy + ε ·
p1 (y)=cα p0 (y)

Z

= g(cα ) + (ε − 1) ·

p0 (y)dy

p0 (y)dy
p1 (y)=cα p0 (y)

= g(cα ) + (ε − 1)(g(cα ) − g(cα + 0))
(
g(cα ) + α − g(cα ) в 1-ом случае
=
g(cα ) во 2-ом и 3-ьем случаях
= α для всех трех случаев.
Таким образом показано, что ϕ∗ – критерий имеет уровень значимости α.
Предположим, что произвольный ϕ – критерий имеет уровень значимости α, и
докажем, что
W (ϕ∗ , θ1 ) > W (ϕ∗ , θ1 )

(1)

Рассмотрим интеграл
Z
I = (ϕ∗ (y) − ϕ(y))(p1 (y) − cα p0 (y))dy
Rn

Z

Z
∗

=

(ϕ (y) − ϕ(y))(p1 (y) − cα p0 (y))dy +
ϕ∗ > ϕ

(ϕ∗ (y) − ϕ(y))(p1 (y) − cα p0 (y))dy =

ϕ∗ < ϕ

= I1 + I2 ;
Покажем, что I1 и I2 неотрицательны.
1) на множестве тех y, где ϕ∗ (y) > ϕ(y) > 0, выполнено также и ϕ∗ (y) > 0, и,
следовательно, p1 (y) > cα p0 (y) ⇒ I1 > 0
2) аналогично на множестве тех y, где ϕ∗ (y) < ϕ(y) 6 1, выполнено также и
ϕ∗ (y) < 1, и, следовательно, p1 (y) 6 cα p0 (y) ⇒ I2 > 0
Отсюда

0 6 I = W (ϕ∗ , θ1 ) − W (ϕ, θ1 ) − cα (W (ϕ∗ , θ0 ) − W (ϕ, θ0 ))
= {W (ϕ∗ , θ0 ) = W (ϕ, θ0 ) = α}.

⇒ W (ϕ∗ , θ1 ) > W (ϕ∗ , θ1 ), и (1) доказано.

18.2

Равномерно наиболее мощные критерии

Пример. Пусть X1 , . . . , Xn из L(X) ∼ N (θ, 1), H0 : θ = 0, H1 : θ = θ1 > 0.
Тогда

133

"
Ã n
!#
" n
#
X
X
p1 (y)
1
n
−
2xi θ1 + nθ12
= exp
xi θ1 − θ12 > c
= exp −
p0 (y)
2
2
i=1
i=1
m
n
X

xi > c 1

i=1

m
X > c2
Пусть α задано. Тогда P(X > c2 | H0 ) = α.
√
1
Из H0 следует, что X ∼ N (0, ), поэтому n X ∼ N (0, 1) и, если uα определяется
n
из равенства
1 − Φ(uα ) = α,

(2)

то
uα
cα = √ .
n
Следовательно, оптимальным критерием является следующее утверждение:
uα
"Гипотеза H0 отвергается, если X > √ ."
n
Замечание. Так как условие θ1 > 0 не содержится в описании критерия, то критерий остается неизменным для всех θ1 > 0, т. е. этот критерий является равномерно
наиболее мощным критерием для альтернативы H1 : θ = θ1 > 0.
uα
Замечание. Если θ1 < 0, то X < − √ , где uα из (2), и данный критерий также
n
является равномерно наиболее мощным.
Замечание. Рассмотрим мощность построенного критерия в случае θ1 > 0 :
uα
1
W (ϕ∗ , θ1 ) = P(X > √ | H1 ) = {X ∼ N (θ1 , )}
n
n
√
= 1 − Φ(uα − θ1 n).
Замечание. Если θ1 ∼ 0, то W (ϕ∗ , θ1 ) ∼ α, т. е. мощность мала. Это можно объяснить тем, что в случае, когда альтернатива H1 близка к H0 , вероятность ошибки
второго рода довольная велика.
Замечание. Если n → ∞, то W (ϕ∗ , θ1 ) → 1, т. е. вероятность ошибки второго рода
стремится к нулю, и ее можно сделать сколько угодно малой, меняя объем выборки.

134

Лекция 19

19.1

Состоятельные критерии

Рассмотрим пример из предыдущей лекции . Пусть X1 , . . . , Xn из L(X) ∼ N (θ, 1),
H0 : θ = θ0 = 0, H1 : θ = θ1 > 0. Используя лемму Неймана-Пирсона, построим
н. м. к. (наиболее мощный критерий):
uα
X>√ ,
n
где
1 − Φ(uα ) = α — уровень значимости.
(Этот критерий является равномерно наиболее мощным.)Несложно видеть, что при
фиксированном значении θ1 и при n → ∞ W → 1.
Определение 19.1. Критерий называется состоятельным, если его мощность
стремится к 1 при неограниченном увеличении объема выборки.
Замечание. Таким образом, построенный выше критерий является состоятельным.

19.2
19.2.1

Критерий χ2 Пирсона
Критерий χ2 Пирсона

Пусть X1 , . . . , Xn из L(X), где L(X) — дискретное распределение, при котором случайная величина принимает значения
a1 , . . . , ak
с вероятностями
p1 , . . . , p k .
И рассматриваются две гипотезы:
H0 : pi = pi0
H1 :

k
X

(pi − pi0 )2 > 0

∀i = 1, k,
, т. е. хотя бы для одного i pi 6= pi0 .

i=1

Тогда по критерию χ2 Пирсона предлагается рассмотреть следующую статистику:
пусть x1 , . . . , xn — реализация выборки, а ν1 , . . . , νk — набор чисел, составленный
по следующему закону:

135

νi равно количеству встретившихся в данной выборки значений ai . Если H0 справедлива, то νi ∼ Bi(n, pi0 ). Тогда
Eνi = npi0 ,
Dνi = npi0 (1 − pi0 ),
k
X
(νi − npi0 )2
χ =
.
npi0
i=1
2

То есть получена статистика χ 2 , или χ 2 – критерий.

19.2.2

Асимптотика для критерия Пирсона

Пример. Рассмотрим следующие данные: в 2006 году в России насчитывалось 53
миллиардера, из которых 12% родились под знаком Девы. Предположим, что исследуемая случайная величина принимает значения 1 (миллиардер родился под знаком
Девы) и 0 (под другим знаком), т. е. a1 = 1, a2 = 0. Тогда гипотезы H0 и H1 можно
сформулировать следующим образом:
1
1
H0 : p1 0 =
(вероятность родиться под знаком Девы равняется
).
12
12
1
1
H1 : p1 1 6=
(вероятность родиться под знаком Девы не равна , в данном случае
12
12
12
1
больше, т. к.
> ).
100
12
Предположим, что объем выборки n = 100 и ν1 = 12, тогда, используя критерий
χ2 Пирсона, получаем, что χ 2 = 1.76. Если же справедлива H0 , то χ 2 ∼ 0. Тогда
критическая область S имеет вид
S = {χ 2 : χ 2 > χ2крит. },
и
α = P(χ 2 > χ2крит. | H0 ),
причем найти из этого уравнения χ2крит. по заданному α довольно непросто. Используем ассимптотический подход:
(ν1 − np1 0 )2 (ν2 − np2 0 )2
+
= {ν1 + ν2 = n, p1 0 + p2 0 = 1} =
np1 0
np2 0
¶
µ
(ν1 − np1 0 )2 (n − ν1 − n(1 − p1 0 ))2
(ν1 − np1 0 )2
1
1
=
+
=
−
=
np1 0
np2 0
n
p1 0 1 − p1 0
Ã
!2 Ã
!2
(ν1 − np1 0 )2
ν1 − np1 0
Y1 + . . . + Yn − np1 0
p
= p
=
=
,
np1 0 (1 − p1 0 )
np1 0 (1 − p1 0 )
np1 0 (1 − p1 0 )

χ2 =

где

(
Yi =

1, если xi = ai ,
.
0, иначе

Применяем ЦПТ : выражение, стоящее внутри скобок сходится по распределению к
стандартному нормальному, т. е. все выражение сходится по распределению к распределению χ2 с одной степенью свободы. Таким образом, доказана
Теорема 19.1.
∀z ∈ R

P(χ 2 < z) → P(χ21 < z).
136

Теорема 19.2.
∀z ∈ R

P(χ 2 < z) → P(χ2k−1 < z),

где k — число значений в дискретном распределении L(X),
χ2k−1 — χ2 – случайная величина с (k − 1) степенями свободы.
Пример. В рассмотренном выше примере о миллиардерах
α = P(χ 2 > χ2крит. | H0 ) ∼ P(χ12 > χ2крит. | H0 ),
и при α = 0.1 получаем χ2крит. = 2.71, т.е. гипотеза H0 не противоречит данным.

19.3

Состоятельность критерия Пирсона

Теорема 19.3. Критерий χ2 является состоятельным, т. е.
P(χ 2 =

k
X
(νi − npi0 )2
> χ2крит. | H1 ) → 1 при росте n, или
np
i0
i=1

k
X
(νi − npi0 )2
P(χ =
< χ2крит. | H1 ) → 0 при росте n.
npi0
i=1
2

Доказательство.
k
k
X
(νi − npi0 )2 X (νi − npi1 + npi 1 − npi 0 )2
χ =
=
=
npi0
npi0
i=1
i=1
2

= { при условии H1 : νi ∼ Bi(n, pi 1 ) ⇒ Eνi = npi 1 } =
k
k
k
X
X
X
(νi − npi1 )(npi1 − npi0 )
(npi 1 − npi0 )2
(νi − npi1 )2
+2
+n
=
=
npi0
npi0
npi0
i=1
i=1
i=1

= Y1 + 2Y2 + nC1 (k), причем Y1 > 0, C1 (k) > 0.
Тогда в терминах введенных случайных величин Y1 , Y2 надо доказать, что
P(Y1 + 2Y2 + nC1 (k) < χ2крит. | H1 ) → 0.
Обозначим −nC2 (k) = χ2крит. − nC1 (k), причем C2 (k) > 0.
И, т. к. Y1 > 0, достаточно показать, что
nC2 (k)
| H1 ) → 0, или
2
P(Y2 < −nC3 (k) | H1 ) → 0.

P(Y2 < −

P(Y2 < −nC3 (k) | H1 ) 6 P(|Y2 | > nC3 (k) | H1 ) 6
6 { по н-ву Чебышева } 6

DY2
.
2
n C32 (k)

Для того, чтобы доказать стремление к нулю, достаточно показать, что DY2 6
nC4 (k), а этот факт будет следовать из того, что EY22 6 nC4 (k). Покажем последнее

137

неравенство:
Ã k
!2
X (νi − npi )(pi − pi )
1
1
0
EY22 = E
=
pi0
i=1
Ã k
!2
X
(pi1 − pi0 )
=E
(νi − npi1 )
6
p
i
0
i=1
6 { по н-ву Коши-Буняковского} 6
6 C5 (k)E
= nC5 (k)

k
X
i=1
k
X

(νi − npi1 )2 =
pi 1 (1 − pi1 ) = nC4 (k).

i=1

19.4

Обобщение классического критерия χ2

Рассмотрим L(X) — дискретное распределение, при котором случайная величина
принимает значения
a1 , . . . , ak
с вероятностями
p1 , . . . , p k .
И нулевая гипотеза имеет вид:
H0 : pi = pi0 (θ)

∀i = 1, k, где θ = (θ1 , . . . , θr ).

Тогда следует рассматривать
2

χ =

k
X
(νi − npi0 (θ̂))2
i=1

npi0 (θ̂)

, где θ̂ — оценка для θ.

(1)

Теорема 19.4. Если функция pn (X, θ) достаточно гладкая, и θ̂ — оценка максимального правдоподобия для θ,
то статистика, определяемая (1), сходится по распределению к χ2k−1−r .

138

Лекция 20

20.1

Критерий согласия Пирсона χ 2 для абсолютно
непрерывных распределений

Пусть L(X) — абсолютно непрерывное распределение. Разобьем вещественную прямую на интервалы следующим образом:
Ã
!
[ k−2
[
[
(zi ; zi+1 ]
R = (−∞; z1 ]
[zk−1 ; +∞).
i=1

В качестве νi берем число xi , попавших в Ci = (zi−1 ; zi ], считая z0 = −∞, zk = +∞.
Сформулируем гипотезу H0 для функции плотности f (y)
H0 : f (y) = f0 (y).
Положим
Z
pi = P(X ∈ Ci ) =

f0 (y)dy = pi0 .
Ci

Далее можем, как и ранее, считать
χ2 =

k
X
(νi − npi0 )2
→ χ2k−1 .
np
i0
i=1

Таким образом проведена дискретизация непрерывной задачи.
Тем не менее, остаются нерешенными два вопроса:
1. выбор zi ,
2. количество точек разбиения zi .
Пример. Рассмотрим случай k = 2. Для любого симметричного распределения получаем p10 = p20 = 12 , и, как следствие, при разбиении вещественной прямой на две
полупрямые мы уже не можем различить два неравных друг другу распределения с
функциями плотности, симметричными относительно оси абсцисс. Т. е. необходимо,
чтобы дискретная модель максимально отражала непрерывную.
Наиболее правдоподобное приближение непрерывной модели дискретной
получается при достаточно большом (k) и при более мелком разбиении прямой для
тех участков, где функция плотности f0 (y) принимает большие значения. С другой
стороны, нельзя неограниченно увеличивать (k), т. к. при фиксированном объеме
выборки (n) мы можем получить ситуацию, при которой многие νi будут равняться
нулю, что не прибавит точности.

139

20.2

Критерий независимости χ 2

Пример. Допустим, что проведен опрос (n) выпускников некоторого учебного заведения
( и имеется следующая выборка — X1 , . . . , Xn , где Xi = (Z1 i , Z2 i ),
1, если i -тый выпускник имеет красный диплом
Z1 i =
,
0, иначе


 2, если i -тый выпускник доволен работой
Z2 i = 1, если i -тый выпускник нейтрально относится к работе .


0, если i -тый выпускник не доволен работой
Т. е. имеются две случайные величины: Z1 , отражающая распределение красных
дипломов, и Z2 , показывающая отношение выпускников к текущей работе. Тогда
можно сформулировать гипотезу
H0 : Z1 и Z2 независимы,
и по полученной выборке двумерных векторов попытаться определить, насколько
она соответсвует полученным данным.
Рассмотрим следующую абстрактную модель: имеется выборка из (n) двумерных
векторов X1 , . . . , Xn , где Xi = (Z1 i , Z2 i ), νi j — число векторов из данной выборки, у
которых первая компонента равна bi , а вторая — aj , i = 1, l, j = 1, k. По гипотезе
H0 случайные величины Z1 и Z2 независимы, т. е.
pi j = P(Z1 = bi ; Z2 = aj ) = P(Z1 = bi ) · P(Z2 = aj ) = pi · · p·j .
Положим
2
χнезав.

l X
k
X
(νi j − npi j )2
=
.
npi j
i=1 j=1

Для мультиномиального распределения функция правдоподобия имеет вид
Y ν
L=c
pijij ,
i,j

и для рассматриваемой нулевой гипотезы получим
L=c

l
Y

pνi·i·

i=1

k
Y

ν

p·j·j .

j=1

Можно показать, что оценка максимального правдоподобия для pi · и p· j такова
νi ·
p∗i · =
,
n
ν· j
p∗·j =
.
n
Аналогично случаю обощения классического критерия χ 2
³
νi· · ν·j ´2
l X
k n νij −
X
2
n
=
→ χ2kl−1−(l−1)−(k−1) = χ2(l−1)(k−1) .
χнезав.
ν
·
ν
i·
·j
i=1 j=1
2
Так же, как и ранее, для некоторым образом определенного χкрит.
, гипотеза H0 от2
2
вергается при χнезав. ≥ χкрит. . Поскольку считать вероятность
2
2
≥ χкрит.
| H0 ) довольно сложно, используем то, что
P(χнезав.
2
2
2
≥ χкрит.
| H0 ) → P(χ2(l−1)(k−1) ≥ χкрит.
| H0 ).
α = P(χнезав.

140

20.3

Критерий независимости χ 2

Рассмотрим (l) выборок из дискрентых распределений L(X1 ), . . . , L(Xl ), набор значений в которых одинаков — a1 , . . . , ak :
X1 1 , . . . , X1 n1 из L(X1 ),
X2 1 , . . . , X2 n1 из L(X2 ),
...
Xl 1 , . . . , X1 nl из L(Xl ).
По гипотезе H0 предполагается, что : L(Xi ) одинаковы, т. е. имеем задачу об однородности выборки. Пусть νi j — число элементов i-той выборки, совпадающих со
значением aj , тогда H0 такова, что pij = pj ∀j = 1, k и сразу для всех i.
2
χоднор.

l X
k
X
(νij − ni pij )2
=
=
ni pij
i=1 j=1
n
o
ν· j
= pij = pj (H0 ) неизвестны, ОМП для них: p∗j =
, n = n1 + . . . + nl =
n
³
ν·j · ni ´2
l X
k
νij −
X
n
=n
→ χ2(l−1)(k−1) при k → ∞,
ν·j · ni
i=1 j=1

и
2
2
2
α = P(χоднор.
≥ χкрит.
| H0 ) → P(χ2(l−1)(k−1) ≥ χкрит.
| H0 ),
2
2
≥ χкрит.
.
т. е. H0 отвергается при χоднор.

20.4

Проверка гипотез и доверительный интервал

Пример. Рассмотрим выборку X1 , . . . , Xn из L(X) ∼ N (θ, 1),
H0 : θ = 0,
H1 : θ > 0.
Тогда р. н. м. кр. (равномерно наиболее мощный критерий) таков:
uα
при X > √ гипотеза H0 отвергается,
n
где α находится из уравнения 1 − Φ(uα ) = α.
Аналогично, если
H0 : θ = θ0 ,
H1 : θ > θ1 ,
р. н. м. кр. таков:
uα
при X > √ + θ0 гипотеза H0 отвергается,
n
где α : 1 − Φ(uα ) = α.

141

Допустим, что имеется нерандомизированный S-критерий ( S = S(θ0 )),
т. е. если y = (x1 , . . . , xn ) — реализация выборки и y ∈ S, то простая нулевая
гипотеза H0 : θ = θ0 отвергается. Понятно, что H0 принимается при y ∈ S ,
причем P(Y ∈ S | H0 ) = 1 − α.
Рассмотрим случай n = 1, тогда множество всех значения выборки X = R,
р. н. м. кр. : X1 > θ0 + uα , т. е.
S = S(θ0 ) = {x : x > θ0 + uα }.
Для ∀ θ ∈ R получим
S(θ) = X\S(θ) ⊂ X,

n

o
S(θ) . С другой стороны,

т. е. имеем однопараметрическое семейство множеств
фиксировав произвольное x∗ ∈ R, определим
n
o
T (x∗ ) = θ ∈ Θ = R : x∗ ∈ S(θ) ,

тогда получим совокупность множеств {T (x)} в пространстве Θ.
Предположим, что
x ∈ S(θ)
m
θ ∈ T (x),

(20.1)

и, рассматривая вместо x случайную величину X1 , будем иметь
1 − α = P(X1 ∈ S(θ)) = P(θ ∈ T (X1 )).
Таким образом, область T (X1 ) в Θ в данном случае рассматривается нами как доверительная область для неизвестного параметра θ с коэффициентом доверия
(1 − α).
Можно двигаться и в обратном направлении: пусть T (X) — построенная
доверительная область с коэффициентом доверия γ, тогда из (20.1)
получим S-критерий с уровнем значимости (1 − γ).

20.5

Несмещенные критерии

Определение 20.1. Статистический критерий называется несмещенным, если для любого значения параметра из альтернативы H1 мощность критерия не
меньше уровня его значимости.
Пусть X1 , . . . , Xn из L(X) ∼ N (θ, 1),
H0 : θ = θ0 ,
H1 : θ =
6 θ0 ,
α — уровень значимости. Можно применить лемму Неймана-Пирсона для построения критериев для альтернатив θ > θ0 и θ < θ0 :
uα
для θ > θ0 критическая область X > θ0 + √ 1 ,
n
uα 2
для θ < θ0 критическая область X < θ0 − √ ,
n
142

где α1 , α2 : α1 + α2 = α. Тогда критическая область
¾ ½
¾
½
uα 1 [
uα 2
x1 , . . . , x n : x < θ 0 − √
.
S = x1 , . . . , x n : x > θ 0 + √
n
n
Можно показать, что
1. мы получим несмещенный критерий только при α1 = α2 ,
2. среди всех несмещенных критериев данный критерий с критической областью
S при α1 = α2 является равномерно наиболее мощным несмещенным критерием.
Так как

½
¾
uα 2
S = x1 , . . . , xn : |x − θ0 | < √
,
n

то из (20.1) можно получить доверительный интервал
uα
uα
x − √ 2 < θ0 < x + √ 2 ,
n
n
который является доверительным интервалом наименьшей длины. Можно также
показать, что если получен доверительный интервал минимальной длины, то
соответствующий ему критерий будет равномерно наиболее мощным несмещенным
критерием.

143

